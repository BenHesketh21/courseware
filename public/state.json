{"topics": [{"gitUri": "topics/iptables", "overview": "Iptables is a command line utility for configuring Linux kernel firewall.", "name": "Iptables", "resourceName": "iptables", "modules": [{"estTime": 25, "gitUri": "topics/iptables/modules/introduction", "overview": "Iptables is a command line utility for configuring Linux kernel firewall.", "name": "Introduction", "resourceName": "iptables/introduction", "content": "<!--PROPS\n{\n    \"estTime\": 25\n}\n-->\n\n<h1>Introduction</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#concepts\">Concepts</a><ul>\n<li><a href=\"#tables\">Tables</a></li>\n<li><a href=\"#chains\">Chains</a><ul>\n<li><a href=\"#filter-table-chains\">Filter Table Chains</a></li>\n</ul>\n</li>\n<li><a href=\"#rules\">Rules</a><ul>\n<li><a href=\"#targets\">Targets</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href=\"#installation\">Installation</a><ul>\n<li><a href=\"#ubuntudebian\">Ubuntu/Debian</a></li>\n<li><a href=\"#centosrhel\">CentOS/RHEL</a></li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#view-current-rules\">View Current Rules</a></li>\n</ul>\n</li>\n<li><a href=\"#allow-for-ssh-connections\">Allow for SSH Connections</a><ul>\n<li><a href=\"#default-polices\">Default Polices</a></li>\n<li><a href=\"#saving\">Saving</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>Iptables is a command line utility for configuring Linux kernel firewall.\nIptables is used to inspect, modify, forward, redirect, and/or drop IP packets.\nAn IP packet is just a very small fragment of data being transmitted over a network.\nTo send a single file over a network, it will likely need to be broken down into many packets and sent over the network to be peiced back together on the other end.\nThe code for filtering IP packets is already built into the kernel and is organized into a collection of tables, each with a specific purpose. </p>\n<p>When using the <code>iptables</code> command, you will need to be either prefixing commands with <code>sudo</code> or be logged in as the <code>root</code> user.</p>\n<h2>Concepts</h2>\n<h3>Tables</h3>\n<p>By default there are three tables in the kernel that contain sets of rules:\n- The <code>filter</code> table is used for packet filtering; this is the table that you will likely be using the most. Think of this table as the default table.\n- The <code>nat</code> table is used for address translation.\n- The <code>mangle</code> table can be used for special-purpose processing of packets.</p>\n<h3>Chains</h3>\n<p>Series of rules in each table are called a chain.\nA table can have more than one chain.</p>\n<h4>Filter Table Chains</h4>\n<p>The <code>filter</code> table has 3 chains: <code>INPUT</code>, <code>FORWARD</code> and <code>OUTPUT</code>.\nThe route table decides which chain incoming packets go to.\nRules can be added to the different chains, to <code>ACCEPT</code> or <code>DROP</code> packets. There will be more on this in the rules section.</p>\n<pre><code class=\"text\">                                      Kernal\n    ,-----------------------------------------------------------------------,\n    |                                                                       |\n    |                                                                       |\n    |                       ,------&gt; FORWARD --------------------------------&gt;\n    |                       |                                               |\n------&gt; Incoming Packet --&gt; Route?                                          |\n    |                       |                                               |\n    |                       `------&gt; INPUT --- Local Process ---&gt; OUTPUT ----&gt;\n    |                                                                       |\n    |                                                                       |\n    `-----------------------------------------------------------------------`\n</code></pre>\n\n<h3>Rules</h3>\n<p>All of the packet filtering is based on rules.\nRules are conditions that can match packets. All the conditions must be met for the rule to apply.\nA rule will usually match things such as: what network interface the packet arrived on (<code>eth0</code> for example), what type of packet it is (<code>ICMP</code>, <code>UDP</code>, <code>TCP</code> for example) and the destination port (<code>80</code> or <code>9000</code> for example).\nA <code>target</code> must also be specified, for when these conditions are met, which basically decides what is going to happen to the packet.</p>\n<h4>Targets</h4>\n<p>A Target (also known as a jump) can be a user-defined chain, or one that already exists.\nA couple of the built in targets are <code>ACCEPT</code> and <code>DROP</code>, which are the ones that you will most likely be using.</p>\n<p>For example; to allow an SSH connection to a machine, you can add a rule to the <code>INPUT</code> chain on the <code>filter</code> (default) table that checks if the packet is using TCP port <code>22</code>.\nIf the condition is met, send the packet to the <code>ACCEPT</code> target. This will allow the packet through.\nYou would also have a default policy to <code>DROP</code> the packet if none of the conditions are met.</p>\n<pre><code class=\"text\">----&gt; Packet ----&gt; INPUT (Filter Table Chain) \n                    |\n                    TCP Port 22? (INPUT Chain Rule)\n                    |       |\n                    |       `----&gt; True ---&gt; ACCEPT (Target to allow the connection)\n                    |       \n                    `----&gt; DROP (Default Policy for INPUT Chain)\n</code></pre>\n\n<h2>Installation</h2>\n<p>Iptables actually comes pre-installed on many popular Linux distributions.\nIf iptables isn't installed, you can use the following to install it for your operating system:</p>\n<h3>Ubuntu/Debian</h3>\n<pre><code class=\"bash\">sudo apt install -y iptables\n</code></pre>\n\n<h3>CentOS/RHEL</h3>\n<pre><code class=\"bash\">sudo yum install -y iptables\n</code></pre>\n\n<h2>Tasks</h2>\n<p>Here, we'll setup a basic chain for using SSH on a machine.\nBe very careful when following the instructions; <strong>if you are using a remote machine over SSH for this, there is a chance you can block yourself out</strong> if the commands below aren't entered correctly.</p>\n<p>In the unlikely case you do get locked out of the machine, you can just restart it to gain access again, <strong>providing that you have not saved your changes</strong>.</p>\n<h3>View Current Rules</h3>\n<p>Try running <code>sudo iptables -v -L</code> to view the current chains and rules in place.\nYou should see that there aren't any rules made:</p>\n<pre><code class=\"text\">Chain INPUT (policy ACCEPT 28 packets, 2550 bytes)\n pkts bytes target     prot opt in     out     source               destination         \n\nChain FORWARD (policy ACCEPT 0 packets, 0 bytes)\n pkts bytes target     prot opt in     out     source               destination         \n\nChain OUTPUT (policy ACCEPT 18 packets, 2286 bytes)\n pkts bytes target     prot opt in     out     source               destination \n</code></pre>\n\n<h2>Allow for SSH Connections</h2>\n<p>We are going to give access to SSH first, before creating the default rules to deny all. This is to make sure that we won't be locked (especially if we are working on a remote machine).\nThe SSH protocol uses TCP port <code>22</code>, so we will allow access to this machine on port <code>22</code>:</p>\n<pre><code class=\"bash\">sudo iptables -A INPUT -p tcp -m tcp --dport 22 -j ACCEPT\n</code></pre>\n\n<p>To make sure that the rule has been added, you can run <code>sudo iptables -L -v</code>. You'll be able to see the new rule under the <code>INPUT</code> chain:</p>\n<pre><code class=\"text\">Chain INPUT (policy ACCEPT 0 packets, 0 bytes)\n pkts bytes target     prot opt in     out     source               destination\n   86  7352 ACCEPT     tcp  --  any    any     anywhere             anywhere             tcp dpt:ssh\n\nChain FORWARD (policy ACCEPT 0 packets, 0 bytes)\n pkts bytes target     prot opt in     out     source               destination\n\nChain OUTPUT (policy ACCEPT 44 packets, 5184 bytes)\n pkts bytes target     prot opt in     out     source               destination\n</code></pre>\n\n<h3>Default Polices</h3>\n<p>It's best practice to have default rules in place to deny all traffic; we can then create rules with a higher priority to allow certain connections.\nDefault targets for chains can be specified by using the <code>-P</code> option:</p>\n<pre><code class=\"bash\"># by default, deny access to all incoming packets\nsudo iptables -P INPUT DROP\n\n# don't forward any packets\nsudo iptables -P FORWARD DROP\n\n# allow any outgoing packets by default\nsudo iptables -P OUTPUT ACCEPT\n\n# allow all connections within the same machine\nsudo iptables -A INPUT -i lo -j ACCEPT\nsudo iptables -A OUTPUT -o lo -j ACCEPT\n</code></pre>\n\n<p>When you run <code>sudo iptables -L -v</code> again, you should now see that the default policies on the chains have changed.\nThe <code>INPUT</code> and <code>FORWARD</code> chains will now <code>DROP</code> all packets by default:</p>\n<pre><code class=\"text\">Chain INPUT (policy DROP 0 packets, 0 bytes)\n pkts bytes target     prot opt in     out     source               destination         \n  162 13240 ACCEPT     tcp  --  any    any     anywhere             anywhere             tcp dpt:ssh\n    0     0 ACCEPT     all  --  lo     any     anywhere             anywhere            \n\nChain FORWARD (policy DROP 0 packets, 0 bytes)\n pkts bytes target     prot opt in     out     source               destination         \n\nChain OUTPUT (policy ACCEPT 34 packets, 5832 bytes)\n pkts bytes target     prot opt in     out     source               destination         \n    0     0 ACCEPT     all  --  any    lo      anywhere             anywhere \n</code></pre>\n\n<h3>Saving</h3>\n<p>At this point, you would typically save the changes we made.\nIf you don't save, the changes made would be erased on a system reboot (which is good if you locked yourself out).\nTo save the changes, run:</p>\n<pre><code class=\"bash\">sudo iptables-save\n</code></pre>"}]}, {"gitUri": "topics/powershell", "overview": "PowerShell is a task-based command-line shell and scripting language built on .NET.", "name": "PowerShell", "resourceName": "powershell", "modules": [{"gitUri": "topics/powershell/modules/error-handling", "overview": "", "name": "Error Handling", "resourceName": "powershell/error-handling", "content": "<h1>Error Handling</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#terminating-vs-nonterminating-errors\">Terminating vs Non-Terminating Errors</a></li>\n<li><a href=\"#the-error-variable\">The $error Variable</a></li>\n<li><a href=\"#erroraction\">ErrorAction</a></li>\n<li><a href=\"#trycatchfinally-block\">Try/Catch/Finally Block</a></li>\n<li><a href=\"#tasks\">Tasks</a></li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>Error handling refers to the anticipation, detection, and resolution of programming, application, and communications errors.</p>\n<p>This process can be seen in most programming languages, but this module will focus on Error Handling in PowerShell.</p>\n<h2>Terminating vs Non-Terminating Errors</h2>\n<p>It is important to firstly understand the types of errors that can occur during execution:</p>\n<ul>\n<li><strong>Terminating Error</strong>: A serious error during execution that halts the command (or script execution) completely. Examples can include non-existent cmdlets, syntax errors that would prevent a cmdlet from running, or other fatal errors.</li>\n<li><strong>Non-Terminating Error</strong>: A non-serious error that allows execution to continue despite the failure. Examples include operational errors such file not found, permissions problems, etc.</li>\n</ul>\n<h2>The $error Variable</h2>\n<p>When either type of error occurs during execution, it is logged to a global variable named <strong>$error</strong>.</p>\n<p>On a new PowerShell instance, where no errors have occured yet, the <strong>$error</strong> variable is ready and waiting. At this point it will be empty, and you can check this by running the following:</p>\n<pre><code class=\"powershell\">$error.Count\n</code></pre>\n\n<h2>ErrorAction</h2>\n<p>We can use <code>ErrorAction</code> to handle non-terminating errors in PowerShell.</p>\n<p>When running a script, you can add a command line option of <code>-ErrorAction</code> followed by:</p>\n<ul>\n<li><strong>SilentlyContinue</strong>: error messages are suppressed and execution continues.</li>\n<li><strong>Stop</strong>: forces execution to stop, behaving like a terminating error.</li>\n<li><strong>Continue</strong>: the default option. Errors will display and execution will continue.</li>\n<li><strong>Inquire</strong>: prompt the user for input to see if we should proceed.</li>\n<li><strong>Ignore</strong>: the error is ignored and not logged to the error stream. Has very restricted usage scenarios.</li>\n</ul>\n<p>An example of this would be if we wanted to zap processes on our pc (providing we are comfortable we know what we are doing!). You could do the following:</p>\n<pre><code class=\"powershell\">Stop-Process 5132, 5076, 5072 -ErrorAction SilentlyContinue\n</code></pre>\n\n<p>If process <code>5132</code> didn't exist and we didn't have an <code>-ErrorAction</code>, the script would come to a halt prematurely and throw an error message (<code>Cannot find process with the process identifier 5132</code>)</p>\n<h2>Try/Catch/Finally Block</h2>\n<p>A terminating error stops a script from running, so we need to make sure we handle the error in some way.</p>\n<p>To handle terminating errors in scripts, we use <code>Try</code>, <code>Catch</code> and <code>Finally</code> blocks.</p>\n<p>Use the <code>Try</code> block to define a section of a script in which you want PowerShell to monitor for errors.</p>\n<p>PowerShell then searches for a <code>Catch</code> block to handle the error.</p>\n<p>After a <code>Catch</code> block is completed, the <code>Finally</code> block is run.</p>\n<p>If the error cannot be handled, the error is written to the error stream.</p>\n<pre><code class=\"powershell\">try { NonsenseString }\ncatch { &quot;An error occured.&quot; }\nfinally { &quot;Exiting.&quot; }\n</code></pre>\n\n<p>PowerShell does not recognise <code>NonsenseString</code> as a cmdlet or other item. Running this script returns the following result:</p>\n<pre><code class=\"powershell\">An error occured.\nExiting.\n</code></pre>\n\n<p>When the script encounters <code>NonsenseString</code>, it causes a terminating error. The <code>Catch</code> block handles the error by running what is inside that block.</p>\n<p>The <code>Finally</code> block runs every time the script is run, even if the <code>Try</code> statement ran without error or an error was caught in a <code>Catch</code> block.</p>\n<h2>Tasks</h2>\n<ol>\n<li>Open a new Powershell Instance</li>\n<li>Check the <code>$error</code> variable, to see if there is anything inside it</li>\n<li>Write the following to the console:</li>\n</ol>\n<pre><code class=\"powershell\">function Hello{\n    [CmdletBinding()]\n    param($Name)\n\n    Write-Error -Message &quot;Nothing to write to console&quot;\n}\n</code></pre>\n\n<ol>\n<li>Type <code>Hello</code> in the console - you should see an error message saying <code>Nothing to write to console</code></li>\n<li>Check the count of the <code>$error</code> variable (it should now be <code>1</code>)</li>\n<li>Use <code>$error[0]</code> to see the error that is stored inside the variable. What do you notice about it?</li>\n<li>Type <code>Hello</code> again, but this time try to not have an error message shown (hint: <code>SilentlyContinue</code>)</li>\n<li>Create a <code>Try</code>, <code>Catch</code>, <code>Finally</code> Block to catch an error (use <code>ThisCmdlet-DoesnotExist</code>), and give some feedback to the user about what kind of error has been encountered.</li>\n</ol>"}, {"gitUri": "topics/powershell/modules/arrays", "overview": "Arrays hold a list of data, in PowerShell they don't need to be the same type of data.", "name": "Arrays", "resourceName": "powershell/arrays", "content": "<h1>Arrays</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#create\">Create</a><ul>\n<li><a href=\"#one-or-less-elements\">One or Less Elements</a></li>\n<li><a href=\"#multi-dimentional-arrays\">Multi Dimentional Arrays</a></li>\n</ul>\n</li>\n<li><a href=\"#access-array-elements\">Access Array Elements</a><ul>\n<li><a href=\"#by-index\">By Index</a></li>\n<li><a href=\"#multiple-elements\">Multiple Elements</a><ul>\n<li><a href=\"#ranges\">Ranges</a></li>\n</ul>\n</li>\n<li><a href=\"#last-element\">Last Element</a></li>\n<li><a href=\"#multi-dimensional\">Multi Dimensional</a></li>\n</ul>\n</li>\n<li><a href=\"#add-array-elements\">Add Array Elements</a><ul>\n<li><a href=\"#append-to-an-array\">Append to An Array</a></li>\n</ul>\n</li>\n<li><a href=\"#change-array-elements\">Change Array Elements</a></li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#log-files\">Log Files</a><ul>\n<li><a href=\"#getting-the-log-files\">Getting the Log Files</a></li>\n<li><a href=\"#last-3-log-file-paths\">Last 3 Log File Paths</a></li>\n<li><a href=\"#compress-the-log-files\">Compress the Log Files</a></li>\n</ul>\n</li>\n<li><a href=\"#csv-table\">CSV Table</a><ul>\n<li><a href=\"#read-in-the-csv-file\">Read in the CSV File</a></li>\n<li><a href=\"#create-a-multi-dimensional-array-from-the-csv\">Create a Multi Dimensional Array from the CSV</a></li>\n<li><a href=\"#iterate-the-multi-dimentional-array\">Iterate the Multi Dimentional Array</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>Arrays hold a list of data, in PowerShell they don't need to be the same type of data.\nArrays can come in useful whenever we need to store lots of information to process one at a time, for instance:\n- Servers to connect to and configure\n- Application folders to build and upload\n- Log files to analyse</p>\n<h2>Create</h2>\n<p>To create an array the easiest way to do it is just list the data, seperated by commas:</p>\n<pre><code class=\"powershell\">$myArray = 1,&quot;two&quot;,3,&quot;four&quot;,5\n</code></pre>\n\n<h3>One or Less Elements</h3>\n<p>Sometimes you will need to explicitly cast to array, for instance if there is only 1 or no elements in the array to start with:</p>\n<pre><code class=\"powershell\"># array with 1 element\n$myArray = @(1)\n# an empty array\n$myArray = @()\n</code></pre>\n\n<h3>Multi Dimentional Arrays</h3>\n<p>A multi dimentional array is basically just storing arrays within an array, this comes in useful when processing grid or table information such as CSV files.\nThe multi dimentional arrays can be created by nesting brackets <code>()</code> in the assignment:</p>\n<pre><code class=\"powershell\">$multiDimentionalArray = @((1,2,3),(1,2,3))\n# same assignment but over multiple lines\n$multiDimentionalArray = @(\n    (1,2,3),\n    (1,2,3)\n)\n</code></pre>\n\n<h2>Access Array Elements</h2>\n<p>There wouldn't be much point storing data in arrays unless we can access them later, so that's what we'll be looking at here in this section.</p>\n<h3>By Index</h3>\n<p>A very common way to access some data in an array is by its index.\nJust like many other languages index start at <code>0</code>, so the first element in the list is at index <code>0</code>.</p>\n<pre><code class=\"powershell\"># access the 1st element in an array\n$myArray[0]\n## access the 3rd element in an array\n$myArray[2]\n</code></pre>\n\n<h3>Multiple Elements</h3>\n<p>A comma seperated list of indexes can be provided to access multiple elements in an array:</p>\n<pre><code class=\"powershell\">$myArray = @(1,2,3)\n# access the 1st and 3rd elements \n$myArray[0,2]\n</code></pre>\n\n<h4>Ranges</h4>\n<p>Multiple elements can be accessed from an array as a range.\nFor example you can access elements 1 to 3 (0,1,2):</p>\n<pre><code class=\"powershell\">$myArray = @(1,2,3)\n$myArray[0..2]\n</code></pre>\n\n<p>A range and specific indexes can be access by adding <code>+</code>:</p>\n<pre><code class=\"powershell\">$myArray = @(1,2,3,4,5,6,7,8)\n# access the 1st and 3rd elements, also access elements at index 4 to 7\n$myArray[0,2+4..7]\n</code></pre>\n\n<h3>Last Element</h3>\n<p>The last element of an array can be accessed by using <code>-1</code> as the index:</p>\n<pre><code class=\"powershell\">$myArray = @(1,2,3,4,5,6,7,8)\n# show only the last element (8)\n$myArray[-1]\n</code></pre>\n\n<p>You can think of <code>-1</code> as a \"special\" index for getting the last element - all other indexes must be a postive number, for instance <code>-5</code> wouldn't work.</p>\n<h3>Multi Dimensional</h3>\n<p>Access to elements in multi dimentional arrays work pretty much the same as when you are accessing regular arrays.\nWe can use two sets of brackets <code>[][]</code> for specifying which elements we would like:</p>\n<pre><code class=\"powershell\">$people = @(\n    (&quot;Bob&quot;,23,&quot;Manchester&quot;),\n    (&quot;Jay&quot;,27,&quot;San Francisco&quot;)\n)\n# Bob\n$people[0][0]\n# 23\n$people[0][1]\n# Manchester\n$people[0][2]\n# Jay\n$people[1][0]\n# 27\n$people[1][1]\n# San Franciso\n$people[1][2]\n</code></pre>\n\n<p>The easiest way to think of this is like you are accessing an array inside of another array.\nYou specify which array with the first index and then which element inside of that sub array that you want.\nBased on the example above here is a table showing which indexes get which elements in the array:</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>0</th>\n<th>1</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>0</td>\n<td>Bob (<code>[0][0]</code>)</td>\n<td>Jay (<code>[1][0]</code>)</td>\n</tr>\n<tr>\n<td>1</td>\n<td>23 (<code>[0][1]</code>)</td>\n<td>27 (<code>[1][1]</code>)</td>\n</tr>\n<tr>\n<td>2</td>\n<td>Manchester (<code>[0][2]</code>)</td>\n<td>San Francisco (<code>[1][2]</code>)</td>\n</tr>\n</tbody>\n</table>\n<h2>Add Array Elements</h2>\n<p>There are of scenarios where the array has been created but we still intend to added more elements.</p>\n<h3>Append to An Array</h3>\n<p>Elements can be appended to an array using the <code>+=</code> operator:</p>\n<pre><code class=\"powershell\">$myArray = 1,2,3\n$myArray += 4\n</code></pre>\n\n<h2>Change Array Elements</h2>\n<p>Once an array has been created we are still able to amend any of the elements in the list by specifying the index:</p>\n<pre><code class=\"powershell\">$myArray = 1,2,3\n# change the value of the 1st element in the array\n$myArray[0] = 10\n</code></pre>\n\n<h2>Tasks</h2>\n<p>This set of tasks is split up into a couple of sections, managing log files with arrays and the second task is to read in a comma seperated values CSV file and display it as a table using multi dimentional arrays.</p>\n<h3>Log Files</h3>\n<p>In this section we are going to be making a script that can:\n- Read a folder full of log files\n- Compress the 3 latest log files into a zip archive</p>\n<p>Start by creating a file in this module folder called <code>last-3-log-files.ps1</code>.</p>\n<h4>Getting the Log Files</h4>\n<p>The log files are stored in the <code>logs</code> folder on this module, for purpose of this exercise they are actually empty but named with a date.</p>\n<p>We will need a list of the log file names before we can start figuring out which are the 3 latest:</p>\n<pre><code class=\"powershell\">$logFiles = Get-ChildItem &quot;logs&quot; -Filter *.log\n</code></pre>\n\n<p>The log file names will actually be in ascending order by default, we can reverse this to make it easier for us to get the latest 3:</p>\n<pre><code class=\"powershell\">$logFiles = Get-ChildItem &quot;logs&quot; -Filter *.log\n[Array]::Reverse($logFiles)\n</code></pre>\n\n<h4>Last 3 Log File Paths</h4>\n<p>The paths for the log files that we want to compress need to be aquired.\nWe can iterate over the log files, only selecting the first three using a ranged selection.\nWhen we are iterating over this list, we can collect the <code>FullName</code> property which is the full path to the log file, and store it in another list:</p>\n<pre><code class=\"powershell\">$logFiles = Get-ChildItem &quot;logs&quot; -Filter *.log\n[Array]::Reverse($logFiles)\n$logFilePaths = @()\nForEach ($logFile in $logFiles[0..2]) {\n    $logFilePaths += $logFile.FullName\n}\n</code></pre>\n\n<h4>Compress the Log Files</h4>\n<p>Now we know which files to compress we can compress them into an archive using the <code>Compress-Archive</code> command.\nA zip file called <code>logs.zip</code> will now be created:</p>\n<pre><code class=\"powershell\">$logFiles = Get-ChildItem &quot;logs&quot; -Filter *.log\n[Array]::Reverse($logFiles)\n$logFilePaths = @()\nForEach ($logFile in $logFiles[0..2]) {\n    $logFilePaths += $logFile.FullName\n}\n$compress = @{\n    Path=$logFilePaths\n    CompressionLevel = &quot;Optimal&quot;\n    DestinationPath = &quot;logs.zip&quot;\n}\nCompress-Archive @compress\n</code></pre>\n\n<h3>CSV Table</h3>\n<p>There is a file called <code>scores.csv</code> which contains some results for test takers.\nThis section includes some heavy use of loops in PowerShell, don't worry if you don't quite understand these at this point, just know that we are using loops to traverse through the arrays, processing each element one at a time.</p>\n<p>Start this section by creating a file in this module folder called <code>csv-scores-table.ps1</code>.</p>\n<h4>Read in the CSV File</h4>\n<p>The contents of the CSV can be obtained by using the <code>Get-Content</code> command:</p>\n<pre><code class=\"powershell\">$contents = Get-Content scores.csv\n</code></pre>\n\n<h4>Create a Multi Dimensional Array from the CSV</h4>\n<p>To create a multi dimensional array from the contents we can read the contents line by line and seperate them into columns and rows:</p>\n<pre><code class=\"powershell\">$contents = Get-Content scores.csv\n$rows = @()\nForEach ($line in $contents) {\n    $columns = $line -split &quot;,&quot;\n    $rows += , $columns\n}\n</code></pre>\n\n<p>Notice the way that <code>$columns</code> is being appended to <code>$rows</code>; a comma has been included to say explicity that we want to append the <code>columns</code> variable to <code>$rows</code> as an array:</p>\n<pre><code class=\"powershell\">$rows += , $columns\n</code></pre>\n\n<h4>Iterate the Multi Dimentional Array</h4>\n<p>Now the information is sorted in a multi dimensional array, a loop can be used to iterate through it and print out the values in a basic format for a table:</p>\n<pre><code class=\"powershell\">$contents = Get-Content scores.csv\n$rows = @()\nForEach ($line in $contents) {\n    $columns = $line -split &quot;,&quot;\n    $rows += , $columns\n}\nFor ($row=0;$row -lt $rows.Length;$row++) {\n    &quot;==============&quot;\n    $output = &quot;&quot;\n    For ($column=0; $column -lt $rows[0].Length;$column++) {\n        $output += &quot;$($rows[$row][$column]) | &quot;\n    }\n    $output\n}\n</code></pre>\n\n<p>The ouput should look something like this:</p>\n<pre><code class=\"text\">==============\nName | Score |\n==============\nBob | 80% |\n==============\nJay | 85% |\n==============\nJohn | 80% |\n==============\nTadas | 85% |\n</code></pre>"}, {"gitUri": "topics/powershell/modules/navigation", "overview": "Knowing how to navigate a file system with PowerShell, Command Prompt or Bash is important for being able to automate tasks with their respective scripting languages.", "name": "Navigation", "resourceName": "powershell/navigation", "content": "<h1>Navigation</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#working-directory\">Working Directory</a></li>\n<li><a href=\"#showing-directory-contents\">Showing Directory Contents</a><ul>\n<li><a href=\"#ls-command\"><code>ls</code> command</a><ul>\n<li><a href=\"#output\">Output</a></li>\n</ul>\n</li>\n<li><a href=\"#dir-command\"><code>dir</code> command</a><ul>\n<li><a href=\"#output-1\">Output</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href=\"#changing-the-current-working-directory\">Changing the Current Working Directory</a></li>\n<li><a href=\"#path-names\">Path Names</a><ul>\n<li><a href=\"#path-ending-with-a-folder\">Path Ending with a Folder</a></li>\n<li><a href=\"#path-ending-with-a-file\">Path Ending with a File</a></li>\n<li><a href=\"#absolute-path\">Absolute Path</a><ul>\n<li><a href=\"#windows\">Windows</a></li>\n<li><a href=\"#linux\">Linux</a></li>\n</ul>\n</li>\n<li><a href=\"#relative-paths\">Relative Paths</a></li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#change-to-your-home-directory\">Change to Your Home Directory</a></li>\n<li><a href=\"#make-some-folders\">Make Some Folders</a></li>\n<li><a href=\"#change-into-folder-2\">Change into Folder <code>2</code></a></li>\n<li><a href=\"#change-into-folder-b\">Change into Folder <code>b</code></a></li>\n<li><a href=\"#clean-up\">Clean Up</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>Knowing how to navigate a file system with PowerShell, Command Prompt or Bash is important for being able to automate tasks with their respective scripting languages.\nFortunately the commands are very similar for all of these applications when it comes to navigation.\nUsing an interactive console is the easiest way to start learning navigation in PowerShell.</p>\n<h2>Working Directory</h2>\n<p>Whenever you are in an interactive console or running a script with PowerShell, each session has something called a working directory.</p>\n<p>Knowing what the working directory can be very important, especially when accessing files.\nThe current working directory is usually shown before the cursor in a console. If you cannot see this and you aren't running a script, you may view your current working directory by running the Print Working Directory command:</p>\n<pre><code class=\"powershell\">pwd\n</code></pre>\n\n<h2>Showing Directory Contents</h2>\n<p>To view the contents of a directory you can use either of these commands:</p>\n<h3><code>ls</code> command</h3>\n<p><code>ls</code> will provide you with a simple list of the files and folders in your current working directory:</p>\n<pre><code class=\"powershell\">ls\n</code></pre>\n\n<h4>Output</h4>\n<pre><code class=\"text\">PS /home/bob/projects/github.com/bob-crutchley/notes&gt; ls\nautomation   courses              pip_dependencies  state.json  venv\n_config.yml  packages-microsoft-prod.deb  README.md     topics\n</code></pre>\n\n<h3><code>dir</code> command</h3>\n<p><code>dir</code> can be executed to show the current contents of your working directory with some information about the files:</p>\n<pre><code class=\"powershell\">dir\n</code></pre>\n\n<h4>Output</h4>\n<pre><code class=\"text\">PS /home/bob/projects/github.com/bob-crutchley/notes&gt; ls -al\ntotal 76\ndrwxr-xr-x  9 bob bob  4096 Sep 16 14:44 .\ndrwxr-xr-x 11 bob bob  4096 Sep 13 11:45 ..\ndrwxr-xr-x  3 bob bob  4096 Sep  2 10:44 automation\ndrwxr-xr-x  2 bob bob  4096 Sep  2 09:24 .circleci\n-rw-r--r--  1 bob bob    25 Sep  2 09:24 _config.yml\ndrwxr-xr-x  3 bob bob  4096 Sep  2 09:24 courses\ndrwxr-xr-x  8 bob bob  4096 Sep 16 14:43 .git\ndrwxr-xr-x  3 bob bob  4096 Aug 30 09:21 .github\n-rw-r--r--  1 bob bob    34 Aug 30 09:21 .gitignore\n-rw-r--r--  1 bob bob  2452 Nov 27  2017 packages-microsoft-prod.deb\n-rw-r--r--  1 bob bob    15 Aug 30 09:21 pip_dependencies\n-rw-r--r--  1 bob bob  3658 Aug 30 09:21 README.md\n-rw-r--r--  1 bob bob 19762 Sep 16 14:39 state.json\ndrwxr-xr-x 16 bob bob  4096 Sep 16 14:39 topics\ndrwxr-xr-x  5 bob bob  4096 Aug 30 14:42 venv\n</code></pre>\n\n<h2>Changing the Current Working Directory</h2>\n<p>The working directory can be changed by using the Change Directory (<code>cd</code>) command:</p>\n<pre><code class=\"powershell\">cd folder_name\n</code></pre>\n\n<h2>Path Names</h2>\n<p>A path is an ordered list of directories on on a file system which describe the location of a file or folder. This list of directories is delimited with a backslash (<code>\\</code>) on Windows and a forward slash (<code>/</code>) on Linux.</p>\n<h3>Path Ending with a Folder</h3>\n<pre><code class=\"text\">C:\\Users\\bob\n</code></pre>\n\n<h3>Path Ending with a File</h3>\n<pre><code class=\"text\">C:\\Users\\bob\\readme.txt\n</code></pre>\n\n<h3>Absolute Path</h3>\n<p>An absolute path specifies the location of a file or folder by providing the <strong>full path</strong> i.e. every directory from the top of the filesystem down to the object in question.\nOn Windows, you must specify the drive letter (Default primary drive is <code>C:</code>) at the start of the path.\nLinux has a very different file system to Windows - you only need to start the path with a forward slash (<code>/</code>) to get to the root of the file system.\nBelow are examples of absolute paths to the hosts file on both Windows and Linux.</p>\n<h4>Windows</h4>\n<pre><code class=\"text\">C:\\Windows\\System32\\drivers\\etc\\hosts\n</code></pre>\n\n<h4>Linux</h4>\n<pre><code class=\"text\">/etc/hosts\n</code></pre>\n\n<h3>Relative Paths</h3>\n<p>Accessing the absolute path for all files can be tedious work. Relative paths make it possible to access files and folders that are relative to your current location in the file system (your working directory).\nFor example, if you were in the <code>C:\\Windows\\System32\\drivers</code> folder on Windows, we would only need to execute the following command to get into the <code>C:\\Windows\\System32\\drivers\\etc folder</code>:</p>\n<pre><code class=\"powershell\">cd etc\n</code></pre>\n\n<p>The current working directory that you are in and the relative path that is specified in the command are added together; resolving to the absolute path of the file or folder.</p>\n<p>Relative paths are especially useful if you are needing to reference a directory that is \u201cbackwards\u201d in the filesystem.\nYou can accomplish this by using <code>..</code> as the relative path:</p>\n<pre><code class=\"powershell\">cd ..\n</code></pre>\n\n<p><code>..</code> just means \u201cone directory up\u201d, and we can use it alongside other folders as well.\nFor instance if there were two folders:\n- <code>C:\\Users\\bob\\folder_1</code>\n- <code>C:\\Users\\bob\\folder_2</code>\nAnd the current working directory was in the first folder (<code>C:\\Users\\bob\\folder_1</code>)\nWe can change into the second folder by using a relative path:</p>\n<pre><code class=\"powershell\">cd ..\\folder_2\n</code></pre>\n\n<h2>Tasks</h2>\n<h3>Change to Your Home Directory</h3>\n<p>Make sure that you are in your home directory by running the following command:</p>\n<pre><code class=\"powershell\">cd $home\n</code></pre>\n\n<h3>Make Some Folders</h3>\n<p>We'll be using a new command here to create some folders for us to navigate through:</p>\n<pre><code class=\"powershell\">New-Item -ItemType Directory -Path $home/powershell-navigation/1/2\nNew-Item -ItemType Directory -Path $home/powershell-navigation/a/b\n</code></pre>\n\n<p>After running those commands we will have the following directory structure:</p>\n<pre><code class=\"text\">powershell-navigation/\n\u251c\u2500\u2500 1\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 2\n\u2514\u2500\u2500 a\n    \u2514\u2500\u2500 b\n</code></pre>\n\n<h3>Change into Folder <code>2</code></h3>\n<p>The <code>cd</code> command can be used to change the directory into folder 2:</p>\n<pre><code class=\"powershell\">cd powershell-navigation/1/2\n</code></pre>\n\n<p>Our current working directory can now be confirmed by running <code>pwd</code>.</p>\n<h3>Change into Folder <code>b</code></h3>\n<p>One of the better ways to change to folder <code>b</code> from our current working directory is by using mor relative paths:</p>\n<pre><code class=\"powershell\">cd ../../a/b\n</code></pre>\n\n<p>We can check out working directory again now with <code>pwd</code>.</p>\n<h3>Clean Up</h3>\n<p>Let's change back to our home directory and delete the folders that were created to clean up.</p>\n<pre><code class=\"powershell\">cd $home\nRemove-Item -Recurse $home/powershell-navigation\n</code></pre>"}, {"gitUri": "topics/powershell/modules/environment-variables", "overview": "PowerShell has the ability to set and access system environment variables.", "name": "Environment Variables", "resourceName": "powershell/environment-variables", "content": "<h1>Environment Variables</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#access-types\">Access Types</a><ul>\n<li><a href=\"#which-access-type-and-when\">Which Access Type and When?</a><ul>\n<li><a href=\"#example-scenario\">Example Scenario</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href=\"#accessing-an-environment-variable\">Accessing an Environment Variable</a></li>\n<li><a href=\"#assigning-environment-variables\">Assigning Environment Variables</a><ul>\n<li><a href=\"#process-level-assignment\">Process Level Assignment</a></li>\n<li><a href=\"#user--system-level-assignment\">User &amp; System Level Assignment</a><ul>\n<li><a href=\"#user-level-example\">User Level Example</a></li>\n<li><a href=\"#system-level-example\">System Level Example</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href=\"#unassign-environment-variables\">Unassign Environment Variables</a><ul>\n<li><a href=\"#unassign-process-level-environment-variable\">Unassign Process Level Environment Variable</a></li>\n<li><a href=\"#unassign-user-level-environment-variable\">Unassign User Level Environment Variable</a></li>\n<li><a href=\"#unassign-system-level-environment-variable\">Unassign System Level Environment Variable</a></li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#process-level-assignment-1\">Process Level Assignment</a></li>\n<li><a href=\"#user--system-level-assignment-1\">User &amp; System Level Assignment</a><ul>\n<li><a href=\"#user-level\">User Level</a></li>\n<li><a href=\"#system-level\">System Level</a></li>\n</ul>\n</li>\n<li><a href=\"#viewing-system--user-level-environment-variables-on-windows\">Viewing System &amp; User Level Environment Variables on Windows</a></li>\n<li><a href=\"#unassign-the-environment-variables\">Unassign the Environment Variables</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>PowerShell has the ability to set and access system environment variables.\nEnvironment variables are just like normal variables, except they are configured outside of applications.\nThis gives us the ability to program applications more generically, as opposed to hard-coding the values that we want into the program itself.</p>\n<h2>Access Types</h2>\n<p>Environment variables differ from regular variables, because they are not subjected to scope like regular variables are.\nHowever, there are different access types that you can set on an environment variable, which affects access to it.</p>\n<table>\n<thead>\n<tr>\n<th>Access Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Process</td>\n<td>The current PowerShell session and any applications started within it will be able to access the variable. Environment variables at this level can be thought of as temporary; when the process stops or the system restarts, the variable will no longer exist.</td>\n</tr>\n<tr>\n<td>User</td>\n<td>Any applications being run by the same system user will be able to access the variable. The variable is persisted and will still be accessible after a reboot.</td>\n</tr>\n<tr>\n<td>System</td>\n<td>Access is allowed across the entire system, and the variable will remain after a restart. Only administrators can modify these variables.</td>\n</tr>\n</tbody>\n</table>\n<h3>Which Access Type and When?</h3>\n<p>Deciding on which access type to use can get fairly subjective; however, if you consider the scopes for the variables, it isn't too hard to figure out. Try answering the following question in order to decide what scope to use: does it need to be accessible at this scope?</p>\n<h4>Example Scenario</h4>\n<p>Let's consider the following scenario as an example:\n- Deploying an application server that needs a database connection passed in as an environment variable\n- Application server executable is run by the <code>app</code> user\n- The application is executed as a service (a background process that is not started by a PowerShell session)</p>\n<p>From this information, we can see that a System environment variable is not a good option here. This is because only the <code>app</code> user needs access to the value stored in that environment variable.\nA better scenario to have the envinronment variable as a System access type would be if every user on the system needed to be able to access the same variable. </p>\n<p>We can't really use a Process level environment variable because the application is executed as a service, so not executed by a PowerShell session.</p>\n<p>This leaves us with the User level, which will mean that any process running as the <code>app</code> user will have access to this variable.\nThis will work with the application being executed as a service.</p>\n<h2>Accessing an Environment Variable</h2>\n<p>Environment variables can be accessed in PowerShell by using <code>$env:</code> and the name of the environment variable:</p>\n<pre><code class=\"powershell\">echo $env:HOMEPATH\n</code></pre>\n\n<p>All the types of environment variables we have discussed are accessed in the same way.\nThe access level will only change whether they are accessible or not.</p>\n<p>When setting an environment variable that is either for <code>User</code> or <code>System</code> level, you will need to restart the PowerShell session before you will be able to access it.</p>\n<h2>Assigning Environment Variables</h2>\n<p>There are a couple of ways to assign an environment variable, depending on what access type is going to be needed.</p>\n<h3>Process Level Assignment</h3>\n<p>You can use <code>$env</code> to assign a process level environment variable:</p>\n<pre><code class=\"powershell\">$env:TEST_VARIABLE = \u201ctest variable value\u201d\n</code></pre>\n\n<h3>User &amp; System Level Assignment</h3>\n<p>User and System level environment variable assigment will need to be configured by leveraging the .NET framework that PowerShell has access to.\nThis works by accessing the <code>SetEnvironmentVariable</code> method from the <code>System.Environment</code> class.\nWe can pass this method the variable <code>name</code>, <code>value</code> and the <code>type</code>.</p>\n<h4>User Level Example</h4>\n<pre><code class=\"powershell\">[System.Environment]::SetEnvironmentVariable(&quot;TEST_VARIABLE&quot;, &quot;test variable&quot;, &quot;User&quot;)\n</code></pre>\n\n<h4>System Level Example</h4>\n<p>System-wide environment variables can be provided by using the <code>Machine</code> type, which seems a bit ambiguous considering it's for a System environment variable.\nRemember, when you are setting a System environment variable, you will need have a PowerShell session opened as an administrator on Windows.\nYou could try running the example shown here in a non-administritive PowerShell session first to see the error, then try running it in an administrivtive PowerShell window:</p>\n<pre><code class=\"powershell\">[System.Environment]::SetEnvironmentVariable(&quot;TEST_VARIABLE&quot;, &quot;test variable&quot;, &quot;Machine&quot;)\n</code></pre>\n\n<h2>Unassign Environment Variables</h2>\n<p>Variables can be unassigned by setting them to be <code>$null</code>.\nSo, to unassign a variable, you just assign <code>$null</code> to it.\nSome examples have been included in this section for extra clarification.</p>\n<h3>Unassign Process Level Environment Variable</h3>\n<pre><code class=\"powershell\">$env:TEST_VARIABLE = $null\n</code></pre>\n\n<h3>Unassign User Level Environment Variable</h3>\n<pre><code class=\"powershell\">[System.Environment]::SetEnvironmentVariable(&quot;TEST_VARIABLE&quot;, $null, &quot;User&quot;)\n</code></pre>\n\n<h3>Unassign System Level Environment Variable</h3>\n<pre><code class=\"powershell\">[System.Environment]::SetEnvironmentVariable(&quot;TEST_VARIABLE&quot;, $null, &quot;Machine&quot;)\n</code></pre>\n\n<h2>Tasks</h2>\n<p>Although PowerShell can be used on other systems like Linux, these exercises are best suited on a Windows machine. This is so that you can see the the different access types working correctly.\nYou will find that only process environment variables seem to work correctly on Linux.</p>\n<h3>Process Level Assignment</h3>\n<p>Let's set a process level environment variable called <code>TEST_PROCESS_VARIABLE</code>, with a value of <code>test process variable</code>:</p>\n<pre><code class=\"powershell\">$env:TEST_PROCESS_VARIABLE = \u201ctest process variable\u201d\n</code></pre>\n\n<p>We can now check that the variable has been assigned correctly by accessing it:</p>\n<pre><code class=\"powershell\">echo $env:TEST_PROCESS_VARIABLE\n</code></pre>\n\n<h3>User &amp; System Level Assignment</h3>\n<p>Now we can assign simliar variables, but on a <code>User</code> and <code>System</code> level, by using PowerShell's .NET capabilities.</p>\n<h4>User Level</h4>\n<pre><code class=\"powershell\">[System.Environment]::SetEnvironmentVariable(&quot;TEST_USER_VARIABLE&quot;, &quot;test user variable&quot;, &quot;User&quot;)\n# restart your powershell session\necho $env:TEST_USER_VARIABLE\n</code></pre>\n\n<h4>System Level</h4>\n<pre><code class=\"powershell\">[System.Environment]::SetEnvironmentVariable(&quot;TEST_SYSTEM_VARIABLE&quot;, &quot;test system variable&quot;, &quot;Machine&quot;)\n# restart your powershell session\necho $env:TEST_SYSTEM_VARIABLE\n</code></pre>\n\n<h3>Viewing System &amp; User Level Environment Variables on Windows</h3>\n<p>Specifically for Windows, we are able to view the System and User environment variables that have been assigned.</p>\n<p>A common way to open the Environment Variables window is by navigating through these steps:\n- Right click on the Start Menu \n- Select Control Panel\n- Select System\n- Select Advanced System Settings\n- Select Environment Variables</p>\n<p>The fastest way we can get to the Environment Variables open, for the purpose of this exercise, is by using the Window Run application to open it:\n- Press <code>Windows key</code> and <code>R</code> on you keyboard to open the run window\n- Enter the following and select ok: <code>rundll32.exe sysdm.cpl,EditEnvironmentVariables</code>:</p>\n<p><img alt=\"Windows Run Environment Variables\" src=\"https://lh3.googleusercontent.com/McdTfOGpJ8oPdFGQqcXbIrwo7EpatdsRPeSHFQkGOgeAlzjZ7GR_sl4JtO3_cHNPwUdmxIirbDVc4Zumy8Bcy5ofaz6nlKtGjKZZVujecS203-GlDrkBNBzDaMg38zo0zxxCYP7DgvM6SOyUsg97zjK5aosQMV1hWCIS5ZRBnooQaF6f2o3RGade-p36wUjCI9i_Ghk6fQ0ICa55HilYcHagIHWtmpj7dzmc23lvtWtr2Wib7RPdsGho-omxeP7gVUyAGcJBxuL1iHusAxN1zTg9HPdHdaYkhcnPJM_URDGBHq97AWhsDWqv0Be3oQCs9P4B17-dGHbxjpY-6n-fjilnuNWC-4zh5Tsc8PlINsg-r4lUC6DIRhwA5EQa-aikrCJGuZLlevVEWdo6CUupfHdbxI8ug12rdicr9Bjv6GjvxHFTtyBz-Vhx-klYfPGSc50riuNkE1kZngvfvMoa2Wuo3uCJlA4Lj13d4sydfJKv8EpXuPwtZowocbLik_ZmOzfE6RKd0yKw1SCEskai19_KvT-T-v7WMmqQ1ieFc4UyshYY2meuhBLDc2G_QYWgqvTq_ZB6I12bxNSQSVgJFxge3rYAG7iASJzDHl0T2ETGw5HRi_hxrb4o84ahDbhxUG1olnmuRPJbXbW3tbSqNdMF247AVsiTvwI8xbrxodlPhZUZSb9CURHpuiKRBYX9TKaMnZxL7xqwpfWKHVFQaexKFLDUBdSE8vCZ5LlvgAC4sFpP=w408-h223-no\" /></p>\n<p>You should now have the Environment Variables window open.\nThe <code>TEST_USER_VARIABLE</code> and <code>TEST_SYSTEM_VARIABLE</code> environment variables should also be visible:</p>\n<p><img alt=\"Windows Environment Variable Window\" src=\"https://lh3.googleusercontent.com/CZcMmNjbj8P8GPe0yzmhSQJ_0Q4fJzxeWnURhMWiEe-oFHuJ12B9Pm3j84Y4qnToWqdFmVoFVKp0V9M0bema3xtWkYEBepbUoxRErf_hKYuXYEmZ3r-o_1Y6HiXyfoIE5yQZ0SO5gwQ4AscZpuHJBe7iWXFHSo8WfS7zNPi4dkpj_KFDIRSqxfgzUfn7vyC_W2af0vrMstPJlrmn91ynSCUZNJRQM0ebAhR569dh4qEIaOJU5FawdDf90ZaYtSdhoHvnJ5MNJEtkW4G3AGEoDUEZX5d0Ikl5g9ZOqWGNBiKmSiEADR309w6ZFoZXx-CHfsau-NvyhRTRCjC12KYy3-_HIigYJRM7cDP_vOnnldydTySRV8rQn7UpEB0gZBwDaLqUi4T1crbQuCBdtPOy0dgcFVyASx9M_ZnTg6wLpqLDHzm1lOv7OGtdLXGfmj5srnbgf_6X1oPxMNw3yJPJQvarZKm0KzA7i4pexZ3ghO7q_bAbtqSBcyGHbYnktwDYo-ubLmNaUzJSa0gG9k-NBqfavosnOICC82ME9OGod6TeC5HcqIva-A203x4Yl9eyfvWk2fNG-fkZjV2M6ogt-XFGQ4yZkAARfgDhx3Uxrvunxo13vn1T366f0MhRzru3f4T8XdngZ954b5huXYTFGT2bSZ6OIOm-rGipej9WSRHcITKdBFEyR9RFdmhElJxkt6nbzN0lTxBSX1aD8JCimWomLi4MLJtWGM-uudy1ZYp7AgDY=w376-h427-no\" /></p>\n<h3>Unassign the Environment Variables</h3>\n<p>The variables created in this task can be unassignd by setting their values to <code>$null</code>:</p>\n<pre><code class=\"powershell\">[System.Environment]::SetEnvironmentVariable(&quot;TEST_USER_VARIABLE&quot;, $null, &quot;User&quot;)\n[System.Environment]::SetEnvironmentVariable(&quot;TEST_SYSTEM_VARIABLE&quot;, $null, &quot;Machine&quot;)\n</code></pre>"}, {"gitUri": "topics/powershell/modules/conditional-statements", "overview": "Conditional statements in PowerShell enable scripts to make decisions based on provided conditions.", "name": "Conditional Statements", "resourceName": "powershell/conditional-statements", "content": "<h1>Conditional Statements</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#if-else--elseif-statements\"><code>if</code>, <code>else</code> &amp; <code>elseif</code> Statements</a><ul>\n<li><a href=\"#if\"><code>if</code></a></li>\n<li><a href=\"#else\"><code>else</code></a></li>\n<li><a href=\"#elseif\"><code>elseif</code></a></li>\n<li><a href=\"#nesting-statements\">Nesting Statements</a></li>\n</ul>\n</li>\n<li><a href=\"#switch-statement\"><code>switch</code> Statement</a><ul>\n<li><a href=\"#example\">Example</a></li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#obtain-the-user-input\">Obtain the User Input</a></li>\n<li><a href=\"#calculate-the-users-input-with-if-else--elseif\">Calculate the User's Input with <code>if</code>, <code>else</code> &amp; <code>elseif</code></a></li>\n<li><a href=\"#calculate-the-users-input-with-a-switch-statment\">Calculate the User's Input with a <code>switch</code> Statment</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>Conditional statements in PowerShell enable scripts to make decisions based on provided conditions.\nPowerShell is like many other languages; it uses <code>if</code>, <code>else</code>, <code>elseif</code> and <code>switch</code> statements.\nConditions are evaluated to a boolean value (True or False).</p>\n<h2><code>if</code>, <code>else</code> &amp; <code>elseif</code> Statements</h2>\n<h3><code>if</code></h3>\n<p>The <code>if</code> statement can be used to execute statements based on whether the provided condition is true or not:</p>\n<pre><code class=\"powershell\">if (true) {\n    echo &quot;this statement will execute because the condition is true&quot;\n}\nif (false) {\n    echo &quot;this statement will not execute because the condition is not true&quot;\n}\n</code></pre>\n\n<h3><code>else</code></h3>\n<p>The <code>else</code> statement can be used in conjunction with the <code>if</code> statement, to provide a block of statements to run if the <code>if</code> condition is not met:</p>\n<pre><code class=\"powershell\">if (false) {\n    echo &quot;this statement will not run&quot;\n} else {\n    echo &quot;this statement will run, because the 'if' condition was not met&quot;\n}\n</code></pre>\n\n<h3><code>elseif</code></h3>\n<p>Using <code>elseif</code> will help if there's more than one condition that you're going to need to check.\nYou can have as many <code>elseif</code> statements as you like, but if you start getting many more than 2 or 3, for instance, you should consider using a <code>switch</code> statement.</p>\n<pre><code class=\"powershell\">if (false) {\n    echo &quot;this statement will not run&quot;\n} elseif (true) { echo &quot;this statement will run&quot; } else {\n    echo &quot;this statement will not run because the 'ifelse' condition was met&quot;\n}\n</code></pre>\n\n<h3>Nesting Statements</h3>\n<p>These statements can, of course, be nested. However, be cautious when doing this, as having lots of nested statements can be very detrimental to the readability of the code:</p>\n<pre><code class=\"powershell\">if (true) {\n    echo &quot;this statement will run&quot;\n    if (false) {\n        echo &quot;this statement won't run&quot;\n    } else {\n        echo &quot;this statement will run&quot;\n    }\n}\n</code></pre>\n\n<h2><code>switch</code> Statement</h2>\n<p>The <code>switch</code> statement is more appropriate to use when you want to test equality; for instance, checking if a given value eqauls something specific.</p>\n<h3>Example</h3>\n<p>The example shown below will ask the user for a number between 1 and 3. Once a number has been selected, <code>\"You selected [NUMBER]\"</code> will be printed to the terminal.\nIf a number between 1 and 3 isn't entered then <code>\"You didn't select a number between 1 and 3\"</code> will be displayed on the terminal.</p>\n<pre><code class=\"powershell\">switch (Read-Host &quot;Pick a number between 1 and 3&quot;) {\n    1 {&quot;You selected 1&quot;; break}\n    2 {&quot;You selected 2&quot;; break}\n    3 {&quot;You selected 3&quot;; break}\n    default {&quot;You didn't select a number between 1 and 3&quot;}\n}\n</code></pre>\n\n<p>For each statement, the first number on the line is being checked against what was provided in the <code>Read-Host</code> statement.\nIf the number matches, the block between the brances <code>{}</code> will be executed.</p>\n<p>If a match is found, the switch statement will still continue to check the other statements, unless a <code>break</code> statement is issued.</p>\n<p>Should none of the statements match, the <code>default</code> block will be executed.</p>\n<h2>Tasks</h2>\n<p>This set of tasks will show you how <code>if</code>, <code>else</code>, <code>elseif</code> and <code>switch</code> statements can be applied to a simple PowerShell script.</p>\n<p>The PowerShell script will figure out how much someone weighs on another planet:\n- User input for the weight\n- User input for selecting which Planet\n- Multiply the relative gravity by the weight and output it</p>\n<h3>Obtain the User Input</h3>\n<p>Create a script called <code>space-weight.ps1</code> and enter the following to gain the user input for the <code>weight</code> and the <code>planetNumber</code> to change the weight to.\nThe unit of weight can be obtained as well, just to make the output at the end a little nicer:</p>\n<pre><code class=\"powershell\">$unit = Read-Host &quot;What is the unit of weight? (KG/lbs)&quot;\n$weight = Read-Host &quot;Please enter a weight: &quot;\n$planetNumber = Read-Host &quot;\nWhich planet would you like to know how much this weighs on?\n   1. Venus   2. Mars    3. Jupiter\n   4. Saturn  5. Uranus  6. Neptune\n&quot;\n</code></pre>\n\n<h3>Calculate the User's Input with <code>if</code>, <code>else</code> &amp; <code>elseif</code></h3>\n<p>Using the <code>weight</code> and <code>planetNumber</code> variables, we can now figure out what weight it is going to be.</p>\n<p>Here, we are going to add <code>if</code> and <code>elseif</code> statements, to figure out which Planet the user selected, and then we will multiply the weight by the relative gravity for the Planet.\nIf the user selects a number from the list that doesn't exist then this can be caught in an <code>else</code> statement, to inform the user that they have made an  invalid selection:</p>\n<pre><code class=\"powershell\"># user input\n$unit = Read-Host &quot;What is the unit of weight? (KG/lbs)&quot;\n$weight = Read-Host &quot;Please enter a weight&quot;\n$planetNumber = Read-Host &quot;\nWhich planet would you like to know how much this weighs on?\n   1. Venus   2. Mars    3. Jupiter\n   4. Saturn  5. Uranus  6. Neptune\n&quot;\n# calculate the user's input\nif ($planetNumber -eq 1) {\n    $planetName = &quot;Venus&quot;\n    $weightOnPlanet = [Int]$weight * 0.78\n} elseif ($planetNumber -eq 2) {\n    $planetName = &quot;Mars&quot;\n    $weightOnPlanet = [Int]$weight * 0.39\n} elseif ($planetNumber -eq 3) {\n    $planetName = &quot;Jupiter&quot;\n    $weightOnPlanet = [Int]$weight * 2.65\n} elseif ($planetNumber -eq 4) {\n    $planetName = &quot;Saturn&quot;\n    $weightOnPlanet = [Int]$weight * 1.17\n} elseif ($planetNumber -eq 5) {\n    $planetName = &quot;Uranus&quot;\n    $weightOnPlanet = [Int]$weight * 1.05\n} elseif ($planetNumber -eq 6) {\n    $planetName = &quot;Neptune&quot;\n    $weightOnPlanet = [Int]$weight * 1.23\n} else {\n    echo &quot;Sorry, the planet number: $planetNumber is not recognised&quot;\n    exit\n}\necho &quot;On planet $planetName, $weight $unit would weigh: $weightOnPlanet $unit&quot;\n</code></pre>\n\n<p>Once you have created the script, try running it!</p>\n<pre><code class=\"powershell\">./space-weight.ps1\n</code></pre>\n\n<h3>Calculate the User's Input with a <code>switch</code> Statment</h3>\n<p>The last script will work fine, but it can be cleaned up quite a bit by using a <code>switch</code> statement instead; this will utilise the same logic that was implemented in the <code>if</code>, <code>elseif</code>, <code>else</code> example:</p>\n<pre><code class=\"powershell\"># user input\n$unit = Read-Host &quot;What is the unit of weight? (KG/lbs)&quot;\n$weight = Read-Host &quot;Please enter your weight&quot;\n$planetNumber = Read-Host &quot;\nWhich planet would you like to know how much this weighs on?\n   1. Venus   2. Mars    3. Jupiter\n   4. Saturn  5. Uranus  6. Neptune\n&quot;\n# calculate the user's input\nswitch ($planetNumber) {\n    1 {\n        $planetName = &quot;Venus&quot;\n        $weightOnPlanet = [Int]$weight * 0.78\n        break\n    }\n    2 {\n        $planetName = &quot;Mars&quot;\n        $weightOnPlanet = [Int]$weight * 0.39\n        break\n    }\n    3 {\n        $planetName = &quot;Jupiter&quot;\n        $weightOnPlanet = [Int]$weight * 2.65\n        break\n    }\n    4 {\n        $planetName = &quot;Saturn&quot;\n        $weightOnPlanet = [Int]$weight * 1.17\n        break\n    }\n    5 {\n        $planetName = &quot;Uranus&quot;\n        $weightOnPlanet = [Int]$weight * 1.05\n        break\n    }\n    6 {\n        $planetName = &quot;Neptune&quot;\n        $weightOnPlanet = [Int]$weight * 1.23\n        break\n    }\n    default {\n        echo &quot;Planet Number: $planetNumber is not recognised&quot;\n        exit\n    }\n}\necho &quot;On planet $planetName, $weight $unit would weigh: $weightOnPlanet $unit&quot;\n</code></pre>\n\n<p>Now try running the script again, but with the <code>switch</code> statement implented!</p>"}, {"gitUri": "topics/powershell/modules/comparison-logical-operators", "overview": "PowerShell operators play an important role in PowerShell scripting. Learning to use operators is essential if you want to take your scripting to the next level.", "name": "Comparison and Logical Operators", "resourceName": "powershell/comparison-logical-operators", "content": "<h1>Comparison and Logical Operators</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#comparison-operators\">Comparison Operators</a></li>\n<li><a href=\"#logical-operators\">Logical Operators</a></li>\n<li><a href=\"#use-with-if-and-while-statements\">Use with <code>if</code> and <code>while</code> Statements</a></li>\n<li><a href=\"#tasks\">Tasks</a></li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>PowerShell operators play an important role in PowerShell scripting. Learning to use operators is essential if you want to take your scripting to the next level.</p>\n<p>There are two types of operators we will discuss in this module, Comparison Operators and Logical Operators, and they are typically used in conjunction with <code>if</code> and <code>while</code> statements.</p>\n<h2>Comparison Operators</h2>\n<p>These allow you to specify conditions for comparing values. This is a very common attribute of any programming or scripting language.</p>\n<p>Some of the key comparison operators in PowerShell include:</p>\n<ul>\n<li><code>-eq</code> : equals</li>\n<li><code>-ne</code> : not equals</li>\n<li><code>-gt</code> : greater than</li>\n<li><code>-ge</code> : greater than or equal to</li>\n<li><code>-lt</code> : less than</li>\n<li><code>le</code> : less than or equal to</li>\n</ul>\n<p>All comparison operators are case-insensitive by default. To make them case-sensitive, you would precede the operator with a <code>c</code> (for example, <code>-ceq</code> for equals).</p>\n<p>These operators return a value of <code>True</code> when one or more of the input values is identical to the specified pattern, and <code>False</code> when this isn't the case.</p>\n<p>Some examples are:</p>\n<pre><code class=\"powershell\">PS &gt; 2 -eq 2\nTrue\n</code></pre>\n\n<pre><code class=\"powershell\">PS &gt; 2 -gt 3\nFalse\n</code></pre>\n\n<pre><code class=\"powershell\">PS &gt; &quot;abc&quot; -ne &quot;dfg&quot;\nTrue\n</code></pre>\n\n<pre><code class=\"powershell\">PS &gt; 27 -le 27\nTrue\n</code></pre>\n\n<pre><code class=\"powershell\">PS &gt; &quot;abc&quot; -ne &quot;abc&quot;\nFalse\n</code></pre>\n\n<h2>Logical Operators</h2>\n<p>Logical operators are great because they allow you to check for multiple conditions in one expression.</p>\n<p>Some of the key logical operators in PowerShell include:</p>\n<ul>\n<li><code>-and</code> : <code>True</code> when both statements are <code>True</code></li>\n<li><code>-or</code> : <code>True</code> when either statement is <code>True</code></li>\n<li><code>-xor</code> : <code>True</code> when only one statement is <code>True</code></li>\n<li><code>-not</code> or <code>!</code> : Negates the statement that follows</li>\n</ul>\n<p>The general syntax for this would be:</p>\n<pre><code class=\"powershell\">(condition) (operator) (condition)\n</code></pre>\n\n<p>Some examples of these in action are:</p>\n<pre><code class=\"powershell\">PS &gt; (1 -eq 1) -and (2 -gt 1)\nTrue\n</code></pre>\n\n<pre><code class=\"powershell\">PS &gt; (2 -eq 1) -or (5 -lt 4)\nFalse\n</code></pre>\n\n<pre><code class=\"powershell\">PS &gt; (1 -eq 1) -xor (2 -eq 2)\nFalse\n</code></pre>\n\n<pre><code class=\"powershell\">PS &gt; -not (8 -lt 10)\nFalse\n</code></pre>\n\n<pre><code class=\"powershell\">PS &gt; !(12 -gt 12)\nTrue\n</code></pre>\n\n<h2>Use with <code>if</code> and <code>while</code> Statements</h2>\n<p>The general syntax for using operators with <code>if</code> and <code>while</code> statements is:</p>\n<pre><code class=\"powershell\">(statement) (condition) {command_block}\n</code></pre>\n\n<p>For example:</p>\n<pre><code class=\"powershell\">PS &gt; if (12 -eq 12 -and 28 -lt 30){&quot;This is most definitely True!&quot;}\n</code></pre>\n\n<p>This will check to see if the condition, <code>(12 -eq 12 -and 28 -lt 30)</code> is <code>True</code>. If it is, the code inside the curly brackets will execute. </p>\n<p>In this example, the condition is <code>True</code> (12 is equal to 12 and 28 is less than 30), so <code>This is most definitely True!</code> was displayed on the console.</p>\n<pre><code class=\"powershell\">PS &gt; $val = 0\nwhile ($val -lt 5){\n    $val++\n    Write-Host $val\n}\n</code></pre>\n\n<p>In this example, we firstly set a variable called <code>$var</code> to the value of 0. We then use a <code>while</code> statement, so that the code inside the curly brackets will execute as long as the condition is <code>True</code>.</p>\n<p>The condition in this case is <code>($val -lt 5)</code>. As long as whatever is inside the <code>$val</code> variable is less than 5, the code inside the curly brackets will execute.</p>\n<p>Inside the curly brackets, we write what is stored in the <code>$var</code> variable to the console. Then, we increase the value of <code>$var</code> by 1 (using <code>$var++</code>). So, every time this code block executes, the value of <code>$var</code> will increase by 1.</p>\n<p>Once the value of <code>$var</code> is no longer less than 5, the condition is false and the code inside the curly braces won't execute.</p>\n<h2>Tasks</h2>\n<p>In the PowerShell console:</p>\n<ol>\n<li>Create 3 conditions that evaluate to <code>True</code>.</li>\n<li>Create 3 conditions that evaluate to <code>False</code>.</li>\n<li>Use a logical operator to evaluate 2 conditions at the same time, and have the console display <code>True</code> 3 times and <code>False</code> 3 times.</li>\n<li>Create a simple <code>if</code> statement that evaluates a condition and displays something to the console.</li>\n</ol>"}, {"gitUri": "topics/powershell/modules/variables", "overview": "Variables are a programming concept that has remained consistent across many different programming languages and PowerShell isn\u2019t an exception; a variable is like a container that holds information.", "name": "Variables", "resourceName": "powershell/variables", "content": "<h1>Variables</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#assignment-and-access\">Assignment and Access</a></li>\n<li><a href=\"#data-types\">Data Types</a><ul>\n<li><a href=\"#implicitly-applied-data-types\">Implicitly Applied Data Types</a></li>\n<li><a href=\"#explicitly-applied-data-types\">Explicitly Applied Data Types</a></li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#create-a-simple-string-variable\">Create a Simple String Variable</a></li>\n<li><a href=\"#access-the-name-variable\">Access the <code>name</code> Variable</a></li>\n<li><a href=\"#create-an-integer-variable\">Create an Integer Variable</a></li>\n<li><a href=\"#access-both-the-name-and-age-variables\">Access both the <code>name</code> and <code>age</code> Variables</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>Variables are a programming concept that has remained consistent across many different programming languages and PowerShell isn\u2019t an exception; a variable is like a container that holds information.\nVariables are a great way of storing information that allows us to develop programs that are far more flexible.</p>\n<h2>Assignment and Access</h2>\n<p>In PowerShell, variables are set and accessed by using the dollar character <code>$</code>, which is then followed by the name of the variable.</p>\n<p>Variables can be assigned by using the <code>=</code> character:</p>\n<pre><code class=\"powershell\">$myVariable = &quot;test&quot;\n</code></pre>\n\n<p>Below is an example of the variable contents being accessed by using the echo command:</p>\n<pre><code class=\"powershell\">echo $myVariable\n</code></pre>\n\n<h2>Data Types</h2>\n<p>PowerShell variables use data types, similar to programming languages like C#, Java and Python.\nData types can be explicitly applied to variables. In the event that you don't give a variable a data type, PowerShell will implicitly apply one for you.</p>\n<h3>Implicitly Applied Data Types</h3>\n<p>PowerShell being able to understand a variable's data type implicitly provides the value of less code. For example, if we want a variable of type <code>String</code>, then it could be accomplished by surrounding the value with quotes <code>\u201c\u201d</code>:</p>\n<pre><code class=\"powershell\">$myStringVariable = &quot;powershell will understand that this is a string&quot;\n</code></pre>\n\n<p>Variables of type <code>Integer</code> can be applied by omitting the quotes and setting the value as a number:</p>\n<pre><code class=\"powershell\">$myIntegerVariable = 2\n</code></pre>\n\n<h3>Explicitly Applied Data Types</h3>\n<p>There are often times where we should set the data type for a variable as it allows for functionality which only a specific type has. It also improves the readability of the code.\nFor example, a variable with a type of <code>DateTime</code> will have more functionality built-in to work with dates as opposed to using a <code>String</code>.\nTake this string <code>\u201cFebruary 26, 2015\u201d</code> for instance - we can see it is a date but PowerShell doesn\u2019t know that you want it to be of type <code>DateTime</code>, so for an occasion where we want to compare two dates, PowerShell won't be able to do it:</p>\n<pre><code class=\"text\">PS C:\\Users\\bob&gt; $differenceBetweenTwoDates = (\u201cFebruary 26, 2015\u201d - \u201cFebruary 15, 2015\u201d)\nCannot convert value &quot;February 26, 2015&quot; to type &quot;System.Int32&quot;. Error: &quot;Input string was not in a correct format.&quot;\nAt line:1 char:1\n+ $differenceBetweenTwoDates = (\u201cFebruary 26, 2015\u201d - \u201cFebruary 15, 201 ...\n+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    + CategoryInfo          : InvalidArgument: (:) [], RuntimeException\n    + FullyQualifiedErrorId : InvalidCastFromStringToInteger\n</code></pre>\n\n<p>As shown above in the error message, PowerShell has made the assumption that we want to convert both of the <code>String</code> values to be an <code>Integer</code>, except this is quite far from what we want.</p>\n<p>So if we explicitly tell PowerShell to consider those Strings as <code>DateTime</code> objects, then PowerShell will attempt to parse them as such:</p>\n<pre><code class=\"text\">PS C:\\Users\\bob&gt; $time = ([DateTime]\u201cFebruary 26, 2015\u201d - [DateTime]\u201cFebruary 15, 2015\u201d)\n\nPS C:\\Users\\bob&gt; echo $time\nDays              : 11\nHours             : 0\nMinutes           : 0\nSeconds           : 0\nMilliseconds      : 0\nTicks             : 9504000000000\nTotalDays         : 11\nTotalHours        : 264\nTotalMinutes      : 15840\nTotalSeconds      : 950400\nTotalMilliseconds : 950400000\n</code></pre>\n\n<h2>Tasks</h2>\n<h3>Create a Simple String Variable</h3>\n<p>Create a simple variable which contains your name, for the example below you can replace <code>bob</code> with your name:</p>\n<pre><code class=\"powershell\">$name = &quot;bob&quot;\n</code></pre>\n\n<h3>Access the <code>name</code> Variable</h3>\n<p>The <code>name</code> variable that has just been created can be accessed like this:</p>\n<pre><code class=\"powershell\">echo &quot;Hi, my name is $name&quot;\n</code></pre>\n\n<p>You should then see an output like this but with your name:</p>\n<pre><code class=\"text\">Hi, my name is bob\n</code></pre>\n\n<h3>Create an Integer Variable</h3>\n<p>We can create another variable for your age, you can replace <code>23</code> here with your age:</p>\n<pre><code class=\"powershell\">$age = 23\n</code></pre>\n\n<h3>Access both the <code>name</code> and <code>age</code> Variables</h3>\n<p>Both variables that have been created can be accessed in an <code>echo</code> command at the same time:</p>\n<pre><code class=\"powershell\">echo &quot;Hi, my name is $name and I am $age years old&quot;\n</code></pre>\n\n<p>You should then see an output like this with your name and age:</p>\n<pre><code class=\"text\">Hi, my name is bob and I am 23 years old\n</code></pre>"}, {"gitUri": "topics/powershell/modules/introduction", "overview": "PowerShell is a tool that allows us to manage machines from the command-line, as well as create scripts to automate tasks on Windows, Linux and MacOS operating systems.", "name": "Introduction", "resourceName": "powershell/introduction", "content": "<h1>Introduction</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#installation\">Installation</a><ul>\n<li><a href=\"#windows\">Windows</a></li>\n<li><a href=\"#linux\">Linux</a></li>\n<li><a href=\"#macos\">MacOS</a></li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#open-powershell\">Open PowerShell</a></li>\n<li><a href=\"#make-a-variable\">Make a Variable</a></li>\n<li><a href=\"#show-the-contents-of-a-variable\">Show the Contents of a Variable</a></li>\n<li><a href=\"#test-a-connection-to-a-remote-host\">Test a Connection to a Remote Host</a></li>\n<li><a href=\"#conditionals\">Conditionals</a><ul>\n<li><a href=\"#connection-test-to-a-host-that-doesnt-exist\">Connection Test to a Host that doesn't exist</a></li>\n<li><a href=\"#connection-test-to-a-host-that-does-exist\">Connection Test to a Host that does exist</a></li>\n</ul>\n</li>\n<li><a href=\"#exit-powershell\">Exit PowerShell</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>PowerShell is a tool that allows us to manage machines from the command-line, as well as create scripts to automate tasks on Windows, Linux and MacOS operating systems.\nBelow are some notable characteristics about PowerShell:\n- <strong>Command-line shell</strong>\n    - Single commands can be run in an interactive shell\n- <strong>Scripting language</strong>\n    - Multiple commands, logic and control flow can be implemented in scripts to automate complex tasks\n- <strong>Open Source</strong>\n    - The source code for the application is open to the public, meaning everyone can view the code and everyone can request to make contributions to the code\n- <strong>Available on Windows, Linux and MacOS</strong>\n    - Pre-installed and configured on Windows \n    - Built on the .NET Framework\n    - Object oriented scripting is available through the .NET framework that PowerShell has been developed on</p>\n<h2>Installation</h2>\n<h3>Windows</h3>\n<p>PowerShell is compatible with all of the popular operating systems. PowerShell is already pre-installed on Windows, so there is no need for initial installation or further configuration to get started with it.</p>\n<h3>Linux</h3>\n<p>PowerShell is available through most popular package managers for Linux. However, you must configure the relevant package manager to work with PowerShell, which is entirely dependent on your Linux version.\nPlease refer to the <a href=\"https://docs.microsoft.com/en-us/powershell/scripting/install/installing-powershell-core-on-linux?view=powershell-6\">Microsoft documentation</a> to configure and install PowerShell correctly for your operating system.</p>\n<h3>MacOS</h3>\n<p>PowerShell can be installed on Mac by using the brew package manager:</p>\n<pre><code class=\"bash\">brew cask install powershell\n</code></pre>\n\n<h2>Tasks</h2>\n<p>Here are some basic commands and concepts to try out in PowerShell.</p>\n<h3>Open PowerShell</h3>\n<p>On Windows you can simply search for <code>powershell</code> in the start menu.\nWith MacOS and Linux, open a terminal and execute <code>pwsh</code>.</p>\n<h3>Make a Variable</h3>\n<p>Variables have all sorts of uses within programming, and will be important for most PowerShell scripts:</p>\n<pre><code class=\"powershell\">$myVariable = \u201cHello World\u201d\n</code></pre>\n\n<h3>Show the Contents of a Variable</h3>\n<p>Logging output is a good way for debugging and understanding where the scripts you create are at. You can use <code>Write-Output</code> or <code>Echo</code> for this.</p>\n<pre><code class=\"powershell\">Write-Output $myVariable\n</code></pre>\n\n<h3>Test a Connection to a Remote Host</h3>\n<p>We can see if a connection can be made to a remote machine by using the Test-Connection command.</p>\n<pre><code class=\"powershell\">Test-Connection google.co.uk\n</code></pre>\n\n<h3>Conditionals</h3>\n<p>All commands that are executed either succeed or fail; we can use this to change how scripts behave or react to failed commands.\nIf you run the examples below, they will print out a different message to the console depending on whether the <code>Test-Connection</code> commands succeeds.</p>\n<h4>Connection Test to a Host that doesn't exist</h4>\n<pre><code class=\"powershell\">if (Test-Connection goasd1le.co2.rq.r.q2r) {\n   Write-Output &quot;Connection Successful&quot;\n} else {\n   Write-Output &quot;Could not connect&quot;\n}\n</code></pre>\n\n<h4>Connection Test to a Host that does exist</h4>\n<pre><code class=\"powershell\">if (Test-Connection google.co.uk) {\n   Write-Output &quot;Connection Successful&quot;\n} else {\n   Write-Output &quot;Could not connect&quot;\n}\n</code></pre>\n\n<h3>Exit PowerShell</h3>\n<p>You can run the <code>exit</code> command to quit PowerShell:</p>\n<pre><code class=\"powershell\">exit\n</code></pre>"}, {"gitUri": "topics/powershell/modules/functions", "overview": "", "name": "Functions", "resourceName": "powershell/functions", "content": "<h1>Functions</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#powershell-functions\">Powershell Functions</a></li>\n<li><a href=\"#basic-functions\">Basic Functions</a></li>\n<li><a href=\"#advanced-functions\">Advanced Functions</a><ul>\n<li><a href=\"#builtin-parameters\">Built-in Parameters</a></li>\n</ul>\n</li>\n<li><a href=\"#task\">Task</a></li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>Instead of copying and pasting the same code over and over again, we can use a function. We will be learning about functions in Powershell in this module, but the concepts also translate across all programming languages.</p>\n<h2>Powershell Functions</h2>\n<p>When you first start out with Powershell, you aren't always too concerned with things such as modularity, reusibility and \"best practices\". As time goes on, you will very quickly realise that you are repeating yourself in code often.</p>\n<p>This is where functions become really useful. Copying and pasting isn't sustainable, so instead we create small \"building blocks\" that can be reused.</p>\n<p>In Powershell, there are two different types of functions: <strong>Basic</strong> fuctions and <strong>Advanced</strong> functions.</p>\n<p>If the function only needs to carry out simple and quick tasks, such as generating a random 12-digit number and adding 12 random letters to it (maybe you are generating a password), a Basic Function would be perfect.</p>\n<p>However, if you need the function to perform more advanced tasks, such as those that require error streams or pipeline input, you would need to use an Advanced Function.</p>\n<h2>Basic Functions</h2>\n<p>These are the simplest form of function in Powershell. It is created or declared by using the <em>function</em> statement, followed by a set of curly braces:</p>\n<pre><code class=\"powershell\">function Hello{}\n</code></pre>\n\n<p>Although this is a viable function in Powershell, it doesn't do very much. To make it useful, we would need to add some code inside it. Let's fix this now:</p>\n<pre><code class=\"powershell\">function Hello{\n    Write-Host &quot;Hello&quot;\n}\n</code></pre>\n\n<p>We could then call the function in Powershell, by simply using the name of the function. In this case, the following would return <code>Hello</code> to the console:</p>\n<pre><code class=\"powershell\">PS &gt; Hello\n</code></pre>\n\n<p>This is great, but what if we wanted to pass something into the code inside the function when it's running? This can be done by creating one, or more, parameters inside of a parameter block:</p>\n<pre><code class=\"powershell\">function Hello{\n    param($Name)\n    Write-Host &quot;Hello $Name!&quot;\n}\n</code></pre>\n\n<p>Here, we have created a parameter called <code>Name</code>, which can then be used in the statement in the next line of code.</p>\n<p>To use this parameter, we need to pass it a value when we call the function:</p>\n<pre><code class=\"powershell\">PS &gt; Hello -Name 'Bob'\n</code></pre>\n\n<p>This would return <code>Hello Bob!</code> to the console.</p>\n<h2>Advanced Functions</h2>\n<p>These include all the functionality of basic functions, but also come with some built-in features as well.</p>\n<p>Powershell has a concept of streams called <code>Error</code>, <code>Warning</code>, <code>Verbose</code>, etc. These streams are critically important in correctly displaying output to users. <strong>Basic Functions do not inherently understand these streams</strong>, making it much more difficult to achieve the same functionality using them.</p>\n<p>You create an advanced function using the <code>[CmdletBinding()]</code> keyword:</p>\n<pre><code class=\"powershell\">function Hello{\n    [CmdletBinding()]\n    param($Name)\n\n    Write-Error -Message &quot;Nothing to write to console&quot;\n}\n</code></pre>\n\n<p>If we call this function using <code>PS &gt; Hello</code>, we will see an error message on the console (which has come from the error stream) saying <code>Nothing to write to console</code>.</p>\n<p>This is because a <em>Write-Error</em> has occured - we didn't add a line of code inside the function to ensure that something is written to the console when the function is ran (this is the <code>Write-Host</code> line from earlier).</p>\n<p>Without this error stream, the user would be unsure as to why their function isn't working the way they wanted it to.</p>\n<h3>Built-in Parameters</h3>\n<p>Advanced functions have lots of built in parameters that you can use, even if you don't include them in the code block of the function. An example of this is <code>ErrorAction</code>:</p>\n<pre><code class=\"powershell\">PS &gt; Hello -ErrorAction SilentlyContinue\n</code></pre>\n\n<p>This effectively ignores the error stream, and carries out the function as if it didn't exist.</p>\n<h2>Task</h2>\n<ol>\n<li>\n<p>Create a Basic Function in Powershell that:</p>\n<ul>\n<li>Takes 2 parameters: a user's name and their favourite food</li>\n<li>Outputs the following message to the console, replacing the text in brackets with the parameters - <code>\"(name)'s favourite food is (food)\"</code>.</li>\n</ul>\n</li>\n<li>\n<p>Create an Advanced Function in Powershell:</p>\n<ul>\n<li>Include a <code>Write-Error</code></li>\n<li>Manupulate the function so that, when ran, an error occurs from the error stream</li>\n<li>Use <code>SilentlyContinue</code> to call the function and ignore the error stream.</li>\n</ul>\n</li>\n</ol>"}]}, {"gitUri": "topics/terraform", "overview": "", "name": "Terraform", "resourceName": "terraform", "modules": [{"gitUri": "topics/terraform/modules/introduction", "overview": "", "name": "Introduction", "resourceName": "terraform/introduction", "content": "<h1>Introduction</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a><ul>\n<li><a href=\"#infrastructure-as-code\">Infrastructure as Code</a></li>\n<li><a href=\"#workflows\">Workflows</a></li>\n<li><a href=\"#common-use-cases\">Common use cases</a></li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#installation\">Installation</a></li>\n<li><a href=\"#windows\">Windows</a><ul>\n<li><a href=\"#configuring-the-terraform-on-your-path\">Configuring the Terraform on your <code>PATH</code></a></li>\n</ul>\n</li>\n<li><a href=\"#linux\">Linux</a></li>\n<li><a href=\"#verify-the-installation\">Verify the Installation</a></li>\n<li><a href=\"#creating-a-simple-resource-in-aws\">Creating a Simple Resource in AWS</a></li>\n<li><a href=\"#creating-a-resource-in-aws\">Creating a resource in AWS</a></li>\n<li><a href=\"#create-an-access-key\">Create an Access Key</a></li>\n<li><a href=\"#create-some-basic-terraform-files\">Create Some Basic Terraform Files</a><ul>\n<li><a href=\"#configure-the-provider\">Configure the Provider</a></li>\n<li><a href=\"#create-a-basic-resource\">Create a Basic Resource</a></li>\n<li><a href=\"#use-the-configurations-that-you-created\">Use the Configurations That You Created</a></li>\n</ul>\n</li>\n<li><a href=\"#clean-up\">Clean up</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>Terraform allows you to control your infrastructure on the cloud service provider. </p>\n<p>The big providers are: \n* AWS\n* GCP\n* Azure </p>\n<h3>Infrastructure as Code</h3>\n<p>Infrastructure as code means that we can use a high level or descriptive programming language to describe and manage infrastructure.</p>\n<p>There is a known issue with pipelines called <strong>environment drift</strong>, which means that over time, an environment can end up in unique configuration that cannot be automatically recreated.</p>\n<p>When environments become inconsistent, deployments can be affected and testing can be made invalid.</p>\n<p>With infrastructure as code, the infrastructure configurations can be versioned and maintained, so if another environment needs to be created, you can be sure that you are using up to date configurations.</p>\n<h3>Workflows</h3>\n<p>There are a few steps that should be followed for a deployment, don't worry if you don't understand the concepts immediately, they will make more sense later on.</p>\n<ol>\n<li><strong>Scope</strong> - check resources that need to be created for a given project</li>\n<li><strong>Author</strong> - create the configuration file</li>\n<li><strong>Initialise</strong> - execute <code>terraform init</code> in the project directory where the configuration file lies. \nThis will download any dependencies necessary for the selected cloud provider.</li>\n<li><strong>Plan</strong> - execute <code>terraform plan</code> in the project directory where the configuration file lies. \nThis will verify the creation process and scan the configuration file for any detectable faults.</li>\n<li><strong>Apply</strong> - execute <code>terraform apply</code> in the project directory where the configuration file lies. \nThis will create the actual resource as well as the state file which terraform will use to check for changes in the configuration file to what is actually deployed.</li>\n</ol>\n<h3>Common use cases</h3>\n<ul>\n<li><strong>Multi-Tier Applications</strong> - It is very common to have applications with multiple tiers, each tier having different requirements and dependencies. \nWith Terraform we are able to describe each tier of the application as a collection of resources so that the dependencies for each tier can be handled automatically.</li>\n<li><strong>Software Demos</strong> - Although tools like Vagrant can be used to create environments for demos, vagrant can\u2019t completely mimic production environments.\nAdditionally, depending on how large the infrastructure for the application is, it might be challenging to run it on something like a laptop.\n Because configurations for Terraform can be distributed, demos can be run against the end user\u2019s infrastructure with ease. \n Parameters for the Terraform configurations can also be tweaked so that the software can be demoed at any scale.</li>\n<li><strong>Disposable Environments</strong> - It is common to have a staging environment before deploying to production, which is a smaller clone of the production environment. \nProduction environments over time can become more complex and require more effort to mimic on a smaller scale. \nWith Terraform, the infrastructure will be kept as code and can easily applied to other new environments for testing and then be disposed. \nSpinning up and disposing environments this easily means that costs can also saved on environments that do not need to be operational 24/7 and only for a fraction of that time.</li>\n<li><strong>Multi-Cloud Deployments</strong> - Terraform has the ability to configure infrastructure across more than one cloud service.\n This hybrid solution might be due to a customer wanting to take advantage of the features available on different cloud provider solutions. \nAnother reason for multi-cloud deployments could be for extra fault tolerance.</li>\n</ul>\n<h2>Tasks</h2>\n<h3>Installation</h3>\n<p>We will now install terraform and check that the installation was successful.</p>\n<h3>Windows</h3>\n<ul>\n<li>Navigate to https://www.terraform.io/downloads.html in a web browser and download Terraform for 64-bit windows</li>\n<li>Extract the .zip file</li>\n<li>Copy the terraform.exe file from where you decided to extract it to a new folder: <code>C:\\tools\\terraform\\</code></li>\n</ul>\n<h4>Configuring the Terraform on your <code>PATH</code></h4>\n<p>We now need to configure the <code>PATH</code> environment variable so that Terraform can be used easily on the command line.\n- Press <strong>Windows key + R</strong> to open the <strong>Run program</strong>\n- Type <strong>SystemPropertiesAdvanced</strong> and click <strong>OK</strong></p>\n<p><img alt=\"Windows Configure Environment Variables\" src=\"https://imgur.com/6y4t3MX.jpg\" /></p>\n<ul>\n<li>Select <strong>Environment Variables...</strong> button</li>\n</ul>\n<p><img alt=\"Select Environment Variables\" src=\"https://imgur.com/XihMpT9.jpg\" /></p>\n<ul>\n<li>Under <em>User Variables for <your-username></em>, select <strong>New\u2026</strong> and enter the Variable name: <strong>TERRAFORM_HOME</strong> and the Variable value: <code>C:\\tools\\terraform</code>, then click <strong>OK</strong> button</li>\n</ul>\n<p><img alt=\"Environment Variables\" src=\"https://imgur.com/EaIt6Jv.jpg\" /></p>\n<ul>\n<li>Under <em>System Variables</em>, select the variable called <strong>Path</strong> then click <strong>Edit\u2026</strong> then in the next window click <strong>New</strong> and enter <strong>%TERRAFORM_HOME%</strong></li>\n</ul>\n<p><img alt=\"System Variables\" src=\"https://imgur.com/bkXxBsK.jpg\" /></p>\n<ul>\n<li>Click <strong>OK</strong> button on the <em>Environment Variable Windows</em> and close the <em>System Properties</em> window.</li>\n</ul>\n<h3>Linux</h3>\n<p>Follow the steps below, entering the commands into a terminal. \n* Make sure your system is up to date:\n    * If you are using Debian/Ubuntu OS: <code>sudo apt update &amp;&amp; sudo apt upgrade -y</code>\n    * If you are using CentOS/RHEL/Fedora: <code>sudo yum update -y</code>\n* Ensure the unzip and wget tools are installed:\n    * If you are using Debian/Ubuntu OS: <code>sudo apt install -y unzip wget</code>\n    * If you are using CentOS/RHEL/Fedora: <code>sudo yum install -y unzip wget</code>\n* Download the Terraform zip:\n    * Please not the version here will likely not be the latest, so please use the official download page to find out what the latest download link is: https://www.terraform.io/downloads.html. \n     You will likely need to download the 64-bit version.\n    <code>wget https://releases.hashicorp.com/terraform/0.12.12/terraform_0.12.12_linux_amd64.zip</code>\n* Extract the Terraform zip archive: <code>unzip terraform_*_linux_*.zip</code>\n* Move the Terraform binary to the /usr/local/bin folder: <code>sudo mv terraform /usr/local/bin</code>\n* Remove the downloaded zip file: <code>rm terraform_*_linux_*.zip</code></p>\n<h3>Verify the Installation</h3>\n<p>You can verify that you have installed Terraform correctly by opening a command line or terminal and run the command below, the version of Terraform that you installed should be shown: <code>terraform --version</code></p>\n<h3>Creating a Simple Resource in AWS</h3>\n<p>We will now create a resource in AWS and check that it has been successfully created.</p>\n<h3>Creating a resource in AWS</h3>\n<p>Before going forward with this task there are a couple of pre-requisites:\n* Your terraform installation has to be working\n* You will need an AWS account\n    * If you don't have one, you can create a free account by going to: <a href=\"https://aws.amazon.com/free\">AWS free account</a></p>\n<p>We will now create a resource in AWS using Terraform.</p>\n<h3>Create an Access Key</h3>\n<p>First you need to find your <code>access_key</code> and <code>secret_key</code> in order to give terraform access to manage resources on AWS.</p>\n<p>You can find them by following these steps:\n* Log in to your <em>AWS Management Console</em>\n* Click on your user name at the top right of the page\n* Click on the <em>Security Credentials</em> link from the drop-down menu\n* Find the <em>Access Credentials</em> section, and copy the latest <em>Access Key ID</em>, this is the <code>access_key</code> \n* Click on the Show link in the same row, and copy the Secret Access Key, this is the <code>secret_key</code> \n    * If there is no Secret Access Key, create a new one\n* Copy and save both in some text file but make sure to note down which is which. \nAfter saving both of them you should have them looking like this in your text file.</p>\n<pre><code>access_key = &quot;AKIBIWX7DKIDGMCHPG4A&quot;\nsecret_key = &quot;3gSerUT5rreC989K5l4f3WcGZ0yUNaltaw4C8r/1&quot;\n</code></pre>\n\n<h3>Create Some Basic Terraform Files</h3>\n<p>For the next step create a new folder, you can pick any name for it but a suggested one would be <code>example_1</code>.</p>\n<p>Within the newly created folder, create a new file called <code>main.tf</code>.</p>\n<p>Open the <code>main.tf</code> with a text editor of your choosing.</p>\n<h4>Configure the Provider</h4>\n<p>We will now declare in terraform syntax what provider we'll be using, as well as the <code>access_key</code>, <code>secret_key</code> and region where the resource will be created.</p>\n<p>Place the following into your <code>main.tf</code> file:</p>\n<pre><code>provider &quot;aws&quot; {\n    access_key = &quot;AKIBIWX7DKIDGMCHPG4A&quot;\n    secret_key = &quot;3gSerUT5rreC989K5l4f3WcGZ0yUNaltaw4C8r/1&quot;\n    region = &quot;eu-west-2&quot;\n}\n</code></pre>\n\n<p>First line tells terraform that the cloud provider will be <code>aws</code>.</p>\n<p>Second and third lines are required to authenticate with <code>aws</code> and give terraform access to manage the resources.</p>\n<p>Fourth line is specifying which region the resource will be created.</p>\n<h4>Create a Basic Resource</h4>\n<p>For the next step we need to tell terraform what resource to create.</p>\n<p>Place the following into your <code>main.tf</code> file below the <code>provider</code>:</p>\n<pre><code>resource &quot;aws_instance&quot; &quot;example&quot; {\n    ami = &quot;ami-2757f631&quot;\n    instance_type = &quot;t2.micro&quot;\n}\n</code></pre>\n\n<p>The first line is telling terraform to create a new resource, in this case a virtual machine instance, with the name of <code>example</code>.</p>\n<p>Second line is declaring what <em>Amazon Machine Image</em> to use for the operating system.</p>\n<p>Third line is declaring what instance type to use, this will determine how many virtual CPUs and Memory it will have.</p>\n<p><code>main.tf</code> should look similar to this once you have place the two pieces of text into it:</p>\n<pre><code>provider &quot;aws&quot; {\n    access_key = &quot;AKIBIWX7DKIDGMCHPG4A&quot;\n    secret_key = &quot;3gSerUT5rreC989K5l4f3WcGZ0yUNaltaw4C8r/1&quot;\n    region = &quot;eu-west-2&quot;\n}\n\nresource &quot;aws_instance&quot; &quot;example&quot; {\n    ami = &quot;ami-2757f631&quot;\n    instance_type = &quot;t2.micro&quot;\n}\n</code></pre>\n\n<h4>Use the Configurations That You Created</h4>\n<ul>\n<li>Open a terminal in the directory where the <code>main.tf</code> file is located.</li>\n<li>Run the following command for terraform to get any required dependencies based on the cloud provider being used:\n    <code>terraform init</code></li>\n<li>Run the following command to scan the <code>main.tf</code> for any issues:\n    <code>terraform plan</code></li>\n<li>Run the following command to create the real resource:\n    <code>terraform apply</code></li>\n<li>Once terraform will give you a prompt about the successful operation in the <em>AWS console</em> under <em>Compute</em> and then <em>EC2</em> check that the resource has been created. \nMake sure that you are within the correct region, otherwise you won't be able to see the resource.</li>\n</ul>\n<h3>Clean up</h3>\n<p>To delete the created resource run the following command in the terminal, make sure that the terminal is in the directory where <code>main.tf</code> is located:\n    <code>terraform destroy</code> </p>\n<p>Check in the <em>AWS console</em> under <em>Compute</em> and then <em>EC2</em> check that the resource has been deleted.</p>\n<p>Make sure that you are within the correct region, otherwise you won't be able to see the resource.</p>"}]}, {"gitUri": "topics/netstat", "overview": "In computing, netstat (network statistics) is a command-line network utility that displays network connections for Transmission Control Protocol (both incoming and outgoing), routing tables and network protocol statistics, and uses a number of network interfaces (network interface controller or software-defined network interface).", "name": "Netstat", "resourceName": "netstat", "modules": [{"gitUri": "topics/netstat/modules/basic-usage-for-linux", "overview": "The netstat tool is very important for Linux network administrators, as well as system administrators, to monitor and troubleshoot their network related problems and determine network traffic performance.", "name": "Basic Usage for Linux", "resourceName": "netstat/basic-usage-for-linux", "content": "<h1>Basic Usage for Linux</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#options-on-linux\">Options on Linux</a></li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#install-nginx-for-your-operating-system\">Install NGINX for Your Operating System</a><ul>\n<li><a href=\"#ubuntudebian\">Ubuntu/Debian</a></li>\n<li><a href=\"#centosrhel\">CentOS/RHEL</a></li>\n</ul>\n</li>\n<li><a href=\"#identify-the-process-id-of-the-application-using-a-port-number\">Identify the Process ID of the Application Using a Port Number</a></li>\n<li><a href=\"#clean-up\">Clean Up</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>The netstat tool is very important for Linux network administrators, as well as system administrators, to monitor and troubleshoot their network related problems and determine network traffic performance.</p>\n<h2>Options on Linux</h2>\n<table>\n<thead>\n<tr>\n<th>Short and Long Options</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>-a, --all</td>\n<td>Displays all active connections and the TCP and UDP ports on which the computer is listening</td>\n</tr>\n<tr>\n<td>-c, --continuous</td>\n<td>Continuous listening</td>\n</tr>\n<tr>\n<td>-h, --help</td>\n<td>Show the available options that can be used</td>\n</tr>\n<tr>\n<td>-l, --listening</td>\n<td>Display listening server socket</td>\n</tr>\n<tr>\n<td>-n, --numeric</td>\n<td>Displays active TCP connections, however, addresses and port numbers are expressed numerically and no attempt is made to determine names</td>\n</tr>\n<tr>\n<td>-p, --programs</td>\n<td>Display PID/Program name for sockets; this is great for finding what applications are taking up the ports you are trying to use</td>\n</tr>\n<tr>\n<td>-t, --tcp</td>\n<td>Filter TCP Sockets</td>\n</tr>\n<tr>\n<td>-u, --udp</td>\n<td>Filter UDP Sockets</td>\n</tr>\n<tr>\n<td>-v, --verbose</td>\n<td>Show more information and statistics</td>\n</tr>\n<tr>\n<td>-V, --version</td>\n<td>Display the version of netstat that's installed</td>\n</tr>\n</tbody>\n</table>\n<h2>Tasks</h2>\n<p>Here, we'll look at how we can find a process using a certain port on a machine.\nIt's a common issue where you have an application running (such as a webserver) and you are unable to redeploy that application because the old version of it is still running; this means that the port is in use.\nAn efficient way to resolve this is to find the process ID by the port that it's listening on.\nFor instance, if we knew that the application was listening on port 80, that means we can use a tool like netstat to identify that application's PID by the port that it is listening on.</p>\n<p>To start, we need to install an application to do this - NGINX is a simple reverse proxy and webserver that can serve that purpose well.</p>\n<h3>Install NGINX for Your Operating System</h3>\n<h4>Ubuntu/Debian</h4>\n<pre><code class=\"bash\">sudo apt update\nsudo apt install -y nginx\n</code></pre>\n\n<h4>CentOS/RHEL</h4>\n<pre><code class=\"bash\">sudo yum install -y nginx\n</code></pre>\n\n<h3>Identify the Process ID of the Application Using a Port Number</h3>\n<p>NGINX runs on port <code>80</code>.\nFirstly, we need to get an output from netstat containing the applications PID:</p>\n<pre><code class=\"bash\">netstat -tulpn\n</code></pre>\n\n<p>You might notice that, under the PID column, there aren't any values (only <code>-</code> is listed):</p>\n<pre><code class=\"text\">(No info could be read for &quot;-p&quot;: geteuid()=1001 but you should be root.)\nActive Internet connections (only servers)\nProto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name\ntcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN      -\ntcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      -\ntcp6       0      0 :::80                   :::*                    LISTEN      -\ntcp6       0      0 :::22                   :::*                    LISTEN      -\nudp        0      0 0.0.0.0:68              0.0.0.0:*                           -\nudp        0      0 10.154.0.34:123         0.0.0.0:*                           -\nudp        0      0 127.0.0.1:123           0.0.0.0:*                           -\nudp        0      0 0.0.0.0:123             0.0.0.0:*                           -\nudp6       0      0 fe80::4001:aff:fe9a:123 :::*                                -\nudp6       0      0 ::1:123                 :::*                                -\nudp6       0      0 :::123                  :::*                                -\n</code></pre>\n\n<p>This is because the processes are executed by another user, meaning you don't have access to that information.\nTo get around this, we can use <code>sudo</code>:</p>\n<pre><code class=\"bash\">sudo netstat -tulpn\n</code></pre>\n\n<p>Now we should see a list of PIDs:</p>\n<pre><code class=\"text\">Active Internet connections (only servers)\nProto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    \ntcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN      1665/nginx: master  \ntcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      686/sshd            \ntcp6       0      0 :::80                   :::*                    LISTEN      1665/nginx: master  \ntcp6       0      0 :::22                   :::*                    LISTEN      686/sshd            \nudp        0      0 0.0.0.0:68              0.0.0.0:*                           583/dhclient        \nudp        0      0 10.154.0.34:123         0.0.0.0:*                           644/ntpd            \nudp        0      0 127.0.0.1:123           0.0.0.0:*                           644/ntpd            \nudp        0      0 0.0.0.0:123             0.0.0.0:*                           644/ntpd            \nudp6       0      0 fe80::4001:aff:fe9a:123 :::*                                644/ntpd            \nudp6       0      0 ::1:123                 :::*                                644/ntpd            \nudp6       0      0 :::123                  :::*                                644/ntpd \n````\nYou will now be able to use the PID of NGINX (1665 in this case) to manage that process (most likely to kill it):\n```bash\nsudo kill 1665\n</code></pre>\n\n<h3>Clean Up</h3>\n<p>Lets stop and remove NGINX to cleanup:</p>\n<pre><code class=\"bash\">sudo systemctl stop nginx\nsudo apt purge -y nginx\n</code></pre>"}, {"estTime": 15, "software": [{"name": "nginx", "version": "1.16.1", "platform": "windows"}], "gitUri": "topics/netstat/modules/basic-usage-for-windows", "overview": "Netstat on Windows displays active TCP connections, ports on which the computer is listening, Ethernet statistics, the IP routing table, IPv4 statistics (for the IP, ICMP, TCP, and UDP protocols), and IPv6 statistics (for the IPv6, ICMPv6, TCP over IPv6, and UDP over IPv6 protocols).", "name": "Basic Usage for Windows", "resourceName": "netstat/basic-usage-for-windows", "content": "<!--PROPS\n{\n    \"estTime\": 15,\n    \"software\": [\n        {\n            \"name\": \"nginx\",\n            \"version\": \"1.16.1\",\n            \"platform\": \"windows\"\n        }\n    ]\n}\n-->\n\n<h1>Basic Usage for Windows</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#options-on-windows\">Options on Windows</a></li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#install-nginx-on-windows\">Install NGINX on Windows</a></li>\n<li><a href=\"#identify-the-application-using-a-port-number\">Identify the Application Using a Port Number</a></li>\n<li><a href=\"#stop-the-application\">Stop the Application</a><ul>\n<li><a href=\"#using-the-process-name\">Using the Process Name</a></li>\n<li><a href=\"#using-the-process-id-pid\">Using the Process ID (PID)</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>Netstat on Windows displays active TCP connections, ports on which the computer is listening, Ethernet statistics, the IP routing table, IPv4 statistics (for the IP, ICMP, TCP, and UDP protocols), and IPv6 statistics (for the IPv6, ICMPv6, TCP over IPv6, and UDP over IPv6 protocols).</p>\n<h2>Options on Windows</h2>\n<p>Used without parameters, <code>netstat</code> displays active TCP connections.\nTypically on Windows CLI tools options when running commands are prefixed with <code>/</code>.\nFor instance, to use the <code>a</code> option you would put <code>/a</code>.\nThis is not the case with netstat, where you can use <code>-</code>.\nAn example of using the <code>a</code> option would be <code>-a</code>.\nHere are some of the other available options to use with netstat on Windows:</p>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>-a</code></td>\n<td>Displays all active TCP connections and the TCP and UDP ports on which the computer is listening</td>\n</tr>\n<tr>\n<td><code>-b</code></td>\n<td>Displays the executable involved in creating each connection or listening port</td>\n</tr>\n<tr>\n<td><code>-e</code></td>\n<td>Displays Ethernet statistics, such as the number of bytes and packets sent and received. This parameter can be combined with <code>-s.</code></td>\n</tr>\n<tr>\n<td><code>-h</code></td>\n<td>Show available options</td>\n</tr>\n<tr>\n<td><code>-n</code></td>\n<td>Displays active TCP connections, however, addresses and port numbers are expressed numerically and no attempt is made to determine names.</td>\n</tr>\n<tr>\n<td><code>-o</code></td>\n<td>Displays active TCP connections and includes the process ID (PID) for each connection. You can find the application based on the PID on the Processes tab in Windows Task Manager. This parameter can be combined with <code>-a</code>, <code>-n</code>, and <code>-p</code>.</td>\n</tr>\n<tr>\n<td><code>-p</code></td>\n<td>Shows connections for the protocol specified by Protocol. In this case, the Protocol can be tcp, udp, tcpv6, or udpv6. If this parameter is used with <code>-s</code> to display statistics by protocol, Protocol can be tcp, udp, icmp, ip, tcpv6, udpv6, icmpv6, or ipv6.</td>\n</tr>\n<tr>\n<td><code>-s</code></td>\n<td>Displays statistics by protocol. By default, statistics are shown for the TCP, UDP, ICMP, and IP protocols. If the IPv6 protocol is installed, statistics are shown for the TCP over IPv6, UDP over IPv6, ICMPv6, and IPv6 protocols. The -p parameter can be used to specify a set of protocols.</td>\n</tr>\n<tr>\n<td><code>-r</code></td>\n<td>Displays the contents of the IP routing table. This is equivalent to the <code>route print</code> command.</td>\n</tr>\n</tbody>\n</table>\n<h2>Tasks</h2>\n<p>Here, we'll look at how we can find a process using a certain port on a machine.\nIt's a common issue where you have an application running (such as a web server) and you are unable to redeploy that application because the old version of it is still running; this means that the port is in use.\nAn efficient way to resolve this is to find the process name by the port that it's listening on.\nFor instance, if we knew that the application was listening on port <code>80</code>, that means we can use a tool like netstat to identify that application's name by the port that it is listening on.</p>\n<p>To start, we need to install an application to do this - NGINX is a simple reverse proxy and web server that can serve that purpose well.</p>\n<h3>Install NGINX on Windows</h3>\n<ul>\n<li>Download NGINX <code>1.16.1</code> from <a href=\"http://nginx.org/download/nginx-1.16.1.zip\">here</a> </li>\n<li>Extract the <code>nginx-1.16.1.zip</code> file</li>\n<li>Execute <code>nginx-1.16.1/nginx.exe</code> - All you have to do is double click the file; don't expect anything to pop up as it runs in the background</li>\n<li>Check that NGINX is working by navigating to http://localhost in your browser</li>\n</ul>\n<h3>Identify the Application Using a Port Number</h3>\n<p>NGINX runs on port <code>80</code>.\nFirstly, we need to get an output from netstat containing the applications name.\nIn the examples below the following options are used:\n- <code>a</code>; We are using this to show TCP and UDP ports which the computer is listening on\n- <code>n</code>; This is being used because we don't need to resolve host names, so this will mean that the command runs faster\n- <code>b</code>; One of the most important things we need is the process name; the <code>b</code> option will show us this\n- <code>o</code>; Another way of managing the process is by using the process ID (PID)\n- <code>-p TCP</code>; We saying that we only want to see TCP sockets here to save us looking through too much output</p>\n<pre><code class=\"powershell\">netstat -anbo -p TCP\n</code></pre>\n\n<p>This should give you an output which contains the following:</p>\n<pre><code class=\"text\">Active Connections\n\n  Proto  Local Address          Foreign Address        State           PID\n  TCP    0.0.0.0:80             0.0.0.0:0              LISTENING       4436\n [nginx.exe]\n</code></pre>\n\n<p>We can see from this output that there is an application (<code>nginx.exe</code>) using port <code>80</code> on the machine and it has a PID number of <code>4436</code>.</p>\n<h3>Stop the Application</h3>\n<p>Below are two methods of killing the NGINX process; try identifying and killing the nginx process with both.\nRemember to start NGINX again after killing the process the first time.</p>\n<h4>Using the Process Name</h4>\n<p>Now we know the application name, we can use that to kill the application and gain access back to that port.</p>\n<pre><code class=\"powershell\">taskkill /IM nginx.exe /F\n</code></pre>\n\n<h4>Using the Process ID (PID)</h4>\n<p>To kill a process using its PID we can use the following; replacing <code>[PID]</code> with the PID number:</p>\n<pre><code class=\"powershell\">taskkill /F /PID [PID]\n</code></pre>"}, {"estTime": 15, "questions": [{"value": "What is the Netstat command used for?", "answer": "Displaying network connections for Transmission Control Protocol, routing tables, and a number of network interface and network protocol statistics", "choices": ["Provide information about the currently running processes, including their process identification numbers (PIDs)", "Allowing you to run programs with the security privileges of another user"]}], "gitUri": "topics/netstat/modules/introduction", "overview": "In computing, netstat (network statistics) is a command-line network utility that displays network connections for Transmission Control Protocol (both incoming and outgoing), routing tables and network protocol statistics, and uses a number of network interfaces (network interface controller or software-defined network interface).", "name": "Introduction", "resourceName": "netstat/introduction", "content": "<!--PROPS\n{\n    \"estTime\": 15,\n    \"questions\": [\n        {\n            \"value\": \"What is the Netstat command used for?\",\n            \"answer\": \"Displaying network connections for Transmission Control Protocol, routing tables, and a number of network interface and network protocol statistics\",\n            \"choices\": [\n                \"Provide information about the currently running processes, including their process identification numbers (PIDs)\",\n                \"Allowing you to run programs with the security privileges of another user\"\n            ]\n        }\n    ]\n}\n-->\n\n<h1>Introduction</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#use-cases\">Use Cases</a></li>\n<li><a href=\"#example-outputs\">Example Outputs</a><ul>\n<li><a href=\"#linux\">Linux</a></li>\n<li><a href=\"#windows\">Windows</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>In computing, netstat (network statistics) is a command-line network utility that displays network connections for Transmission Control Protocol (both incoming and outgoing), routing tables and network protocol statistics, and uses a number of network interfaces (network interface controller or software-defined network interface).</p>\n<p>Netstat is usually installed on most operating systems, including: Windows, Mac and many popular Linux distributions.\nOne thing to take into consideration when using netstat is that the options will differ depending on which operating system you are using.</p>\n<h2>Use Cases</h2>\n<p>The netstat tool can be used for the following:\n- Finding issues in a network\n- Finding what application is using a certain port\n- Measuring network performance\n- Showing current connections to the machine</p>\n<h2>Example Outputs</h2>\n<h3>Linux</h3>\n<p>After running a <code>netstat</code> command on Linux, you should see an output of the connections to your machine:</p>\n<pre><code class=\"text\">Proto Recv-Q Send-Q Local Address           Foreign Address         State      \ntcp        0      0 work-laptop:46098       ec2-3-9-202-151.e:https ESTABLISHED\ntcp        0      0 work-laptop:41682       wl-in-f188.1e100.n:5228 ESTABLISHED\ntcp        0      0 work-laptop:49608       server-143-204-18:https ESTABLISHED\ntcp        0      0 work-laptop:46246       lb-192-30-253-124:https ESTABLISHED\ntcp        0      0 work-laptop:55948       17.47.211.130.bc.:https ESTABLISHED\ntcp        0      0 work-laptop:48226       bam-8.nr-data.net:https ESTABLISHED\ntcp        0      0 work-laptop:44982       server-143-204-22:https ESTABLISHED\ntcp        0      0 work-laptop:46106       ec2-3-9-202-151.e:https ESTABLISHED\ntcp        0      0 work-laptop:36322       104.16.70.125:https     ESTABLISHED\ntcp        0      0 work-laptop:42932       do-17.lastpass.co:https ESTABLISHED\ntcp        0      0 work-laptop:33642       185.199.109.154:https   ESTABLISHED\ntcp        0      0 work-laptop:36784       8.255.186.35.bc.g:https ESTABLISHED\ntcp        0      0 work-laptop:56196       a2-18-162-235.dep:https ESTABLISHED\ntcp        0      0 work-laptop:38962       ec2-3-209-208-129:https ESTABLISHED\ntcp        0      0 work-laptop:50210       ec2-54-145-70-92.:https ESTABLISHED\ntcp        0      0 work-laptop:37266       47.67.201.35.bc.g:https ESTABLISHED\ntcp        0      0 work-laptop:40866       151.101.192.176:https   ESTABLISHED\ntcp        0      0 work-laptop:56710       101.59.190.35.bc.:https ESTABLISHED\ntcp        0      0 work-laptop:46112       ec2-3-9-202-151.e:https ESTABLISHED\ntcp        0      0 work-laptop:44858       ec2-52-215-192-13:https ESTABLISHED\n</code></pre>\n\n<h3>Windows</h3>\n<p>When running <code>netstat</code> on Windows, you should see an output similar to the one below:</p>\n<pre><code class=\"text\">Proto  Local Address          Foreign Address        State\n TCP    127.0.0.1:5939         DESKTOP-VJCN58E:50244  ESTABLISHED\n TCP    127.0.0.1:49938        DESKTOP-VJCN58E:49939  ESTABLISHED\n TCP    127.0.0.1:49939        DESKTOP-VJCN58E:49938  ESTABLISHED\n TCP    127.0.0.1:50244        DESKTOP-VJCN58E:5939   ESTABLISHED\n TCP    127.0.0.1:50248        DESKTOP-VJCN58E:50249  ESTABLISHED\n TCP    127.0.0.1:50249        DESKTOP-VJCN58E:50248  ESTABLISHED\n TCP    127.0.0.1:50708        DESKTOP-VJCN58E:50709  ESTABLISHED\n TCP    127.0.0.1:50709        DESKTOP-VJCN58E:50708  ESTABLISHED\n TCP    127.0.0.1:52865        DESKTOP-VJCN58E:52866  ESTABLISHED\n TCP    127.0.0.1:52866        DESKTOP-VJCN58E:52865  ESTABLISHED\n TCP    127.0.0.1:52867        DESKTOP-VJCN58E:52868  ESTABLISHED\n TCP    127.0.0.1:52868        DESKTOP-VJCN58E:52867  ESTABLISHED\n TCP    127.0.0.1:52869        DESKTOP-VJCN58E:52870  ESTABLISHED\n TCP    127.0.0.1:52870        DESKTOP-VJCN58E:52869  ESTABLISHED\n TCP    172.17.25.197:52256    ams16s32-in-f10:https  CLOSE_WAIT\n TCP    172.17.25.197:52259    ams16s32-in-f10:https  CLOSE_WAIT\n TCP    172.17.25.197:52261    ams16s32-in-f10:https  CLOSE_WAIT\n TCP    172.17.25.197:52376    AT-VIE-ANX-R008:5938   ESTABLISHED\n TCP    172.17.25.197:52378    252-57-168-194:https   ESTABLISHED\n TCP    172.17.25.197:52383    252-57-168-194:https   ESTABLISHED\n TCP    172.17.25.197:52387    252-57-168-194:https   ESTABLISHED\n TCP    172.17.25.197:52388    252-57-168-194:https   ESTABLISHED\n ```\n### Output Meaning\nYou should be able to see, from the examples above, that the outputs on Windows and Linux are very similar.\nHere are the meanings of the different headings shown:\n#### Proto\nThis is the type of protocol being used for the connection on that row.\n#### Local Address\nThis is the network interface and port being used on the local machine.\n`127.0.0.1` will mean that it's an internal connection being made (within the same machine).\nIf it's a private IP address, that will likely mean that the connection is being made from outside of the local machine, whether it's on the internet or just communicating with another device on the same network.\n#### Foreign Address\nThis is where the connection is coming from.\nFrom this property, you can determine whether the connection is contained on the same machine or coming from somewhere else.\n#### State\nThe state tells us which state the listed sockets are in.\nThe TCP protocol defines states, including \u201cLISTEN\u201d (wait for some external computer to contact us) and \u201cESTABLISHED\u201d (ready for communication).\nThe stranger among these is the \u201cCLOSE WAIT\u201d state.\nThis means that the foreign or remote machine has already closed the connection, but that the local program somehow hasn\u2019t followed suit.\n#### Recv-Q &amp; Send-Q\nThese are properties found on the Linux output.\nThese tell us how much data is in the queue for that socket, waiting to be read (Recv-Q) or sent (Send-Q).\nIn short: if this is 0, everything\u2019s okay, but if there are non-zero values anywhere, there may be trouble.\n\n## Tasks\nCheck that netstat is working correctly by opening a command prompt on Windows, or a terminal on Linux, and running the following command:\n```bash\nnetstat\n</code></pre>\n\n<p>Try using <code>netstat --help</code> to find out:\n- Which option can be used to show the process ID (PID) of the applications using the sockets\n- Which option can be used to show only TCP sockets\n- Which option can be used to show the system's route table</p>"}]}, {"gitUri": "topics/wireshark", "overview": "Wireshark is a free and open-source packet analyzer.", "name": "Wireshark", "resourceName": "wireshark", "modules": [{"gitUri": "topics/wireshark/modules/display-filters", "overview": "Wireshark's display filter is a bar located at the top, just above where the packets are being shown.", "name": "Display Filters", "resourceName": "wireshark/display-filters", "content": "<h1>Display Filters</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#filtering-by-protocol\">Filtering by Protocol</a></li>\n<li><a href=\"#relational-operators\">Relational Operators</a></li>\n<li><a href=\"#filtering-by-port\">Filtering by Port</a></li>\n<li><a href=\"#logical-operators\">Logical Operators</a></li>\n<li><a href=\"#filter-by-host--address\">Filter by Host &amp; Address</a><ul>\n<li><a href=\"#ipv4\">IPV4</a></li>\n<li><a href=\"#ipv6\">IPV6</a></li>\n</ul>\n</li>\n<li><a href=\"#filter-by-network\">Filter by Network</a></li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#tcp\">TCP</a></li>\n<li><a href=\"#display-your-machines-incoming-and-outgoing-packets\">Display Your Machine's Incoming and Outgoing Packets</a><ul>\n<li><a href=\"#incoming-traffic\">Incoming Traffic</a></li>\n<li><a href=\"#outgoing-traffic\">Outgoing Traffic</a></li>\n</ul>\n</li>\n<li><a href=\"#default-filters\">Default Filters</a></li>\n<li><a href=\"#generating-filters\">Generating Filters</a><ul>\n<li><a href=\"#finding-ip-addresses-by-using-generated-filters\">Finding IP addresses by using generated filters</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>Wireshark's display filter is a bar located at the top, just above where the packets are being shown.</p>\n<p>This is where you type expressions to filter the frames, IP packets, or TCP segments.</p>\n<p>The screenshot below shows the display filter being used to only show packets using TCP:</p>\n<p><img alt=\"Wireshark Display Filter\" src=\"https://lh3.googleusercontent.com/VtovFjwfL1fIKWCN8cZ1D_D_gM0sRlACU-Tj0aOGRDkuVj1MFb7fw5oS4qLkcWMXNwDvFumS546eKLJqwMGztwep24tC-DQKgp13lLVO1SRSATgNERooMwBDqc4d6E3GmLFkg56HekgIiAaFp46KUfhNMlHMm8r0zfqYlHmgzj9F5Lu0LMD8Umk_MKZrDW-n0GGVBQabe4pEx0nO2OBXbJxCzJqWzUd9f9czTTWNacs2XTj2nl3kQdMxmFyM4GJoZNAORRyj60PwT83RGyprUwDNnlTXGojOqsrMzktKbUCIpIre4nSZN8vwl_kfKr69p-GDO-DBt9dMHZh7dw2gg2hH8eqOZA5FPs1bwTcJJySrBRzWmFV1u6DW1RySHfFFglno2r3wzWMeyrG0rMLZBYDZiBNfvlMOOTLG_jK8WZ-fyFBQ367oUerKerL6GKwSWvP86VfA1YhZNwrjSQvIxmJAZCbeFpU5A0LJkyNnolOashFVHqIktURpgc2ZkeyJa_hjFvN3qzJ6upw9f7pi-TTnoIhT6BP8W70LpGHuxxb_NncEQj6_sHm0Ksfnv14hz5yraDRKliSTzx87l4izwMSL45neSozGzpR_8feTc3ouSTyoS5hoE1lRLLg4UEmtbvlkWOC_oN2qQLs-QGgWCVu52jcyBEsUtVCFUHKOC7QxGm2227d1uHG0XjIYLITYd_sIgDAUo3oG7lskrtL06Xcchpjf31N4Hovmo3Z0inFOBThP=w1168-h404-no\" /></p>\n<h2>Filtering by Protocol</h2>\n<p>We can use the display filter to only show a certain protocol acronym.</p>\n<p>It's important to keep the letters <strong>lowercase</strong> however:</p>\n<table>\n<thead>\n<tr>\n<th>Protocol</th>\n<th align=\"center\">Display Filter Value</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Transmission Control Protocol (TCP)</td>\n<td align=\"center\"><code>tcp</code></td>\n</tr>\n<tr>\n<td>User Datagram Protocol (UDP)</td>\n<td align=\"center\"><code>udp</code></td>\n</tr>\n<tr>\n<td>Internet Control Message Protocol (ICMP)</td>\n<td align=\"center\"><code>icmp</code></td>\n</tr>\n<tr>\n<td>Server Message Block (SMB)</td>\n<td align=\"center\"><code>smb</code></td>\n</tr>\n</tbody>\n</table>\n<p>Here's an example for filtering out packets using the ICMP protocol while a <code>ping</code> command to <code>google.com</code> was being run:</p>\n<p><img alt=\"ICMP Display Filter\" src=\"https://lh3.googleusercontent.com/W1j_AtrwMCGBhr3yRUnMc50qgVoltCOT1AnFXXSU9U_8TcSsi1rXDsoPnKiAXxUllgfHsN4dXLB2Bq09aVvPfhwYKgCAQLDoa5hWNnEZ2nvc6HNSB1lZDafJl61jg-ZXwaaRXf687Fyi0viLOO5dUpJoy6IcabiMiKAUDmpjbVXrfg0E11sTT-rFXIF0ecanlyvQl0KsJyugNM3NpoYaDnXSQuhDfCfESy9wF7YHpsMXhadOCk27DVheYB5vEVHFH7GTEmEU8eBxXTI32edzXU14UN1wCUEBv4OqVUEmrt36SweGI1TJ8XW6rT70Zs5Dt1raERiZnLHwYAkG9axjn2SMrCtcXNC1fALajWJ-v5V42qJry_EEs-BLGhwwFPBSWnayEhOHHUHf7GjTVlLIW51ZfVNbdNB9tBkW9s6RNbO6KYXtKe7gtx4WXeDBIVNfy3CK0j8pHdvWDE6K4A6ghpv0a2Gn0ASYGtW13sU90VwR6zmwmYW57Cjm1R9c93amp3SzKoqHEYGJ5fH_qF-lHH7b0UGpLGXeu05K-plJ7lBWJPyOqSMk_2jGwki5hjr-vFMajJu0CrdfdfSD2gQGG-LsUZCgVUbtBS7jUhDeHpOrYpAW6GNNrZ8Gq3hGVlniI9pW_uN3TG8KPuHO47_KGhlWRRXoaiwyiTACFZL187_gveZGYwiTlnC53BA5L4nqzdLXhX1WJ4usBTdZeiBaOVZT8UT-HyAA1EBxeFOhi2eTPWHW=w1168-h339-no\" /></p>\n<h2>Relational Operators</h2>\n<p>The operators here have the same logic as most programming language.</p>\n<p>When the condition that you put into the display filter equates to true, the packet will be shown.</p>\n<table>\n<thead>\n<tr>\n<th>Operator</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>eq</code>, <code>==</code></td>\n<td>Checks if the values of two operands are equal or not, if yes then condition becomes true. An example of this would be checking if the packet is from a certain host: <code>ip.host == example.com</code></td>\n</tr>\n<tr>\n<td><code>!=</code></td>\n<td>Checks if the values of two operands are not equal, if values are not equal then condition becomes true. You could use this to show packets <strong>not</strong> coming from port <code>80</code> for instance: <code>tcp.port != 80</code></td>\n</tr>\n</tbody>\n</table>\n<p>This is an example of a display filter only showing packets coming from the same network (assuming your LAN CIDR is <code>192.168.1.0/24</code>):</p>\n<p><img alt=\"LAN CIDR Display Filter\" src=\"https://lh3.googleusercontent.com/6CwjtGqMl4NkyBbg7vmK86Kl4G_Las0jBT55O4pRbRCLIqkGGJ2HyL5HmUMZWyTu4e1MQ63m5dLaXjlQJ3BFy-nk5NOStU-asvSoo_8vl3lW3Kg2x5eA6JR25pyOb72VyRj1yyh6JF7uwIWNPz4Ad0yZIxLzvIkEsAbOblv4UwuusxrVoKPosDqVad0ndkWthd-WWbhbW21m-wB3aM6z0vLrJ8oKwmVHejE_6fKg8WxlXc-56tp_kYVqHj2Wn0NAmPJZSSTsXUnKHOHvYvXxM1trL5UU0snyeDQ6EDZgCqbGMy1oeEcThQxOSw05GuL8OYS7yLm6nkPSz_6_VzQ5FteQBmpzEh1PqyGhAofMVSaCevCH764jn8SDNHWq0hBVQV9MpCbgTJk4LlQ7mu27J5PqrQb62oC_ifZir4OIApmp8RwMoy6ORsLeUgwvDUj0S9ogKM4LiunfwpQJfDv0dfujnBdmPl_E888jMzOrK6TNfhHl0kSzzJqftX9fR7iMDRC6W4BkQ2sWOuwKjPeCa_MWW1m7LZp5mcztXo7sWSOayTiQp6hoeYRtniDQWWwcLRrxJr-yh0tR0lCZRCJ3uKfMySLxuCHFvl3waw21WGFJuISKTMPlakdSdhR97GNiMWRLH_D3jR9fVlY2g4G8ieMwob8asaSDD7Fhlxh048gzpxhxPBvrjX3tifkcxWlkwvgdH4fJb6DRIF84KxULv4zA0QZizWsc0ubl2iG2MAyRKv8G=w914-h266-no\" /></p>\n<h2>Filtering by Port</h2>\n<p>We can check for connections to a specific in-use port with <code>tcp.port</code>.</p>\n<p>For instance, if we wanted to check connections on port 52036:</p>\n<p><img alt=\"High Port Display Filter\" src=\"https://i.imgur.com/nz2P16e.png\" /></p>\n<p>Wireshark also allows for testing multiple ports through a specific membership operator, <code>in { }</code>. Values within the curly brackets have to be separated with an empty space.</p>\n<p>Here, checking for activity across multiple ports is very easy. Let's add another port (e.g. 51728) to the programs we're filtering connections with:</p>\n<p><img alt=\"High Ports Display Filter\" src=\"https://i.imgur.com/KnBznnK.png\" /></p>\n<h2>Logical Operators</h2>\n<p>Logical operators allow us to chain conditions to make much more complex and specific filters.</p>\n<p>The operators are <code>and</code>, <code>or</code> and <code>not</code>:</p>\n<table>\n<thead>\n<tr>\n<th>Operator</th>\n<th>Description</th>\n<th>Example</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>and</code>, <code>&amp;&amp;</code></td>\n<td>Logical AND operator. If both the operands are true, then the condition becomes true.</td>\n<td>Show only traffic on the LAN (192.168.1.x), not internet traffic: <code>ip.src==192.168.1.0/24 and ip.dst==192.168.1.0/24</code></td>\n</tr>\n<tr>\n<td><code>or</code>, <code> &#124;&#124; </code></td>\n<td>Logical OR Operator. If any of the two operands is true, then condition becomes true.</td>\n<td>Show only SMTP (TCP port 25) and ICMP Traffic: <code>tcp.port eq 25 or icmp</code></td>\n</tr>\n<tr>\n<td><code>!</code></td>\n<td>Logical NOT Operator. Use to reverses the logical state of its operand. If a condition is true then Logical NOT operator will make false.</td>\n<td>Show traffic that is <strong>not</strong> TCP: <code>! tcp</code></td>\n</tr>\n</tbody>\n</table>\n<p>This screenshot shows the <code>OR</code> operator being used to show only TCP and UDP traffic:</p>\n<p><img alt=\"TCP or UDP Display Filter\" src=\"https://lh3.googleusercontent.com/s7gigEWszpwt0APSZOQkmnKx3lrT3PIKTVXurtak5b8Cmns1tCXupkHebkeMnLE6UEruCNURqRffOVEuAm4D_CdGIB5l322zS64oRfXoH49o-WlPhOPMHxhAFYwjpSLKOmzjf2LXxGwA2Pfi4GhSKH6D0gUNuEBCKTWGmSr6lUbru6yLrdLvNYqsTPeN8xTbnUv8zoNDeDcCGi85kkWoRLnWLiNdh-tmyzR5zm2WwoJjieZj3ppKskV36Lg_alOG-bXWttS2LgMaa6nnIo-qz7dldXMTLt7lmQ_Tp3fNlkh1gmnu7CHhqAHTt3W3ga1qpiCMZXaj4mRr86MZqMAE84ovR5FVLsRQuDIjnUDMJlGhJe1qkNg92hHrbQTPAZ56E98Ag2C1Q3vcfUMXRgOh_TW0TeV8RwUh5mf2ioSS_rvkC5uYSuFJhDWpGUD0Hza0zKa-Jg9P6FAhdJ_M7C-LJ8neDAcJmK9Tq0l7BA73iX9-Lmesg9_425qCaf2mpTBq7G4nfPQYbRjWPqTQrxGi32kllDnWjL2SmFJPPriXf8H3sisGrbSmLMdyq8dnF-BA4Vd2owCG-ubg0WRj5unh_W9kJqedcyo-cZsDNWoDySbv3a3IR2QcUjfoNIV3PvJ1LDbEm-0hqdZnD0Cw8h--_ryYIe9WqvZ7NQFINe1LiI4hTA2YnFtw4MWMlivrdY1zN4Po9AujxCq3ezvJ07lM658GvBfX2_EfB2GXCxgOh4qKNUNH=w1165-h341-no\" /></p>\n<h2>Filter by Host &amp; Address</h2>\n<h3>IPV4</h3>\n<p>We can specify which host or address to filter out by using <code>ip.addr</code> for domain names like <code>example.com</code> and IPV4 addresses such as <code>172.217.169.78</code>.</p>\n<p>This example will filter out packets for <code>example.com</code>:</p>\n<pre><code class=\"text\">ip.addr == example.com\n</code></pre>\n\n<p>This doesn't have to be a hostname; we can use just a regular IPV4 address as well:</p>\n<pre><code class=\"text\">ip.addr == 93.184.216.34\n</code></pre>\n\n<h3>IPV6</h3>\n<p>To filter by an IPV6 address we can use <code>ipv6.addr</code> to create conditions; this example will show packets for <code>2606:2800:220:1:248:1893:25c8:1946</code>:</p>\n<pre><code class=\"text\">ipv6.addr == 2606:2800:220:1:248:1893:25c8:1946\n</code></pre>\n\n<h2>Filter by Network</h2>\n<p>The CIDR of a network can be provided in the display filter to only show connections on a certain network.</p>\n<p>You may, for instance, only want to see the traffic on your <strong>L</strong>ocal <strong>A</strong>rea <strong>N</strong>etwork (LAN), or vice-versa.</p>\n<p>To see only TCP traffic on a LAN with a CIDR block of <code>192.168.1.0/24</code> we can use the display filter <code>ip.src == 192.168.1.0/24 and ip.dst == 192.168.1.0/24 and tcp</code>:</p>\n<p><img alt=\"TCP LAN Display Filter\" src=\"https://lh3.googleusercontent.com/Acx9D9IbLldO3xcxhO2uBkSvTHxSMAqOFN4PCwLbHoTQlBkL62SYu50pK4gxWUEylLBSYq6XpAZzZDprZaUBtO4A3C38y1pgMDdNrKk6dHS0mgHrNhoa_-XVLgSx9M6dFeWXXxuBrfbCrHU9-nFlsC0HHdoeVks3iseotT8xh0LbULIFerwMGSQhUUvekgjH-4GrMIPEjGhYmWHbOKb1h1O_Ya4pUy7m_GvvZqdpj8HQP4GquEDyddcvIbFjpf6dNsjhH7pv_uQdqR3IYgL4iTykMqrtkpcWR09B3Fc49gEoG2sIzFqcOkAGJoezOuJoCaqeK7Puyfyaf639sHRtxk4Nq_3IOPQiAWXd6mYrtxKC1BGJpJrHZg307vGiTNLmQRdbmzecMXVtiEBhZuWQUt7r6_atRO6Ur5rR9DRzn4opqsznPPv___hetoRN8b_IJKGauwi37RM3_Fgp_WoMnQT77_Tce3RKgspHIKhllTQ3mqSlMWTxQ21q41gmFu0qWZ8ZTb021gi61QQY5aNp9kV89B7r1iW9MUhA-4v-5M2yivPEXwU1fI6AomjMPlU83t_cLngMAbtFx7Esb_O8BFZn878pxKH1rfzjCMzKjuEBT-up1QLrplv3gPssErO6s8WoppupzUByfaR-ALLqI-YC6YQSiV3tAYGeYORfF_he0wZOP08OrGLrX8rmCHF5ZaE4fYvuuTmMIt27NHKQna1z46bBvaOOMrL3almL6fftOoqE=w1165-h302-no\" /></p>\n<h2>Tasks</h2>\n<h3>TCP</h3>\n<p>Lets start by displaying only TCP traffic by using just <code>tcp</code> as the display filter:</p>\n<p><img alt=\"TCP Display Filter\" src=\"https://lh3.googleusercontent.com/VtovFjwfL1fIKWCN8cZ1D_D_gM0sRlACU-Tj0aOGRDkuVj1MFb7fw5oS4qLkcWMXNwDvFumS546eKLJqwMGztwep24tC-DQKgp13lLVO1SRSATgNERooMwBDqc4d6E3GmLFkg56HekgIiAaFp46KUfhNMlHMm8r0zfqYlHmgzj9F5Lu0LMD8Umk_MKZrDW-n0GGVBQabe4pEx0nO2OBXbJxCzJqWzUd9f9czTTWNacs2XTj2nl3kQdMxmFyM4GJoZNAORRyj60PwT83RGyprUwDNnlTXGojOqsrMzktKbUCIpIre4nSZN8vwl_kfKr69p-GDO-DBt9dMHZh7dw2gg2hH8eqOZA5FPs1bwTcJJySrBRzWmFV1u6DW1RySHfFFglno2r3wzWMeyrG0rMLZBYDZiBNfvlMOOTLG_jK8WZ-fyFBQ367oUerKerL6GKwSWvP86VfA1YhZNwrjSQvIxmJAZCbeFpU5A0LJkyNnolOashFVHqIktURpgc2ZkeyJa_hjFvN3qzJ6upw9f7pi-TTnoIhT6BP8W70LpGHuxxb_NncEQj6_sHm0Ksfnv14hz5yraDRKliSTzx87l4izwMSL45neSozGzpR_8feTc3ouSTyoS5hoE1lRLLg4UEmtbvlkWOC_oN2qQLs-QGgWCVu52jcyBEsUtVCFUHKOC7QxGm2227d1uHG0XjIYLITYd_sIgDAUo3oG7lskrtL06Xcchpjf31N4Hovmo3Z0inFOBThP=w1168-h404-no\" /></p>\n<h3>Display Your Machine's Incoming and Outgoing Packets</h3>\n<p>For this part you will need to know what your private IP address is.</p>\n<p>You can find your private IP address in Linux by typing <code>ifconfig</code> (in Windows type <code>ipconfig</code>) into a command window:</p>\n<p><img alt=\"Private IP ipconfig\" src=\"https://i.imgur.com/Bn4GABx.png\" /></p>\n<h4>Incoming Traffic</h4>\n<p>You can display incoming traffic to your private IP address by filtering by destination <code>ip.dst</code>:</p>\n<p><img alt=\"Incoming Traffic Display Filter\" src=\"https://i.imgur.com/ekZsmlN.png\" /></p>\n<h4>Outgoing Traffic</h4>\n<p>You can display outgoing traffic by filtering by source <code>ip.src</code>:</p>\n<p><img alt=\"Outgoing Traffic Display Filter\" src=\"https://i.imgur.com/A2aUj5V.png\" /></p>\n<h3>Default Filters</h3>\n<p>You can also click <strong>Analyze &gt; Display Filters</strong> to choose from the default filters Wireshark comes bundled with.</p>\n<p>From there, you can add and remove your own custom filters with the <strong>+</strong> and <strong>-</strong> buttons at the bottom of the panel.</p>\n<p>Let's add in a filter for the TCP-only traffic on our LAN with the filter we looked at earlier.</p>\n<p>After clicking the <strong>+</strong> button you can type in the details needed for the filter:</p>\n<ul>\n<li>\n<p>Since you will only need to worry about TCP traffic, use the <code>tcp</code> filter.</p>\n</li>\n<li>\n<p>You also need to set the source <code>ip.src</code> and destination <code>ip.dst</code> to your private IP address.</p>\n</li>\n</ul>\n<p>Give the new filter a meaningful name. Since we're looking for TCP traffic going both to and from a particular CIDR (your private IP), this is relatively easy:</p>\n<p><img alt=\"LAN TCP-Only Display Filter\" src=\"https://i.imgur.com/yTZB3Pi.png\" /></p>\n<h3>Generating Filters</h3>\n<p>Any packet that Wireshark finds can be used as the basis for its own filter.</p>\n<p>Let's try this out by right-clicking any packet and click <strong>Apply as Filter &gt; Selected</strong> to see this happening:</p>\n<p><img alt=\"Right-Click Display Filter\" src=\"https://i.imgur.com/NW7HoI7.png\" /></p>\n<h4>Finding IP addresses by using generated filters</h4>\n<p>This has a number of real-world applications.</p>\n<p>As an example, let's say we want to get the IP addresses of the Spotify servers which some  machine is currently streaming music from.</p>\n<p>We can start by opening a command window and typing <code>netstat -bn</code> to see all the ports which are currently open, along with the services running on them:</p>\n<p><img alt=\"Netstat Show Ports\" src=\"https://i.imgur.com/DnQg6dm.png\" /></p>\n<p>Spotify appears in this list a few times thanks to the distributed nature of music streaming services.</p>\n<p>Luckily, we can plug all the ports which Spotify is using into Wireshark by using the membership operator <code>in {...}</code> we explored earlier.</p>\n<p>This will filter to show all the traffic moving between Spotify and our machine:</p>\n<p><img alt=\"Spotify TCP Traffic Filter\" src=\"https://i.imgur.com/iJ3s3ZG.png\" /></p>\n<p>There are a few IP addresses flying around here, so let's make things easier for ourselves by first filtering in the conventional way.</p>\n<p>Let's keep the port filter from earlier in place, but now we also want to restrict this filter to show only packets <strong>received</strong> by the machine (<code>ip.dst==192.168.1.154</code>).</p>\n<p>This will give a list of traffic coming in specifically from Spotify servers:</p>\n<p><img alt=\"Spotify TCP Received Packets Filter\" src=\"https://i.imgur.com/01fpgbV.png\" /></p>\n<p>We can see that there are two source IP addresses in the list.</p>\n<p>On one of these packets, right-click inside the <strong>Source</strong> column, then click <strong>Prepare a Filter &gt; Selected</strong> to start building a filter.</p>\n<p>For the second IP address, right-click as before, but then use <strong>Apply as Filter &gt; or Selected</strong>.</p>\n<p>The filter will generate itself in the bar at the top:</p>\n<p><img alt=\"Spotify TCP Received Packets Filter\" src=\"https://i.imgur.com/g1Ht8kT.gif\" /></p>\n<p>For longer and more complex filters, generating filters is invaluable.\n<img alt=\"Right-Click Display Filter\" src=\"https://i.imgur.com/NW7HoI7.png\" /></p>"}, {"estTime": 15, "software": [{"name": "Wireshark", "version": "3.0.3", "platform": "windows", "downloadURL": "https://1.na.dl.wireshark.org/win64/Wireshark-win64-{{VERSION}}.exe"}], "gitUri": "topics/wireshark/modules/introduction", "overview": "Wireshark is a free and open-source packet analyzer.", "name": "Introduction", "resourceName": "wireshark/introduction", "content": "<!--PROPS\n{\n    \"estTime\": 15,\n    \"software\": [\n        {\n            \"name\": \"Wireshark\",\n            \"version\": \"3.0.3\",\n            \"platform\": \"windows\",\n            \"downloadURL\": \"https://1.na.dl.wireshark.org/win64/Wireshark-win64-{{VERSION}}.exe\"\n        }\n    ]\n}\n-->\n\n<h1>Introduction</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#purpose\">Purpose</a></li>\n<li><a href=\"#installation\">Installation</a><ul>\n<li><a href=\"#windows\">Windows</a></li>\n<li><a href=\"#ubuntudebian\">Ubuntu/Debian</a></li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#open-wireshark\">Open Wireshark</a></li>\n<li><a href=\"#select-a-network-interface\">Select a Network Interface</a></li>\n<li><a href=\"#filter-packets-by-host-name\">Filter Packets by Host Name</a></li>\n<li><a href=\"#make-some-packets-for-wireshark-to-capture\">Make Some Packets for Wireshark to Capture</a></li>\n<li><a href=\"#following-the-http-stream\">Following the HTTP Stream</a></li>\n<li><a href=\"#anaylsing-the-http-stream\">Anaylsing the HTTP Stream</a></li>\n<li><a href=\"#importance-of-https\">Importance of HTTPS</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>Wireshark is a free and open-source packet analyzer.\nIt is used for network troubleshooting, analysis, software and communications protocol development, and education.</p>\n<h2>Purpose</h2>\n<ul>\n<li>Network administrators use it to troubleshoot network problems</li>\n<li>Network security engineers use it to examine security problems</li>\n<li>Quality Assurance (QA) engineers use it to verify network applications</li>\n<li>Developers use it to debug protocol implementations</li>\n<li>People use it to learn network protocol internals</li>\n</ul>\n<h2>Installation</h2>\n<h3>Windows</h3>\n<p>There is a setup utility available for Wireshark on Windows.\nYou download it from <a href=\"https://1.na.dl.wireshark.org/win64/Wireshark-win64-3.0.3.exe\">here</a> then run the setup.</p>\n<h3>Ubuntu/Debian</h3>\n<p>Wireshark can be installed via <code>apt</code>:</p>\n<pre><code class=\"bash\">sudo apt install -y wireshark\n</code></pre>\n\n<h2>Tasks</h2>\n<h3>Open Wireshark</h3>\n<p>You can open Wireshark on Linux by running <code>sudo wireshark</code>. On Windows, you should be able to find it by searching for <code>wireshark</code> in the start menu.</p>\n<h3>Select a Network Interface</h3>\n<p>Wireshark will list the available network interfaces to monitor.\nYou will need to select the one that you are using to connect to the internet, by double clicking it.\nIf you are not sure which one that is, here are some points to consider:\n- If you are on a wired connection, the interface to use will likely be called something like<code>Ethernet</code> or <code>enps01</code> on Linux.\n- If you are on a wireless connection, the interface to use will likely be called something like<code>Wifi</code> or <code>wlan0</code> on Linux.\n<img alt=\"Interface Selection\" src=\"https://lh3.googleusercontent.com/WF_XlRG_wy53COd3ZSCBeOTogdCo4xICsjXqfjlR2Qyc3jKDLZ3ZHEigcOB5uzL0JloQTR8R16uN6HoFYAaCW9KVmNH4zh8VMI2e08kiM_9c9mUXClcKgNJtE3bF0n8mWdbEmAgEjOsVFFclthV-fyWvTGdI9uAc1itWzr3C4so10fY4m9OFfaJFgLnMZGZJLbbwsMwCrg910ceY74CF1L4ihdSq8mVlpGen6qeyFUAdgch3ZiC0s-n5gp3NRm9r0VkVtndy6Fp6uT0uvPKQnRjjgqfi2GvlWLAz0RomX_kCSMPRw42qi2DpA7rtCTkG4QvJNvOgIe5_pU9gagq_bUbAfo66rT_kd_qMmIgV9tvaQ0X-Wcizk9QSBDUttxmduzkwWJ3Fpei8_V0shNnLMS5eH9RnqgOZwNMdSVq6bYOWFl26IbVFqeftpi5RLlClUNx0VhxLZklLUgzMRuBIn2yWyPU4mi18SFL_C0M_cK6A0-EZFi-cv2W1VRUTOAFAEMp_N8PIwkmkXDQSXdWT7ZhsWqCBK_8pZLJFJooK3DOnntcd1Ac7fN-lNEukWV27lx6EtEiNFuST_HK_N4n79fxy6FIM8-SeVk3cLGqy_1F6BSZ4D83dQcHvrj7jymKZ4gGE2nGp5wuFFD1H2aS3Q1h1tgWA4HaIjcwnEl9X8dU4MTEQTRA5TPEltTPmf-wOrH9KjbisUkogSUh1kNQhN2JrfYbAgxHWzC8eKOWHTsTkiFbl=w903-h417-no\" /></p>\n<h3>Filter Packets by Host Name</h3>\n<p>You should now see Wireshark recording lots of packets, which are flying around your local area network (LAN).\nWe will need to use the filtering tool to help us find what we want.\nSet the display filter to be <code>http.host == example.com</code> and press either <code>Enter</code> on your keyboard or the arrow button on the display filter box.\nThe display should now be empty:\n<img alt=\"HTTP Host Filter\" src=\"https://lh3.googleusercontent.com/jAWTt1VhcdQ6bvsVHcENGHj6EjZVOeHKwJ4zGbK_6tMArVh6_ha3xxl2TxhxpBOoPK36zJ6CxBjVcAhnPDNfp6LVPhJNDSZgu_t66PgY5xw0mhvg006dqHY5DPBmPIk7dM9XZsDQVuikV7O_PUvzuuaWwHG7HHOznHhhSohzHEpM1lNrruM_AKu5jVjZMnHM31bWiAPFOWQIuNsIzoU6fob_RtKhMcHaGMUkEDyWwssv7LEgRft9l13j_L5jn8dafPp-s_STdC5zcvxhbcUY-HmO3ItudInfke6Hc1AdosHjASorACYWzixUz1XonP_SRHdtzrOMWDuCusnpYc56U9tjxANWBrRcoQN6g8QEAFyovib9oKDNcwLJao2wkXrbpUwVPQwiMscc4N6YQ22DjFfwCdoJn6Mob3DkRHwnVMh5yMdhWIXSveLEDVRF9aXHMpFmePavA5-qzPU0BelaNqrAEJ239NjXRi0GNY2HZiFEDL7yUzlh9hjGaDkOMN_GFNTcJKh1_OJJIIs1sas-7nsw3iPq3A6lxM9AAAxK1fTeKedwVqPt2w7mTAa-GJ1mitaGqygGOo8aVM-SQkAuWp7tDwdl1_2B_1S2I7F-QvF4s4Fw_xzxkQaiKWd6wpgb6Ry3-EIahtHE4VOq6SRRM89yCmaqqCKcoHrx9ce6Q5uv96vMB0ilthdUFZwv090i_fKQjleN3ZQFqqLIR4iS2n6jgUYka1_6fZfleI72QjmWjn4F=w929-h417-no\" /></p>\n<h3>Make Some Packets for Wireshark to Capture</h3>\n<p>At the moment, the display filter is only going to show connections that are made to <code>example.com</code>.\nOpen <a href=\"http://example.com\">example.com</a> in your web browser.\nYou should now see some packets appear in Wireshark.</p>\n<h3>Following the HTTP Stream</h3>\n<p>Packets transmitted over a network are tiny; we need to piece them together by following the HTTP Stream.\nFollow the HTTP Stream by right clicking on the packet for <code>GET /</code>, then selecting <code>Follow</code> -&gt; <code>HTTP Stream</code>.\n<img alt=\"Follow HTTP Stream\" src=\"https://lh3.googleusercontent.com/aazYyiTkX-uH1qTJx4KZefs6iw_dDN68kZVCSxSHmOFXltX30pr4pbxknrWW2fxzpaCiOqE-9LRY2zC8fvpjHKYks9mJB4BL2M_ZoeZl7RS6GhqkMGAQ-sx-qTJsH0Iga4g_-yjfceCYaCi3oex9wrr3JoDImLURyO95zp4yYT8N6x8tlOJFGNSljO5ag5oqEvyMeYx0Nsrr-RtoPZwV0oHN5ds9bZ9TGXHmXCzNpxQi-RJnCDnqE_IK1gf6V0RPPfQeLn4k_IUY-Vbmzov4bs0WjI3vUInCNznRYfQdPnO9jl3C18U39s4a0lsM-HRw0qdaFWgJGgvvn9ft_OY1qFn_cS08QjM3Q1E19pYJIQSIEnBFWSvES-UXeQ7XY5iFBjYu-igPnPL9_HopB97J98_svT-OAaUDGFG6MPBjyFT65L7OH_ed3cODr28SzVxLrbCYOo4U90-JG42YBjxnJw8mdbM0-KKuqOxDpRh19kgRveRbVC_gFs8M8fzFbq4zT_A2OEKQnEDqSxk0Wt7cfw2LeeVGZRKt6uaUQ2HcWcNefZCKSq4gRaZMfEjJUE1xod33dlxK95r3C-goFEOqY_ZTrS4e4F3degkRsI4OngO-G_VbJB1T6VZIPDcEOl9yePeNC_oGa4-920Cvw9HrbABo2ucNmTKxcgTuYT7yVFrik3YC7KnQa8-gtpwPnLjXK35B2yb3taEhOYHMumpmQBaJFh1oVA9BkCio8aWM25LVpQo2=w927-h522-no\" /></p>\n<h3>Anaylsing the HTTP Stream</h3>\n<p>A new window should now pop up, containing the HTTP Stream for the connection that you made to <code>example.com</code>.\nThis window is showing us all the information about the connection, including what was downloaded - you should be able to see the HTML for <code>example.com</code>:\n<img alt=\"HTTP Stream\" src=\"https://lh3.googleusercontent.com/sSh_JjuzZFgGO1YgJc68SbrDTKWQvW7Hd7gQVw918Po-Bx0Bv3hGtRp2hatutIp1JVMou2FKkiGmI2IaIOLF5vJMwWMt2fb7PkeVEWSwgt9ZHOx1Nn8cAL3sRvLxhSj0FYqLvuCrobkhR1mS64c-svzh9WMpFSx7o2ibZmET54faQgvW0O_X7DRw0YNonv8t9YUEj1cUeJC6GTn5L-0oQZXeR21OqAWFzg1PgIkgGwbjxxdBu4vCjj-jzPlxWnmCyjVLXzkpaqpBec7XckPFajR67oNSSyr9fkj0SXQJ1fh4t7wr2zc-wkCkS7tz4n6atsS0e-b4u2kqkOKUgqMfV75Dt659b3kp_EnGP4SpMESaEvqeJdDbV51aREXqgvUWRwbn2Ztp11PjxNts7LvV5e_pzC8YjnnYFVTSKiVMo83VDNgcPqj2rTS9D7D3zl3fgpmbkfHKC4IzIq8sCzc9XuB54VR8cERHZNrc7Qd9hie63XvWGm7TO-dprcEWCenhL0jUqDkSKGppSfgi4B7cYNIROwu0VxOcV6MvJMAZI-peC0ruKDYldFERwEeQRRMdcwsq0welc_3Yd7y_rJ-F0-BYa8nbw0UGGqSv5fvgH1pL5ldWDZ11sV1n6WkmeH5wMVFmN_Tg_gd0GKVLYo0X5nkBix0G4DoGRC9xaVmtWdDfW--1lS4Rlgt5fZbrle_v2pLbOcpMLG3E8Lt1S05OnuX50Kelf_bXfrUYA9noSqv7WEza=w868-h1118-no\" /></p>\n<h3>Importance of HTTPS</h3>\n<p>Notice that we connected to <code>example.com</code> using HTTP, and not HTTPS.\nThis means that anyone on the same network as you could have ran Wireshark as well, and be viewing this information.\nLets now look at packets that have been transmitted over HTTPS and see what difference there is:\n- Close the HTTP Stream Window, seen previously\n- Stop Wireshark from scanning by clicking the red stop button.\n- Find out the IPV6 address of <code>example.com</code> by using <code>ping</code>. You can use <code>ping -n 1 -6 example.com</code> on Windows and <code>ping -c 1 -6 example.com</code> on Linux. The IPV6 address can then be taken from the output; in this case, the value is <code>2606:2800:220:1:248:1893:25c8:1946</code>:</p>\n<pre><code>```text\nPinging example.com [2606:2800:220:1:248:1893:25c8:1946] with 32 bytes of data:\nReply from 2606:2800:220:1:248:1893:25c8:1946: time=89ms\n\nPing statistics for 2606:2800:220:1:248:1893:25c8:1946:\n    Packets: Sent = 1, Received = 1, Lost = 0 (0% loss),\nApproximate round trip times in milli-seconds:\n    Minimum = 89ms, Maximum = 89ms, Average = 89ms\n```\n</code></pre>\n<ul>\n<li>Enter <code>ipv6.addr==2606:2800:220:1:248:1893:25c8:1946</code> into the display filter on Wireshark, changing <code>2606:2800:220:1:248:1893:25c8:1946</code> to the IPV6 address you just got from running the <code>ping</code> command.\n    <img alt=\"IPV6 Address Display Filter\" src=\"https://lh3.googleusercontent.com/JwQQm8tcKqO7O9W5XhHUomKQgl59fbQpa5_MtT6d-jklXfGO1Go5uikSU82a5NOIDamYdea_yBsRDSk6CXLyJHevarWOxb2LewhlScB52hBTvh3XykJNzGU9_VDAtCMPChpgovnbqbcZtE-aprfJWZ_vqmW11TJE7bspKRaDcNsyXQ8invnL8VO99WC3sYAX3vYagUBSY7AqB32tjNu_OBgUEkIq9BaPRnVK4heppD0ORpdMQieOK_lHnCmS0wM3rI7tNI4K5PGDIZAK9dlE5i_REbbR1U7_r_mN8fQJ89gUu-JYFMR5rEOWQ81KGOpwKG98If2JMvjO8Kfedu3RCKfZ1F07fehlI19V_zhm47U8LzUI8okSpcfoGb1WWQPsAQNklV9slZuD6qZN4Fvqjc1KliB0LBf0QAZWfGMTyEkqnht73azX4HFVjITt-RDAEbKExyVLVYTylnkKHkDkN72ggCG8ux-mP5G3gNr4GlzhsT1nIO2La7oxZflOKG37MHqvFiXPsvEKwZjX4lVD72iIwygYl9zrgC-rD9stv0RO5T9Zoe1twB6PZ6uKneZcedkr2lBfiapDZhlaRVjaO3FVmha9tGDyTAEntQVOxXaNacC5p5ibfsxavOEMRxLWq3HEd_Cn2NXqXptKnGXCyD8ow1dQrnRMKgHJJ9gqP51fYZm5DQBfs6b2KM5eio__thqSL4pzDiTa4BxZWfi8NAU7hN8TD50bXTCGWYc8AgMSlAxL=w810-h22-no\" /></li>\n<li>Run a scan on Wireshark again by clicking on the blue shark fin.</li>\n<li>Navigate to https://example.com in your web browser. You should see packets starting to appear in Wireshark</li>\n<li>Follow the TCP stream from <code>Client Hello</code>.\n<img alt=\"HTTPS TCP Stream\" src=\"https://lh3.googleusercontent.com/2GEtYKYbiUn28ilXzLTkIcYJQ64c6oeeadNzlPj6Ocd28RYOolJZ1IZjTeLXgVyxp1s0j4aIhfER6N8QDfNhxyuwcOlhqZxf5LxMeWATNodt7gDRQgx59GWOF-fej8eMsjc_LV3vidR0DV9mwsaiVT2XYtPkNoXLT03a0NJJ9ZGqF2Aw66lpXGkxQ0fekBkZpMs_Kq9sRqd9ze6aX4ewN5TwOirVFA7Gct5Vjlv2uwDZcyslRQqi8FGn4U87R6O4hVrG8NY6API9G8yG8lgbd-l_PeDyIsHIAvCtvMVXhgem-RvjeGvI9udEBrCZtaLGj_PFs85tpcNOBqFJ6TKz3ebbzQQKXvm5Pc6JZ5IOLcWMfGzOoyHTMxEYMxG-0yfmWs-QLbCSrUeYB0AO7Ca5PAa3ECNbps1bNcdCdc7nqDDQ2dhXgQH-CiSnccY3MpvYjJeP2nSvCQvyWi_hN0buPma1rHgD85lhSw94SPff0alkVqn4C5KaEJohWsfJP7ONi8wmWPiBV9ztZzuzL0RpZwQtkJXKhFPLDS77ZGhb5uihc7Yzb8a6IP9y-e5cWEyfc7kDYIoevQPyHocLV5wQfyvL53sRrLgjqaYpOQGaTJrEMRaGKS_6BhYPcRsIdoibwbpcZUV9RKZLGX1yOTRroFoijmUddUHjF3DQ9KN68p75qqL5CsZFrP1ilf3KZJoSUIhDNid-lAa47_blvoxHL7WrFWpymh-gSa03XdrKFEHaaNaG=w910-h650-no\" /></li>\n<li>You can see here that the whole stream of data is completey unreadable thanks to HTTPS:\n<img alt=\"TLS TCP Stream\" src=\"https://lh3.googleusercontent.com/haTm06zIEFxpct3_dO1TcAMAsyUuAXF36Hi5adCHcFlMRRI08rjDj94pElyD-VcLilTh6Ua-WgtSbvakl9w5x66KU-Gub17piBEjoB-z8gZO42ceIQxDdArED2SCiCgjgSA4Bv2lS9qeqeNz4AZ-cuaB_xTMP7eMEXg8L3wQ_zyDCrhbQuTIpkXN1LzimyoTZFrXgwjTV173aQjnkaLsc528_z1qqKAUgO-_txeQTv_u11e-fTsFHfA64yTjxZUtF6huzRqVnC1Nq7rPbKjaAolNLydCQaM7b8UXF-sctBAGrmIhpOo2SapojZUFa9j3IOOT91esdZOwnIZnwKAV1HYqf3aGKtgEGP5pIwXSZ9eeqlBQ2Zricbe_oLNLT4jYLsyEde66oARoQy8IbufalZhgm0_tTWp7vSlRO2VU7uxc3asdLdGRQx9aWAqK7IZqA0RjdnTCySU2taMnbhLrE90V6Cu7B1aBAwxqmNAddSAAAZGzGQPvLkuMeexbX7qb26pqQ_ESHsE2fBceKUslGn4t1LyYBAa8P79gEQ-0k5YKMmh3-hZnmPX8AoODBp3Gwawkq332Brw3q9vhwkBWspP7mBHASEuQi13RaoszOh0tXkrdQGjMCGmKP46l8BqDrV_vaXuvbm-r-d_EpGLIdPz4ql86PF0z6PSpI5gpC57zoKEBiurq8iMIMEZsFnbzWhAph4FwASuaSb_AHOco5Q0taramX1mTaxh8EAyrdqSSeMbp=w865-h1116-no\" /></li>\n</ul>"}]}, {"gitUri": "topics/groovy", "overview": "", "name": "Groovy Programming Language ", "resourceName": "groovy", "modules": [{"gitUri": "topics/groovy/modules/closures", "overview": "A closure in Groovy is an open, anonymous, block of code that can take arguments, return a value and be assigned to a variable.  A closure may reference variables declared in its surrounding scope.  In opposition to the formal definition of a closure, a closure in the Groovy language can also contain free variables that are defined outside of its surrounding scope.", "name": "Closures", "resourceName": "groovy/closures", "content": "<h1>Closures</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#basic-usage\">Basic Usage</a><ul>\n<li><a href=\"#create\">Create</a></li>\n<li><a href=\"#execute\">Execute</a></li>\n<li><a href=\"#parameters\">Parameters</a></li>\n<li><a href=\"#implicit-it-parameter\">Implicit <code>it</code> Parameter</a></li>\n</ul>\n</li>\n<li><a href=\"#using-a-closure-as-a-parameter\">Using a Closure as a Parameter</a><ul>\n<li><a href=\"#each-function-example\"><code>each</code> Function Example</a></li>\n<li><a href=\"#find-function-example\"><code>find</code> Function Example</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>A closure in Groovy is an open, anonymous, block of code that can take arguments, return a value and be assigned to a variable.  A closure may reference variables declared in its surrounding scope.  In opposition to the formal definition of a closure, a closure in the Groovy language can also contain free variables that are defined outside of its surrounding scope.\nAlthough it breaks the formal concept of a closure, a Groovy closure does offer many advantages.</p>\n<h2>Basic Usage</h2>\n<h3>Create</h3>\n<p>Here is a very simple example of a Closure:</p>\n<pre><code class=\"groovy\">def simpleClosure = {\n    println &quot;Hi&quot;\n}\n</code></pre>\n\n<h3>Execute</h3>\n<p>We can execute a closure either just like we would a function, by using <code>()</code>, or by using the <code>call()</code> function:</p>\n<pre><code class=\"bash\">def simpleClosure = {\n    println &quot;Hi&quot;\n}\n// using ()\nsimpleClosure()\n// using the call() function\nsimpleClosure.call()\n</code></pre>\n\n<h3>Parameters</h3>\n<p>Closures can be configured to have parameters very easily:</p>\n<pre><code class=\"groovy\">// one parameter\ndef singleParamClosure = {param -&gt;\n    println &quot;${param}&quot;\n}\n// two parameters\ndef multiParamClosure = {param1, param2, param3 -&gt;\n    println &quot;${param1}, ${param2}, ${param3}&quot; \n}\n</code></pre>\n\n<h3>Implicit <code>it</code> Parameter</h3>\n<p>If you define a closure without parameters, it can still take a single parameter; this parameter will be stored in a variable called <code>it</code>:</p>\n<pre><code class=\"groovy\">def justAnotherClosure = {\n    println &quot;Value of it: ${it}&quot;\n}\njustAnotherClosure &quot;test&quot;\n</code></pre>\n\n<h2>Using a Closure as a Parameter</h2>\n<p>Because closures are just stored as variables, they can be passed to other functions and closures:</p>\n<pre><code class=\"groovy\">def myClosure = {\n    println &quot;Hello from myClosure&quot;\n}\n\nvoid myFunction(exec) {\n    exec()\n}\n\nmyFunction myClosure\n\n// Hello from myClosure\n</code></pre>\n\n<h3><code>each</code> Function Example</h3>\n<p>We can pass a closure to the <code>each</code> function, which will execute the closure for each element in an array:</p>\n<pre><code class=\"groovy\">def students = [&quot;bob&quot;, &quot;jay&quot;, &quot;shafeeq&quot;, &quot;dev&quot;]\n\nstudents.each {\n    println it\n}\n</code></pre>\n\n<h3><code>find</code> Function Example</h3>\n<p>The <code>find</code> function can be used to select an element from an array; all we have to do is pass it a closure that returns a boolean value. If the boolean value is true, the element will be returned:</p>\n<pre><code class=\"groovy\">def students = [&quot;bob&quot;, &quot;jay&quot;, &quot;shafeeq&quot;, &quot;dev&quot;]\n\ndef numberOne = students.find {\n    it.equals &quot;shafeeq&quot;\n}\n\nprintln numberOne\n</code></pre>"}, {"gitUri": "topics/groovy/modules/syntax", "overview": "This document aims to cover the basics of the Groovy programming language's syntax.", "name": "Syntax", "resourceName": "groovy/syntax", "content": "<h1>Syntax</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#commenting\">Commenting</a><ul>\n<li><a href=\"#single-line-comments\">Single Line Comments</a></li>\n<li><a href=\"#multiline-comments\">Multi-Line Comments</a></li>\n<li><a href=\"#inline-commenting\">Inline Commenting</a></li>\n<li><a href=\"#shebang-line\">Shebang Line</a></li>\n</ul>\n</li>\n<li><a href=\"#string-interpolation-gstrings\">String Interpolation (GStrings)</a></li>\n<li><a href=\"#optional-parenthesis\">Optional Parenthesis</a><ul>\n<li><a href=\"#overview-1\">Overview</a></li>\n<li><a href=\"#when-you-need-parenthesis\">When you need parenthesis</a></li>\n<li><a href=\"#omitting-parenthesis-with-named-parameters\">Omitting Parenthesis with Named Parameters</a></li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#commenting-1\">Commenting</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>This document aims to cover the basics of the Groovy programming language's syntax.\nMany of the concepts will be easier to pick up if you have used a programming language like Java before, but don't worry if you haven't!</p>\n<h2>Commenting</h2>\n<p>Comments in Groovy are just like Java:</p>\n<h3>Single Line Comments</h3>\n<pre><code class=\"groovy\">// single line comment\n</code></pre>\n\n<h3>Multi-Line Comments</h3>\n<p>Multi-line comments start with <code>/*</code> and end with <code>*/</code>; this saves you having to put <code>//</code> on every commented line:</p>\n<pre><code class=\"groovy\">/* \n    multi line comment\n*/\n</code></pre>\n\n<h3>Inline Commenting</h3>\n<p>The same syntax for multi-line comments can be used for commenting inline:</p>\n<pre><code class=\"groovy\">println 1 /* one */ + 2 /* two */\n</code></pre>\n\n<h3>Shebang Line</h3>\n<p>If the <code>groovy</code> command is available on your <code>PATH</code>, you can add a shebang line to your Groovy scripts so that you can execute your script directly. Here's an example:</p>\n<pre><code class=\"groovy\">#!/usr/bin/env groovy\nprintln &quot;Hello&quot;\n</code></pre>\n\n<p>If the script above was in a file called <code>test.groovy</code>, you would be able to execute it by running <code>./test.groovy</code>.</p>\n<h2>String Interpolation (GStrings)</h2>\n<p>String interpolation can be used to easily get the value of a variable into a string; in Groovy, these are known as GStrings.\nTo do this, you need to include the variable reference within <code>${}</code>, inside of a literal string:</p>\n<pre><code class=\"groovy\">def name = &quot;bob&quot;\nprintln &quot;Hello, my name is ${name}&quot;\n</code></pre>\n\n<p>This doesn't stop at variables; you can also make function calls that return a string to interpolate into the literal string:</p>\n<pre><code class=\"groovy\">def getName() {\n    &quot;Bob&quot;\n}\nprintln &quot;Hello, ${getName()}&quot;\n</code></pre>\n\n<h2>Optional Parenthesis</h2>\n<h3>Overview</h3>\n<p>In an attempt to make code more readable, Groovy allows you the choice of omitting parenthesis.\nFor example, you can omit parenthesis on function calls:</p>\n<pre><code class=\"groovy\">// calling a function like in java\nSystem.out.println(&quot;Hello&quot;)\n// and the &quot;groovy&quot; way...\nprintln &quot;Hello&quot;\n</code></pre>\n\n<h3>When you need parenthesis</h3>\n<p>However, sometimes you will still need to use parenthesis. One example is when you are calling a function with no parameters;\nwe need to include parenthesis here so that Groovy doesn't think that you are trying to access a property:</p>\n<pre><code class=\"groovy\">// accessing a property\nprintln person.name\n// accessing a function\nprintln person.getName()\n</code></pre>\n\n<h3>Omitting Parenthesis with Named Parameters</h3>\n<p>Named parameters can be used whilst omitting parenthesis:</p>\n<pre><code class=\"groovy\">myObject.myFunction param1: &quot;First Parameter&quot;, param2: &quot;Second Parameter&quot;\n</code></pre>\n\n<h2>Tasks</h2>\n<p>Here are some tasks to try out some of the syntax discussed above.\nFor any of the tasks where you are writing code, please add them to a <code>groovy-syntax.groovy</code> file in this folder, and create a single line comment to separate each task, using the task name, like this:</p>\n<pre><code class=\"groovy\">// First Task\nprintln &quot;code for first task&quot;\n\n// String Interpolation\ndef codeForSecondTask() {\n    return &quot;&quot;\n}\n</code></pre>\n\n<h3>Commenting</h3>\n<p>Create a comment at the top of the file that contains the following:</p>\n<pre><code class=\"text\">  ___  ____   __    __   _  _  _  _    ____  _  _  __ _  ____  __   _  _\n / __)(  _ \\ /  \\  /  \\ / )( \\( \\/ )  / ___)( \\/ )(  ( \\(_  _)/ _\\ ( \\/ )\n( (_ \\ )   /(  O )(  O )\\ \\/ / )  /   \\___ \\ )  / /    /  )( /    \\ )  (\n \\___/(__\\_) \\__/  \\__/  \\__/ (__/    (____/(__/  \\_)__) (__)\\_/\\_/(_/\\_)\n ```\n&lt;details&gt;\n&lt;summary&gt;Show Solution&lt;/summary&gt;\nThe easiest way to implement this is by using a multi-line comment:\n\n```groovy\n/*\n  ___  ____   __    __   _  _  _  _    ____  _  _  __ _  ____  __   _  _\n / __)(  _ \\ /  \\  /  \\ / )( \\( \\/ )  / ___)( \\/ )(  ( \\(_  _)/ _\\ ( \\/ )\n( (_ \\ )   /(  O )(  O )\\ \\/ / )  /   \\___ \\ )  / /    /  )( /    \\ )  (\n \\___/(__\\_) \\__/  \\__/  \\__/ (__/    (____/(__/  \\_)__) (__)\\_/\\_/(_/\\_)\n */\n</code></pre>\n\n</details>\n\n<h3>String Interpolation</h3>\n<p>The following example interpolates the <code>name</code> variable into a string and uses the <code>println</code> function to print it to the console:</p>\n<pre><code class=\"groovy\">String name = &quot;bob&quot;\nprintln &quot;Hello ${name}&quot;\n</code></pre>\n\n<p>We can use <code>System.getenv(\"USER\")</code> to get the current user running the application.\nUsing only the <code>println</code> function, try to print the same string, but for the current user who is running the application.\n<details>\n<summary>Show Solution</summary></p>\n<p>Function calls can be interpolated into strings, just like variables:</p>\n<pre><code class=\"groovy\">println &quot;Hello, ${System.getenv(&quot;USER&quot;)}&quot;\n</code></pre>\n\n</details>\n\n<h3>Omitting Parenthesis</h3>\n<p>Here is a block of groovy code that looks very similar to Java; try making it more \"Groovy\" by omitting unnecessary parenthesis.\nWhy not use string interpolation, instead of the string concatenation that is already there:</p>\n<pre><code class=\"groovy\">def user = System.console().readLine(&quot;What's your name?\\n&quot;)\ndef age = System.console().readLine(&quot;Hi &quot; + user + &quot;, what is your age?\\n&quot;)\nprintln(&quot;Your name is &quot; + user + &quot; and you are &quot; + age + &quot; years old.&quot;)\n</code></pre>\n\n<details>\n<summary>Show Solution</summary>\n\nWe can remove the parenthesis for the function calls and interpolate the `user` and `age` variables, like this:\n\n\n<pre><code class=\"groovy\">def user = System.console().readLine &quot;What's your name?\\n&quot;\ndef age = System.console().readLine &quot;Hi ${user}, what is your age?\\n&quot;\nprintln &quot;Your name is ${user} and you are ${age} years old.&quot;\n</code></pre>\n\n\n</details>"}, {"gitUri": "topics/groovy/modules/variables", "overview": "Variables are of course very commonly used, across all programming languages.", "name": "Variables", "resourceName": "groovy/variables", "content": "<h1>Variables</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#define-and-access-variables\">Define and Access Variables</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>Variables are of course very commonly used, across all programming languages.\nIn Groovy, you can create variables with an implicit, fixed type, or by using the <code>def</code> keyword or by explicitly giving it a type such as <code>String</code>.</p>\n<pre><code class=\"groovy\">def myString = &quot;This variable does not have a fixed type&quot;\nString myOtherString = &quot;This variable has a fixed type&quot;\n</code></pre>\n\n<p>Variables that have been declared using the <code>def</code> keyword can have different types assigned to it at run time.\nFor example a variable created using <code>def</code> that starts out as a <code>String</code> type, could then have an <code>Array</code> type assigned to it later on:</p>\n<pre><code class=\"groovy\">def myString = &quot;My String&quot;\nmyString = [&quot;My&quot;, &quot;String&quot;, &quot;Variable&quot;, &quot;Is&quot;, &quot;Now&quot;, &quot;An&quot;, &quot;Array&quot;]\n</code></pre>\n\n<h2>Tasks</h2>\n<h3>Define and Access Variables</h3>\n<p>Here is some Groovy code that stores the current users name in a variable and then prints out \"Hello\" and the users name:</p>\n<pre><code class=\"groovy\"># get the current user on the system\nString name = System.getenv(&quot;USER&quot;)\n# say hello to the user\nprintln &quot;Hello ${name}&quot;\n</code></pre>\n\n<p>Using the above as a reference, create a Groovy script that will also print a message for the user using a variable called <code>message</code> that is a <code>String</code> type.\nThe output should look something like this if the user was called Bob:</p>\n<pre><code class=\"text\">Hi Bob, how are you?\n</code></pre>\n\n<details>\n<summary>Show Solution</summary>\n\n<pre><code class=\"groovy\"># get the current user on the system\nString name = System.getenv(&quot;USER&quot;)\n# set the message variable\nString message = &quot;how are you?&quot;\n# say hello to the user, with the message as well\nprintln &quot;Hello ${name}, ${message}&quot;\n</code></pre>\n\n\n</details>"}, {"gitUri": "topics/groovy/modules/functions", "overview": "", "name": "Functions", "resourceName": "groovy/functions", "content": "<h1>Functions</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#basic-usage\">Basic Usage</a><ul>\n<li><a href=\"#creating-a-function\">Creating a Function</a></li>\n<li><a href=\"#calling-a-function\">Calling a Function</a></li>\n<li><a href=\"#creating-functions-with-parameters\">Creating Functions with Parameters</a></li>\n<li><a href=\"#calling-functions-with-parameters\">Calling Functions with Parameters</a></li>\n</ul>\n</li>\n<li><a href=\"#return-values\">Return Values</a><ul>\n<li><a href=\"#no-value-void\">No value (void)</a></li>\n<li><a href=\"#returning-a-type\">Returning a Type</a></li>\n<li><a href=\"#return-keyword\">Return Keyword</a></li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#create-some-basic-functions\">Create Some Basic Functions</a><ul>\n<li><a href=\"#current-user-message-function\">Current User Message Function</a></li>\n<li><a href=\"#addition-function\">Addition Function</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Basic Usage</h2>\n<h3>Creating a Function</h3>\n<p>Functions can be defined by declaring a type to return, like <code>String</code> or specifying <code>void</code>, meaning that the function wont return anything and then including <code>() {}</code> after the function name:</p>\n<pre><code class=\"groovy\">void myFunction() {\n    // does lots of cool stuff\n}\n</code></pre>\n\n<h3>Calling a Function</h3>\n<p>Stating the function name with <code>()</code> afterwards will call (execute) the function:</p>\n<pre><code class=\"groovy\">void testFunction() {\n    println &quot;I've been called!&quot;\n}\ntestFunction()\n</code></pre>\n\n<p>Note: parenthesis cannot be omitted if the function does not take any parameters.</p>\n<h3>Creating Functions with Parameters</h3>\n<p>We can provide parameters to functions with or without types:</p>\n<pre><code class=\"groovy\">def functionWithoutTypes(param1, param2) {\n    println &quot;${param1}, ${param2}&quot;\n}\ndef functionWithTypes(String param1, String param2) {\n    println &quot;${param1}, ${param2}&quot;\n}\n</code></pre>\n\n<h3>Calling Functions with Parameters</h3>\n<p>Parameters must be passed in order to the function:</p>\n<pre><code class=\"groovy\">void logItem(String item, int amount) {\n    println &quot;Item: ${item}, Amount: ${amount}&quot;\n}\nlogItem(&quot;Apple&quot;, 5)\n</code></pre>\n\n<h2>Return Values</h2>\n<h3>No value (void)</h3>\n<p>To create a function that isn't going to return a value, the void keyword must be used:</p>\n<pre><code class=\"groovy\">void myFunction() {\n    // Do not return any values\n}\n</code></pre>\n\n<h3>Returning a Type</h3>\n<p>You can specify a return types for functions as well:</p>\n<pre><code class=\"groovy\">String myStringFunction() {\n    // returning a string value\n    return &quot;Some String&quot;\n}\nAccount myAccountFunction() {\n    // returning a new account project\n    return new Account()\n}\n</code></pre>\n\n<h3>Return Keyword</h3>\n<p>The return keyword is commonly used for specifying values to be returned from a function however this keyword can be omitted if you choose to do so:</p>\n<pre><code class=\"groovy\">String withReturnKeyword() {\n    return &quot;String Example&quot;\n}\nString withoutReturnKeyword() {\n    &quot;String Example&quot;\n}\n</code></pre>\n\n<h2>Tasks</h2>\n<p>Please create any files for these tasks in this folder.</p>\n<h3>Create Some Basic Functions</h3>\n<h4>Current User Message Function</h4>\n<p>Create a file called <code>current-user-message.groovy</code>.\nThe following function can take a string parameter, a message, and then add the current user's name to the message provided, this string will then be returned.\nAdd the function and function call to <code>current-user-message.groovy</code> and execute the file to see it working.</p>\n<pre><code class=\"groovy\">String formatMessageForCurrentUser(String message) {\n    &quot;Hi ${System.getenv(&quot;USER&quot;)}, ${message}&quot;\n}\nprintln formatMessageForCurrentUser(&quot;how are you?&quot;)\n</code></pre>\n\n<h4>Addition Function</h4>\n<p>Try to create another function that can add two numbers together and return the value as an <code>int</code> type.\nCreate this in a file called <code>addition-function.groovy</code>\n<details>\n<summary>Show Solution</summary></p>\n<pre><code class=\"groovy\">int sumOf(int firstNumber, int secondNumber) {\n    firstNumber + secondNumber\n}\nprintln sumOf(1, 2)\n</code></pre>\n\n</details>"}]}, {"gitUri": "topics/jenkins", "overview": "Jenkins is a self-contained, open source automation server that can be used to automate all sorts of tasks related to building, testing, and delivering or deploying software.", "name": "Jenkins", "resourceName": "jenkins", "modules": [{"gitUri": "topics/jenkins/modules/scm", "overview": "Jenkins SCM", "name": "Jenkins SCM", "resourceName": "jenkins/scm", "content": "<h1>Jenkins SCM</h1>\n<h2>Overview</h2>\n<p>Jenkins SCM</p>"}, {"prereqs": ["jenkins/web-setup", "jenkins/jobs", "jenkins/freestyle-project", "linux/systemd", "linux/sudo"], "gitUri": "topics/jenkins/modules/basic-python-flask-freestyle-project-deployment-with-systemd", "overview": "Basic deployment of a Python Flask server, using systemd and a Freestyle Project.", "name": "Basic Python Flask Freestyle Project Deployment with systemd", "resourceName": "jenkins/basic-python-flask-freestyle-project-deployment-with-systemd", "content": "<!--PROPS\n{\n    \"prereqs\": [\n        \"jenkins/web-setup\",\n        \"jenkins/jobs\",\n        \"jenkins/freestyle-project\",\n        \"linux/systemd\",\n        \"linux/sudo\"\n    ]\n}\n-->\n\n<h1>Basic Python Flask Freestyle Project Deployment with systemd</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#sample-project\">Sample Project</a></li>\n<li><a href=\"#host-machine-configuration\">Host Machine Configuration</a></li>\n<li><a href=\"#jenkins-job\">Jenkins Job</a></li>\n<li><a href=\"#shell-script\">Shell Script</a><ul>\n<li><a href=\"#installing-the-systemd-service\">Installing the systemd Service</a></li>\n<li><a href=\"#installing-and-configuring-the-application-files\">Installing and Configuring the Application Files</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>Basic deployment of a Python Flask server, using systemd and a Freestyle Project.\nIncluded in this module folder is a Python Server that uses the Flask framework.</p>\n<h2>Sample Project</h2>\n<p>The sample project included for this example is a single python script.\nThere is also a systemd service configuration included, for running the application as the <code>pythonadm</code> user.\nPlease note that, because of systemd, this example will not work inside a docker container.</p>\n<h2>Host Machine Configuration</h2>\n<p>There are a few prerequisites for this module, so make sure the following has been configured on your machine:\n- Linux operating system with systemd, not in a container\n- Jenkins installed &amp; running\n- Python 3 installed\n- Jenkins user, configured as a sudo user with no password</p>\n<h2>Jenkins Job</h2>\n<p>Create a Jenkins Freestyle Project called flask-app and configure it to download this code onto its filesystem; this can be configured in the Source Control Management section:\n- <code>Repository URL</code> set to <code>https://github.com/bob-crutchley/notes</code></p>\n<h2>Shell Script</h2>\n<p>Add the following into an <code>Execute shell</code> build step:</p>\n<pre><code class=\"bash\"># move to module folder\ncd ./topics/jenkins/modules/basic-python-flask-freestyle-project-deployment-with-systemd\n# install the service script\nsudo cp flask-app.service /etc/systemd/system/\n# reload the service scripts\nsudo systemctl daemon-reload\n# stop the old service\nsudo systemctl stop flask-app\n# install the application files\ninstall_dir=/opt/flask-app\nsudo rm -rf ${install_dir}\nsudo mkdir ${install_dir}\nsudo cp -r ./* ${install_dir}\nsudo chown -R pythonadm:pythonadm ${install_dir}\n# configure python virtual environment and install dependencies\nsudo su - pythonadm &lt;&lt; EOF\ncd ${install_dir}\nvirtualenv -p python3 venv\nsource venv/bin/activate\npip install -r requirements.txt\nEOF\n# start the flask app\nsudo systemctl start flask-app\n</code></pre>\n\n<p>See below for explanation of the commands used in this script:</p>\n<h3>Installing the systemd Service</h3>\n<p>To account for any changes to the script, or if this is the first time installing the application, the service script needs to be installed into <code>/etc/systemd/system/</code>.\nFor systemd to pickup the changes, we must also reload the services with <code>systemctl daemon-reload</code>.\nBefore we start replacing the old application files, the service should be stopped by running <code>systemctl stop flask-app</code>:</p>\n<pre><code class=\"bash\"># install the service script\nsudo cp flask-app.service /etc/systemd/system/\n# reload the service scripts\nsudo systemctl daemon-reload\n# stop the old service\nsudo systemctl stop flask-app\n</code></pre>\n\n<h3>Installing and Configuring the Application Files</h3>\n<p>Here, we can recreate the application folder to make sure we have a fresh start.\nOnce the folder has been recreated, the application can be copied in.\nWe then need to make sure that <code>pythonadm</code> owns the folder, because that's the user that is going to be running the application.\nThen we need to setup the python virtual environment and install the dependencies.\nThis is ran as the <code>pythonadm</code> user, to make sure that the files remain owned by the <code>pythonadm</code> user.\nOnce all that is done, the service can then be started again using <code>sudo systemctl start flask-app</code>.</p>\n<pre><code class=\"bash\"># install the application files\ninstall_dir=/opt/flask-app\nsudo rm -rf ${install_dir}\nsudo mkdir ${install_dir}\nsudo cp -r ./* ${install_dir}\nsudo chown -R pythonadm:pythonadm ${install_dir}\n# configure python virtual environment and install dependencies\nsudo su - pythonadm &lt;&lt; EOF\ncd ${install_dir}\nvirtualenv -p python3 venv\nsource venv/bin/activate\npip install -r requirements.txt\nEOF\n# start the flask app\nsudo systemctl start flask-app\n</code></pre>"}, {"gitUri": "topics/jenkins/modules/jobs", "overview": "A Jenkins project (job) is a repeatable build job, which contains steps and post-build actions.", "name": "Jobs", "resourceName": "jenkins/jobs", "content": "<h1>Jobs</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#create-a-job\">Create a Job</a></li>\n<li><a href=\"#workspaces\">Workspaces</a></li>\n<li><a href=\"#help\">Help!</a></li>\n<li><a href=\"#job-configuration\">Job Configuration</a><ul>\n<li><a href=\"#general-settings\">General Settings</a></li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a></li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>A Jenkins project (job) is a repeatable build job, which contains steps and post-build actions.\nA job can really do anything, it just depends what you configure it to do.\nAn example of what a job can be used to do is - automatically build a project and deploy it on a server, to be accessed over the internet.</p>\n<h2>Create a Job</h2>\n<p>To create a new job, you can navigate to the <code>New Item</code> link on the Jenkins dashboard.\nThis will then present you with some options for what type of job to create.\nGo ahead and name your job <code>first-job</code>, select <code>Freestyle Project</code> and then select <code>OK</code>.\n<img alt=\"First Job\" src=\"https://i.imgur.com/qd2OW5N.png\" /></p>\n<h2>Workspaces</h2>\n<p>A workspace in Jenkins is basically just a folder that is on the host machine.\nJenkins will run every single job in its own workspace.\nThis is to keep jobs seperate from each other, which avoids conflicts with files and configurations that the jobs may be using.</p>\n<h2>Help!</h2>\n<p>There are many configurations to choose from when setting up a Jenkins job; however, there is usually a <code>?</code> symbol on the right side of the page, which gives a comprehensive explanation of what the option does.</p>\n<h2>Job Configuration</h2>\n<p>This is where you can set up what your job is going to do.\nThere are many options, but this module will just focus on the General Settings.</p>\n<h3>General Settings</h3>\n<p>The settings and options throughout all job configurations will depend on what plugins are installed; this module aims to explain the ones that are suggested when you go through the Jenkins setup.</p>\n<table>\n<thead>\n<tr>\n<th>Setting Name</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Description</td>\n<td>This is just an open text field to fill in information about the job. You'll likely want to put some instructions about your job here, or some information about its current state; for example, if it's a work in progress.</td>\n</tr>\n<tr>\n<td>Discard Old Builds</td>\n<td>Disk space doesn't grow on trees. If your job uses up quite a bit of space, then, after you have built it many times, considerable disk space might be used by old builds that no longer serve any purpose.</td>\n</tr>\n<tr>\n<td>GitHub Project</td>\n<td>Jenkins jobs are commonly associated with some kind of source code repository, like GitHub. You can add a link to that repository here, so it's easier to navigate to from the job's page.</td>\n</tr>\n<tr>\n<td>Parameters</td>\n<td>To make your job more generic and able to accept different configurations, you can pass it parameters.</td>\n</tr>\n<tr>\n<td>Disable Project</td>\n<td>Prevention is better than cure. If there are issues with the job's current configuration and you would like to make sure that it doesn't get executed, then you can check this option.</td>\n</tr>\n<tr>\n<td>Concurrent Builds</td>\n<td>Use this option carefully. There are many cases where your job will not be able to run at the same time as another instance of it, which is why this is disabled by default.</td>\n</tr>\n</tbody>\n</table>\n<h2>Tasks</h2>\n<p>Have a go at entering some simple configurations into your first job:\n- Choose any project from <a href=\"github.com\">GitHub</a>\n- Enter some information about the project into the <code>Project url</code> field, for the <code>GitHub project</code> option\n- Set a <code>String Parameter</code> for the job:\n    - Set the <code>NAME</code> field to be <code>VERSION</code>\n    - Set the <code>Default Value</code> field to be <code>0.1.0</code>\n    - Set the <code>Description</code> field to be <code>Version of the application to build</code> \n- Select the <code>Save</code> button (you will be redirected to the job's page)\n- Select <code>Build with Parameters</code>. You should then see the parameter that you configured\n- Select <code>Delete Project</code> and confirm the deletion</p>"}, {"gitUri": "topics/jenkins/modules/installation-wizard", "overview": "This document aims to guide you through the setup process of Jenkins, through the graphical (web) interface.", "name": "Installation Wizard", "resourceName": "jenkins/installation-wizard", "content": "<h1>Installation Wizard</h1>\n<p>Configuring Jenkins using a graphical interface.</p>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#unlocking-jenkins\">Unlocking Jenkins</a></li>\n<li><a href=\"#customize-jenkins\">Customize Jenkins</a></li>\n<li><a href=\"#plugin-installation\">Plugin Installation</a></li>\n<li><a href=\"#create-the-first-admin-user\">Create the First Admin User</a></li>\n<li><a href=\"#instance-configuration\">Instance Configuration</a></li>\n<li><a href=\"#dashboard\">Dashboard</a><ul>\n<li><a href=\"#dashboard-links\">Dashboard Links</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>This document aims to guide you through the setup process of Jenkins, through the graphical (web) interface.</p>\n<h2>Unlocking Jenkins</h2>\n<p>To make sure that it is you who is trying to configure Jenkins, the setup requires you to enter an initial admin password; this is stored on the file system of the machine that Jenkins is running on.\nThe page clearly states where this file is located - you just need to copy the contents of it into the text field and click <code>Continue</code>.</p>\n<p><img alt=\"Jenkins Initial Admin Password\" src=\"https://i.imgur.com/Poqds4F.png\" /></p>\n<h2>Customize Jenkins</h2>\n<p>Jenkins is highly configurable due to the amount of plugins that you can install.\nThis is fantastic, but, if you are new to Jenkins, you might not have much of an idea about what plugins you would want.\nFortunately, the setup gives you the option to install suggested plugins - select this option.</p>\n<p><img alt=\"Customize Jenkins\" src=\"https://i.imgur.com/hg1BlXL.png\" /></p>\n<h2>Plugin Installation</h2>\n<p>For this part, there isn't much to do but wait.\nThe suggested plugins, or plugins that you selected, will be installed; how fast they are installed depends on your internet speed.\nIf plugins are failing to install, make sure that you have the latest version on Jenkins installed.</p>\n<p><img alt=\"Plugin Installation\" src=\"https://i.imgur.com/tNnEJVf.png\" /></p>\n<h2>Create the First Admin User</h2>\n<p>At this point, you can either fill in the form, to have your details saved into the first admin account, or continue as admin; this will mean that the admin user account name is <code>admin</code> and the password will stay as the initial admin password that you entered.\nBe careful not to enter actual passwords and information here, especially if you are connected to a Jenkins instance over the internet with no TLS or SSL configured (HTTPS secure connection).</p>\n<p><img alt=\"Create First Admin User\" src=\"https://i.imgur.com/DIzyESa.png\" /></p>\n<h2>Instance Configuration</h2>\n<p>All you will need to for this step is to select <code>Save and Finish</code>.</p>\n<p><img alt=\"Instance Configuration\" src=\"https://i.imgur.com/SPPAiXG.png\" /></p>\n<h2>Dashboard</h2>\n<p>You should now have Jenkins setup and have the following dashboard on your screen:</p>\n<p><img alt=\"Dashboard\" src=\"https://i.imgur.com/JsVUo3x.png\" /></p>\n<h3>Dashboard Links</h3>\n<table>\n<thead>\n<tr>\n<th>Link</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>New Item</td>\n<td>This is for creating new jobs in Jenkins. Jobs are essentially scripts that can be triggered.</td>\n</tr>\n<tr>\n<td>People</td>\n<td>The users that are registered to this instance of Jenkins.</td>\n</tr>\n<tr>\n<td>Build History</td>\n<td>A graph displaying the jobs that have been executed over time, through this instance of Jenkins.</td>\n</tr>\n<tr>\n<td>Manage Jenkins</td>\n<td>This is where to go for setting up plugins and other administrative settings for Jenkins.</td>\n</tr>\n<tr>\n<td>My Views</td>\n<td>You can customise how the jobs, and what jobs, are listed on the dashboard here.</td>\n</tr>\n<tr>\n<td>Credentials</td>\n<td>In the Jenkins jobs that you create, you may need to authenticate with external services, such as GitHub. Credentials for these external services can be stored securely here, and accessed by jobs and plugins when they need them.</td>\n</tr>\n<tr>\n<td>Lockable Resources</td>\n<td>This plugin allows defining lockable resources (such as printers, phones, computers, etc.) that can be used by builds. If a build requires a resource that is already locked, it will wait for the resource to be free. You can define a lock-priority globally or on a per-job basis.</td>\n</tr>\n</tbody>\n</table>"}, {"gitUri": "topics/jenkins/modules/freestyle-project", "overview": "Freestyle projects in Jenkins are a type of job you can create for almost any automated task.", "name": "Freestyle Project", "resourceName": "jenkins/freestyle-project", "content": "<h1>Freestyle Project</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#create-a-freestyle-project\">Create a Freestyle Project</a></li>\n<li><a href=\"#source-code-management\">Source Code Management</a></li>\n<li><a href=\"#build-triggers\">Build Triggers</a><ul>\n<li><a href=\"#build-periodically\">Build Periodically</a></li>\n<li><a href=\"#github-hook\">GitHub Hook</a></li>\n<li><a href=\"#poll-scm\">Poll SCM</a></li>\n</ul>\n</li>\n<li><a href=\"#build-environment\">Build Environment</a><ul>\n<li><a href=\"#delete-workspace-before-build-starts\">Delete Workspace Before Build Starts</a></li>\n<li><a href=\"#secret-texts--files\">Secret Texts &amp; Files</a></li>\n</ul>\n</li>\n<li><a href=\"#build\">Build</a></li>\n<li><a href=\"#postbuild-actions\">Post-build Actions</a></li>\n<li><a href=\"#tasks\">Tasks</a></li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>Freestyle projects in Jenkins are a type of job you can create for almost any automated task.\nThese are the best place to start for building any sort of general purpose automation in Jenkins.</p>\n<h2>Create a Freestyle Project</h2>\n<p>Go ahead and select <code>New Item</code> from the Jenkins dashboard, and then create a new Freestyle Project called <code>freestyle-project</code>:\n<img alt=\"Freestyle Project\" src=\"https://i.imgur.com/qGGXAKX.png\" /></p>\n<h2>Source Code Management</h2>\n<p>This section is used for configuring a source code repository to download.\nThe job will download the repository you provide into the jobs workspace.</p>\n<h2>Build Triggers</h2>\n<p>The most simple way to run a Jenkins job is by pressing the build button for the job.\nHowever, jobs can be triggered in many ways (we usually try to avoid doing this manually).</p>\n<h3>Build Periodically</h3>\n<p>You can create a schedule here for the job; for example, having it build every hour or at 6:15 PM every Thursday.</p>\n<h3>GitHub Hook</h3>\n<p>This is where GitHub can send a HTTP POST request; for example, a webhook to your Jenkins server to trigger a build of the job.\nThis must be configured in GitHub and your Jenkins instance must be accessable from the internet for this to work.</p>\n<h3>Poll SCM</h3>\n<p>This feature can be used if your Jenkins instance is not accessible on the internet.\nJenkins will check, using a schedule that you define, whether a change has been made on the configured SCM repository.\nAs soon as a change has been detected, the job will be executed.\nThe minimum polling interval is every 1 minute.</p>\n<h2>Build Environment</h2>\n<h3>Delete Workspace Before Build Starts</h3>\n<p>You will likely want this option checked.\nThe folder where the job runs on the host machine's file system will be deleted before building again.</p>\n<h3>Secret Texts &amp; Files</h3>\n<p>You may securely use secret texts and files that you have configured in the Credentials section here in the job.\nThese secrets will also be hidden in the Jenkins logs as well.</p>\n<h2>Build</h2>\n<p>This is likely where you will spend most of your time on a Jenkins job.\nThe most common build step here is <code>Execute shell</code>; other options are available, depending on what plugins you have installed.\nExactly what your job accomplishes is configured here.</p>\n<h2>Post-build Actions</h2>\n<p>You may want to configure your job to react depending on how the build went.\nFor instance, you could be notified by email if the job failed.\nYou could also publish a report if the job completed successfully.\nLike with most of the options, the sky is the limit; it all depends on what plugins are installed.</p>\n<h2>Tasks</h2>\n<p>These tasks will take you through configuring a very simple Freestyle Project, which will download this repository and execute the <code>run.sh</code> script that is in this directory.\n1. If you haven't created a Freestyle Project already, go ahead and create one now\n2. Lets configure it to download this project and checkout to this subdirectory:\n    - Under <code>Source Code Management</code> select <code>Git</code>\n    - Enter <code>https://github.com/bob-crutchley/notes</code> into the <code>Repository URL</code> field\n3. Now add an <code>Execute shell</code> build step and enter the following into it:\n    <code>bash\n    cd topics/jenkins/modules/freestyle-project\n    sh run.sh</code>\n4. Run the job\n5. Navigate to the jobs logs; you should see the contents of this <code>README.md</code> file displayed in the logs</p>"}]}, {"gitUri": "topics/nginx", "overview": "Nginx is a web server which can also be used as a reverse proxy, load balancer, mail proxy and HTTP cache.", "name": "NGINX", "resourceName": "nginx", "modules": [{"gitUri": "topics/nginx/modules/configuration", "overview": "NGINX uses a text-based configuration file written in a specific format.", "name": "Configuration", "resourceName": "nginx/configuration", "content": "<h1>Configuration</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#directives\">Directives</a></li>\n<li><a href=\"#include-directive\">Include Directive</a></li>\n<li><a href=\"#toplevel-contexts\">Top-Level Contexts</a></li>\n<li><a href=\"#virtual-servers\">Virtual Servers</a><ul>\n<li><a href=\"#http\">HTTP</a></li>\n<li><a href=\"#mail--stream\">Mail &amp; Stream</a></li>\n</ul>\n</li>\n<li><a href=\"#reloading-configurations\">Reloading configurations</a></li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#edit-the-nginxconf-file\">Edit the <code>nginx.conf</code> File</a></li>\n<li><a href=\"#reload-the-new-configurations\">Reload the New Configurations</a></li>\n<li><a href=\"#view-the-new-changes\">View the New Changes</a><ul>\n<li><a href=\"#response-in-a-web-browser\">Response In a Web Browser</a></li>\n<li><a href=\"#response-using-curl\">Response Using <code>curl</code></a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>NGINX uses a text-based configuration file written in a specific format.\nThe default file used to configure NGINX is the <code>nginx.conf</code> file. This can be found in <code>/etc/nginx</code> on Linux systems, and in <code>[INSTALL_PATH]/conf/nginx.conf</code> - <code>[INSTALL_PATH]</code> on Windows machines (based on the location that you unzipped the NGINX folder to).</p>\n<h2>Directives</h2>\n<p>When configuring the <code>nginx.conf</code> file it will contain <em>directives</em> and their parameters.\nYou can use simple single-line directives which just have 1 parameter; like a key-value pair:</p>\n<pre><code class=\"text\">user    nginx;\n</code></pre>\n\n<p>Other directives can act as a container, holding other related directives enclosed using curl braces (<code>{}</code>).\nThese types of directives are often referred to as <em>blocks</em> or <em>contexts</em>:</p>\n<pre><code class=\"text\">location / {\n    return 200 &quot;OK\\n&quot;;\n}\n</code></pre>\n\n<h2>Include Directive</h2>\n<p>NGINX configurations can become difficult to maintain due to the size and length of the file getting larger.\nThe <code>include</code> directive can be used to effectively \"import\" other configurations from other files.\nYou can use this for feature-specific configuration files; conventionally you would store these extra files in <code>/etc/nginx/conf.d</code> on Linux systems and <code>[INSTALL_FOLDER]/conf</code> on Windows.\nHere is an example for the <code>conf.d/http</code> and <code>conf.d/stream</code> files being included:</p>\n<pre><code class=\"text\">include conf.d/http;\ninclude conf.d/stream;\n</code></pre>\n\n<h2>Top-Level Contexts</h2>\n<p>There are a few top-level contexts that are used to group together directives for handling different traffic types:\n- <strong>events</strong>: Genereal connection processing\n- <strong>http</strong>: HTTP Traffic, which can be used for things like web applications\n- <strong>mail</strong>: Mail Traffic, for when you are using NGINX with an SMTP (Mail) server\n- <strong>stream</strong>: TCP and UDP traffic, for when your application is using TCP to communicate, as opposed to something like HTTP\nAny directives that get place outside of these contexts are said to be in the <em>main</em> context.</p>\n<pre><code class=\"text\"># this directive is included in the main context\nuser nginx;\n\nevents {\n    # directives here apply to all traffic types\n}\n\nhttp {\n    # http configurations\n}\n</code></pre>\n\n<h2>Virtual Servers</h2>\n<p>One or more server blocks can be included in each of the traffic handling contexts.</p>\n<h3>HTTP</h3>\n<p>HTTP virtual servers are used for handling traffic for resources depending on what IP address or domain is used.\nFurthermore, a location context can be included to handle a specific Universal Resource Identifier (URI).</p>\n<p>Here is an example configuration for using 2 virtual servers and 4 location contexts.\nTo avoid collisions with port mappings, each virtual server has been set to listen on a different port using the <code>listen</code> directive under the <code>server</code> contexts.\nBy default, the HTTP virtual server will listen on port <code>80</code>.</p>\n<pre><code class=\"text\">events {}\nhttp {\n    server {\n       location /one {\n            listen 8001;\n            return 200 &quot;Location 1, Virtual Server 1\\n&quot;;\n       }\n       location /two {\n            listen 8002; \n            return 200 &quot;Location 2, Virtual Server 1\\n&quot;;\n       }\n    }\n    server {\n       location /one {\n            listen 9001;\n            return 200 &quot;Location 1, Virtual Server 2\\n&quot;;\n       }\n       location /two {\n            listen 9002;\n            return 200 &quot;Location 2, Virtual Server 2\\n&quot;;\n       }\n    }\n}\n</code></pre>\n\n<p>If you were to make requests to an NGINX server with this configuration (assuming you are accessing NGINX using <code>localhost</code>), you would see the following responses depending on the URI and ports used:</p>\n<table>\n<thead>\n<tr>\n<th>Request</th>\n<th>Response</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>http://localhost:8001/one</td>\n<td>Location 1, Virtual Server 1</td>\n</tr>\n<tr>\n<td>http://localhost:8002/two</td>\n<td>Location 2, Virtual Server 1</td>\n</tr>\n<tr>\n<td>http://localhost:9001/one</td>\n<td>Location 1, Virtual Server 2</td>\n</tr>\n<tr>\n<td>http://localhost:9002/two</td>\n<td>Location 2, Virtual Server 2</td>\n</tr>\n</tbody>\n</table>\n<h3>Mail &amp; Stream</h3>\n<p>For the Mail and TCP/UDP traffic the <code>mail</code> and <code>stream</code> contexts are used respectively.\nYou would use the <code>stream</code> context if the applications you are using NGINX with uses TCP or UDP traffic, as opposed to HTTP.</p>\n<p>Streams can be used for proxying requests that are TCP or UDP, as opposed to HTTP; this example accepts TCP connections on port <code>80</code> and proxies them to <code>192.168.1.123:8080</code>.</p>\n<pre><code class=\"text\">stream {\n    server {\n        listen 80\n        proxy_pass 192.168.1.123:8080;\n    }\n}\n</code></pre>\n\n<h2>Reloading configurations</h2>\n<p>Once you have made a change to the NGINX configuration, you will likely notice that nothing has actually happened. This is because the NGINX configurations must be reloaded.</p>\n<p>We can send the <code>reload</code> signal to NGINX using the <code>-s</code>option:</p>\n<pre><code class=\"bash\">nginx -s reload\n</code></pre>\n\n<p>Configurations on Linux can also be reloaded by using <code>systemctl</code>:</p>\n<pre><code class=\"bash\">sudo systemctl reload nginx\n</code></pre>\n\n<h2>Tasks</h2>\n<p>Here we are going to be changing the <code>nginx.conf</code> file so that it can return three different values depending on what URI we request.</p>\n<h3>Edit the <code>nginx.conf</code> File</h3>\n<p>Start by editing the <code>nginx.conf</code> file to contain the following:</p>\n<pre><code class=\"text\"># the events context must exist for any configuration to work\nevents {}\n# http context because we are going to be making http requests\nhttp {\n    server {\n        # this vritual server can be accessed on port 80\n        listen 80;\n        location / {\n            return 200 &quot;Default Location\\n&quot;;\n        }\n        location /one {\n            return 200 &quot;Location One\\n&quot;;\n        }\n        location /two {\n            return 200 &quot;Location Two\\n&quot;;\n        }\n    }\n}\n</code></pre>\n\n<h3>Reload the New Configurations</h3>\n<p>Before our changes are going to work we need to reload our NGINX configurations.\nOn Linux first try using <code>systemctl</code>:</p>\n<pre><code class=\"bash\">sudo systemctl reload nginx\n</code></pre>\n\n<p>Otherwise use the <code>nginx</code> binary:</p>\n<pre><code class=\"bash\">nginx -s reload\n</code></pre>\n\n<h3>View the New Changes</h3>\n<p>We can then use a web browser to see the changes by putting the different resources in the URL bar (<code>/</code>, <code>/one</code>, <code>/two</code>).\nIf you are on a Linux machine with no GUI, the <code>curl</code> command can be used to make HTTP requests to NGINX.</p>\n<p>Depending on the URI request that you made, you should get the relevant response from NGINX for how you configured it above.</p>\n<h4>Response In a Web Browser</h4>\n<p><img alt=\"NGINX Default Location\" src=\"https://lh3.googleusercontent.com/zvRwSbAuZTBwFswyeLBlnrejvGeXXFhSj46CRv_BcGLc24vq7NXDXnnTqOArLyTPzwnvJW-D9J5W3jjzqTmdeG2v3JyJMgekL3CO7ENhYij4_fphEBZAaQLcenWRNGJRE-MG3txSQIVFqQRNDU3vlSaStCAr9JZmNfNfdNH_-2ieGEnIAIqpAe3vqKFg9f4i78RaJlY7B0YTq-IReQ2uXe7qiVU4ZzdlI0nARuxYWnBPfxIVL4czTqajMyMvIHtHx0wxnscljfk4t6aX-L5TN35rYBrVm9LBffJ6davYqL8xCNOYjcM0KJs2-EgcbuxDRZe5grJt1gc1ZC-2YkDJL189ayiy_QgkzdvnCTKd8Vta2Omb2DJJ-YbY4PPLnRvHI1NkNvMM8HH5D3AK7rW6zlUjDK7XIvpLK6stYSscvpAVJ9YZ1qZHz5wMUvD8-_ejXS4v0oqHnlm__ICX-rFNIPmOcy1Og5LdkXNIudqbyqgba6_fQ5rLKldO5VndwomTS1-44JEJW7qwyrBrz9jf00TEdhSapBHtPnlWdQt1At2nlnL_feCHejORwIkmK4Yeqohk_pE6xycPMkuMeXTsJt2Fy8LR-r1p3p32EVtStZmzxj_fh7limlm2V4s1p76KQwPT4dPO_57vxqxN860AbGC86XBlFNFSysCdlGQ0JDPuXx-PJRpDCWCfpYu97zHYxJgRmVoRQYC7b7nd0P07no3pHLTNGaLmuFRTPLvevE5NvTGL=w1030-h117-no\" />\n<img alt=\"NGINX One Location\" src=\"https://lh3.googleusercontent.com/ou48oAWQIHHDH7ETrVA9mClrO3FrbXYOtOgBKbvWNxpZrWh96jdfQq3r5cWL3gOOuvrzLMDWeIqDdMmFqT9omG9b3Pub9-F5WuEecVB9L-3B-Spxb9tOWzIFjny30MapJVJH_wBcib05RYx8fLhcefR7JSe4u88RFFmiJzimEkdq1DUP5pd2X7uo-cZ4NWfHP_1thYLwWvgccQ2BbZRXhDapPCoIvzg8N5bh7WGkhFogl25_ZF7p_knEjRuzcuuwSdbdkkcoOl1eKm-QSFFly8xp5NV_CuL_gfzRwtxG_gKJhzu6n_RfYSm7Y_RjP7uhh9LeHELvtHD1HIRrzNSPQNrfkPUxr1IjRB_prqCY6qYeBtq_2ERu9ep8cQWH5I7qyfeaKtIihaCLta4__VAJD0JIphy-Wgmipvfc7zp0J7rIVT20rp-OVq4VdX5W7HahFdK1S89nud5iFPMv1fI0LZS2XxKaDA78OkuvxhZjwqV8flcAcXLu6yIz3nX5I0tGa3qqN2iQ2Iyc-ap7CSson_OLW5KZS7b1rYAoVswAdt-tegCzkZo1g_3FivbTy3OohFzFCfds7je8CQNvBGylAtk0pRrTAXokM7IFGlcrUDpAp2P6R2XTuv02qNe9d2eCtwFRSy_2Sy3HByD7EZhHGHpaxlkCL_34uIgw5Kqs9MyrTE6eYDSZiXniEUtlrQ2NcQVyB2GxGgxxoxeY-4VN2SibkqYux_lq-n2z84r2qB9NQrVG=w1029-h115-no\" />\n<img alt=\"NGINX Two Location\" src=\"https://lh3.googleusercontent.com/HEFDlUmKvtq53zasqkcfVwoBhVtFSIAkAErWQbzzp5yHj3m7aArKtKN6eLGOYElX-MEQ_Jn4ADN_4s98ZynUoEw_YxYeyDpao-1Tq32p5D_lW51ll_Oy6MUax14wuiuY4LfR8FDp3f8wiiCOyHSrOE0YSzwweUolbD91AAXIxho1h9IbSZKG94sOPH_410sIefJtW1B5phM3Mim5JVjdHdWQkx22LAE1Apy0BRE4OwJsggAy-ke_RZN7HoWMNeRGXUqPxEAVJKIthCgFxKgMv0ALFZ7WvIVBtzfzt7_zm6D2hX4qHD5btv9fbP8liiKYVgkv9xCsy4Sdj6EHu3X3rOVhZekQioxpYyvw8G-6GrX0ZGYqD6Zo9M3SgsSeeJcavfgDNoL7FJv6HtJ2cZLsOExEeqHNuM1EJ12xBqJzLpBN_ZktKJlKeIOuhccTkL95gXDAMe0V-nKAjsXKDkvbfJCRmysYpo8T5saOISUUQoO_zYMNYzdjHX8uFFEQVIu2twk5ul96SgUmDfvjvxjN56-g9Try-EojDZAmWSypfZSVInq3wwd935WFJm8HotndMJPwH3dGCDtYpADYRyL7-XIz_tmDG0HBsW6Arab2z7jKpY1N6eXbKUXt8E-RBmgYa78sLLJMuP8gu9rBRgGCiFjjFhFLVHrUKjHFqHBIVSJertcW85NbUFgj9tTapp6TNIvhmYz5vMfRdyfUQvMdXNZUHEdXTkn-g9Sn1Q28_3qGmGNl=w1029-h116-no\" /></p>\n<h4>Response Using <code>curl</code></h4>\n<pre><code class=\"text\">bob@work-laptop:~/projects/github.com/bob-crutchley/notes$ curl http://localhost\nDefault Location\nbob@work-laptop:~/projects/github.com/bob-crutchley/notes$ curl http://localhost/one\nLocation One\nbob@work-laptop:~/projects/github.com/bob-crutchley/notes$ curl http://localhost/two\nLocation Two\n</code></pre>"}, {"gitUri": "topics/nginx/modules/web-server-configuration", "overview": "NGINX can be configured as a web server to serve content such as HTML, CSS, JavaScript and Images.", "name": "Web Server Configuration", "resourceName": "nginx/web-server-configuration", "content": "<h1>Web Server Configuration</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#web-servers\">Web Servers</a><ul>\n<li><a href=\"#hardware\">Hardware</a></li>\n<li><a href=\"#software\">Software</a></li>\n</ul>\n</li>\n<li><a href=\"#configuration\">Configuration</a><ul>\n<li><a href=\"#toplevel-contexts\">Top-Level Contexts</a></li>\n<li><a href=\"#virtual-server\">Virtual Server</a></li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#prerequisites\">Prerequisites</a></li>\n<li><a href=\"#install-the-web-application\">Install the Web Application</a></li>\n<li><a href=\"#configure-nginx\">Configure NGINX</a></li>\n<li><a href=\"#access-the-web-application\">Access the Web Application</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>NGINX can be configured as a web server to serve content such as HTML, CSS, JavaScript and Images.\nThis allows us to deploy our web applications so that they can be accessed efficiently.</p>\n<h2>Web Servers</h2>\n<p>A web server could be referring to hardware, software, or a combination of both, although you could refer to the software counterpart as a HTTP server.</p>\n<h3>Hardware</h3>\n<p>From a hardware perspective, a web server would be a computer that has web server software installed on it and is connected to the internet.\nThis computer would also have all files that are going to be served (HTML documents, CSS, images and JavaScript files).</p>\n<h3>Software</h3>\n<p>The software will allow users to connect and access the files stored on the computer.\nThis will most often be a HTTP server.\nHTTP servers are a type of software that can understand Universal Resource Locators (URLs), allowing applications like web browsers to download and utilise their resources for things like web applications that we use everyday.</p>\n<p>Web servers, software and hardware combined, allow us to access content over the internet - most commonly in our web browser:\n<img alt=\"Web Server\" src=\"https://lh3.googleusercontent.com/jjIKwaFUdtPFK4785VQbd67_F0g_t3Q2FoAwWp6A7-jBwIel3r8nlRh5sWVzIu50TVIVJCcC6AkQDC5_KH2RrbQbEGDnhEcF8-Ebs_bZX_eadZS_40GrXdgN5WqhEhvM07H8wGuVU1UpcJ9tHmwYrIiLFlhGdZLl8H1gLnf8KA_FJVz_EE4quNo-jnU3a-fCTI5pgh6BocULmrQBqbxkDLVKN0cpUlACuPqrUf9i0zcWus8SCat3fHrX8TV1lwrYkKQ4rIT0hh-MyhSNL94NC8iXr_x1XQoOCZD422eQBIMVXtMkY_QbkkKf8VqHNLm5QA1L8-u1XjIGoUmVmINQm1w73EZARbgcHX2BQ02WCS83COehpZybXSp3mdRp3V59-qeuygR2uhpkhJnCyhTk5iWW4AEU8YPAugtcN1b4EjWVq9V2xRnav6WvElo-J486ZUKK0ygxDY-blBVLxZcqOTwxhdUW1LzwxhtVZeYLdO3P62QjUYKgSjDzyJlEpSMXxLVCTiCff1ARNd32Z2zPmBWMmiyj7qWOxMl9p31aaLscvZEHg1uTs0hY7D9cj9jFk4oQqHhcrrrJbRhIxHUO0bYJBfD2ntPSMUJdlr6y0ylcKP1Q63FdPDTw9_zpJdyVCjMLy0H4JrKpU4oxuwyjf20iO1mYbgcp-9Pyds8ikUamkxYTRnKL2HdhC0p0B_BB2TBIemY1QOO5h83Lp336h67RWM5CLfzBgGbRaDzwnSUHkI0m=w1254-h620-no\" /></p>\n<h2>Configuration</h2>\n<p>This section discusses how you can configure an NGINX server to serve a web application over HTTP.</p>\n<h3>Top-Level Contexts</h3>\n<p>We first need to ensure the top-level contexts are in place; this includes <code>events</code>, <code>http</code> and <code>server</code>.\n- The <code>events</code> context must be included, even if it doesn't have anything configured inside it.\n- The <code>http</code> context is going to be added so that we are able to access the web application over HTTP.\n- The <code>server</code> context is going to be used to create a virtual server, which will serve the web application files.</p>\n<pre><code class=\"text\">events {}\nhttp {\n    server {\n    }\n}\n</code></pre>\n\n<h3>Virtual Server</h3>\n<p>The virtual server must be configured to understand a few important things.\nAll the points discussed below are configured in the virtual <code>server</code> context.\n- Where are the web application files?\n    - The installation folder of your web application files can be set with the <code>root</code> directive.\n- What's the default index file?\n    - Conventionally, the default page for a web application is the <code>index.html</code> file; this can be specified with the <code>index</code> directive.\n- Multipurpose Internet Mail Extensions (MIME) Types\n    - MIME Types are a way of providing more information about the files being served, so that your web browser can handle them correctly.\n    - MIME Types are important especially for more modern web application frameworks and libraries using JavaScript extensively such as React, VueJS and Angular\n    - MIME Types configurations come preconfigured with NGINX and can just be just added to the virtual server configuration using an <code>include</code> directive.\n- Location context for accessing other resources\n    - Web applications will commonly pull in other files to use, such as CSS and JavaScript.\n    - The <code>try_files</code> directive can be used to help find resources, and default to a certain location if the requested resource can't be found.</p>\n<pre><code class=\"text\"># for general traffic processing\nevents {}\n# for serving over http\nhttp {\n    # virtual server for http\n    server {\n        # accessable on port 80\n        listen 80;\n        # the folder which the web application is installed\n        root /opt/web-application;\n        # the default web page\n        index index.html;\n        # included mime types\n        include /etc/nginx/mime.types;\n        # location context so that files from the server can be downloaded and used by your browser\n        location / {\n            try_files $uri $uri/ /;\n        }\n    }\n}\n</code></pre>\n\n<h2>Tasks</h2>\n<p>This section will walkthrough configuring an NGINX server to host the web application included on this module, using the above information as a reference.\nIf possible, it's advised to have a Linux virtual machine for this task with a public IP address and firewall port <code>80</code> open so that it can be easily deleted afterwards, as opposed to cluttering your work machine.</p>\n<h3>Prerequisites</h3>\n<p>Make sure that you have the following installed for this:\n- Git\n- NGINX</p>\n<h3>Install the Web Application</h3>\n<p>The web application in question is included in this module folder.\nAll we need to do is install the application into a suitable folder, such as <code>/opt/web-application</code>:</p>\n<pre><code class=\"bash\"># clone this repository\ngit clone https://github.com/bob-crutchley/notes\n# copy the web application folders to /opt/web-application\nsudo cp -r notes/topics/nginx/modules/web-server-configuration/web-application /opt/\n</code></pre>\n\n<h3>Configure NGINX</h3>\n<p>We'll now need to configure NGINX to host our web application.\nEnter the following into the <code>nginx.conf</code> file:</p>\n<pre><code class=\"text\">events {}\nhttp {\n    server {\n        listen 80;\n        root /opt/web-application;\n        index index.html;\n        include /etc/nginx/mime.types;\n        location / {\n            try_files $uri $uri/ /;\n        }\n    }\n}\n</code></pre>\n\n<h3>Access the Web Application</h3>\n<p>Your web application should be accessable either on <code>localhost</code> if you installed it on a local machine or the public IP address on port <code>80</code>:\n<img alt=\"NGINX Web Application\" src=\"https://lh3.googleusercontent.com/4rBKXTIQR1IfBUGO5Z8xsNdrLhG8obTn4s6TICIT-j5mc9jk1twZSzw4nmA9CNmglAW8MciKcyHLaA6OXuav-XmrHy0V-_FA1xncKWf3r52GWXdkzwP4eLKoLqDiRBo--OvmBVX7VUVC6NTyOozMXusjEHWSMjaS40dbi_pXwEDDlp-7VcOGOlWFf2-Y3r1COPGAooOHaq2ZOTbRJIdwwPmCEMPG8wAXQ6fvlFAPEhEZzaThMXxn2kgAzELzfVHjW4sEQ4xJDn0tDHcn8tAHzSwyHtRSkG4yW88X5sZ75zB54pWrtU8Dt7xz_iazN0NxezbZ-ohjJdL9yRepmjqtrt-5lNhHperlnfooAAtM8CEF6GfJSORkRc5EK1J31vbhq2_-uL-Twq_FYaXjU-8poxUnaA--esG3R8FskxHowbGIZOXqzrqoFqlX5LLK4BeBZoIpMbJLQ2qX9GvSQ9-UluI6ICxGQlXlc0XEl-XCEWf2nf2nJ-KgO6vhKFIjH_EmDTLrVezSNQOWnRJ-cHXwBOy_QiBWPOPEfLvu5nBmcyn-zWu5B3JpmwjL-f1ECI3zH4gLDBrCOVhCi6demvW-Pm6yXeoFQCQZTcMUZh_WMuyvaeT20M-Lv8FZsxCrlBiz42h8EO0hJKXxmLHuaAPD_3Szw5ccxEAU__m3rGP1BiXkKyDxhpGxTwmVepaUV3wXiP2J1Toe2kPlwhK-jG8Ne4RsjBV6-21-n3yIzvrl-7Rl6AZf=w1028-h450-no\" /></p>\n<p>If you see this page then you have completed the task, otherwise double check your NGINX configuration and make sure that the web application is installed into <code>/opt/web-application</code>.</p>"}, {"gitUri": "topics/nginx/modules/http-reverse-proxy-configuration", "overview": "An NGINX reverse proxy server sits in front of web servers and forwards client requests (e.g. web browsers) to those web servers.", "name": "HTTP Reverse Proxy Configuration", "resourceName": "nginx/http-reverse-proxy-configuration", "content": "<h1>HTTP Reverse Proxy Configuration</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#reasons-for-using-a-reverse-proxy\">Reasons for Using a Reverse Proxy</a><ul>\n<li><a href=\"#load-balancing--global-server-load-balancing\">Load Balancing &amp; Global Server Load Balancing</a></li>\n<li><a href=\"#protection-from-attacks\">Protection from Attacks</a></li>\n<li><a href=\"#caching\">Caching</a></li>\n<li><a href=\"#tlsssl-encryption\">TLS/SSL Encryption</a></li>\n<li><a href=\"#visual-representation\">Visual Representation</a></li>\n</ul>\n</li>\n<li><a href=\"#configuration\">Configuration</a><ul>\n<li><a href=\"#basic\">Basic</a></li>\n<li><a href=\"#multitier-applications\">Multi-Tier Applications</a></li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#prerequisites\">Prerequisites</a></li>\n<li><a href=\"#configure-the-api-virtual-machine\">Configure the <code>api</code> Virtual Machine</a><ul>\n<li><a href=\"#make-sure-git-is-installed\">Make Sure Git is Installed</a></li>\n<li><a href=\"#download-and-install-the-api-application\">Download and Install the <code>api</code> Application</a></li>\n</ul>\n</li>\n<li><a href=\"#configure-the-webapp-virtual-machine\">Configure the <code>web-app</code> Virtual Machine</a><ul>\n<li><a href=\"#make-sure-git-is-installed-1\">Make Sure Git is Installed</a></li>\n<li><a href=\"#download-and-install-the-webapp-application\">Download and Install the <code>web-app</code> Application</a></li>\n</ul>\n</li>\n<li><a href=\"#configure-the-nginx-virtual-machine\">Configure the <code>nginx</code> Virtual Machine</a><ul>\n<li><a href=\"#install-git\">Install Git</a></li>\n<li><a href=\"#configure-nginx\">Configure NGINX</a></li>\n</ul>\n</li>\n<li><a href=\"#view-the-web-application\">View the Web Application</a></li>\n<li><a href=\"#get-the-current-date\">Get the Current Date</a></li>\n<li><a href=\"#clean-up\">Clean Up</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>An NGINX reverse proxy server sits in front of web servers and forwards client requests (e.g. web browsers) to those web servers.\nReverse proxies are typically implemented to help increase security, performance, and reliability.</p>\n<h2>Reasons for Using a Reverse Proxy</h2>\n<p>There are several reasons for configuring your web applications to be behind a reverse proxy.</p>\n<h3>Load Balancing &amp; Global Server Load Balancing</h3>\n<p>Reverse proxies can be used as load balancing solution for popular websites that cannot handle all of the incoming traffic on a single server.\nThis can also be introduced on a global scale for directing customers to your services which are located closer to them geographically.\nClients would connect to the NGINX server, then NGINX would distribute the traffic evenly over the application servers behind it.</p>\n<h3>Protection from Attacks</h3>\n<p>By using a reverse proxy, information about the applications behind it are not revealed, making it harder for attackers to establish unwelcome connections to your applications.</p>\n<h3>Caching</h3>\n<p>Caching can be used to save on time and network traffic.\nResources and information received from remote locations by the reverse proxy can be cached so that it doesn't have to make another request for them if another client asks for the same thing such as a public image or icon.</p>\n<h3>TLS/SSL Encryption</h3>\n<p>Encrypting traffic is now almost just expected when you visit a website however, encrypting and decrypting all requests can be expensive computationally.\nA reverse proxy can be used to encrypt and decrypt communications before passing it on to your web applications which can be configured in a private subnet, only accessible by the reverse proxy.\nThis would save your web application servers from having to handle any encryption and would still be a solution secure enough for many scenarios.\nYou can of course implement TLS internally behind the reverse proxy to adhere to any mandatory compliances or requirements.</p>\n<h3>Visual Representation</h3>\n<p>Consider the following diagram and points for the service hosted on <code>example.com</code>:\n- More than one instance of the web application can be hosted behind the NGINX reverse proxy.\n- NGINX will balance HTTP traffic between the two istances of the web application evenly.\n- If the web server wants to make requests to an API or backend service, this can be done using NGINX as well. All requests starting with <code>/api</code> can be sent to the API servers instead of the web application, you will get a chance to implement and understand this in the Tasks section.</p>\n<p><img alt=\"NGINX Reverse Proxy\" src=\"https://lh3.googleusercontent.com/dzet9BkO4Vy3BQn61CKpu7KMAeBPngZPZFdPGWLwk8pOlyIp4KgR4lFr6OiwSQDq_XZ_GlBvX0FsQIWMF_v7bxXpdonWNNK7oDBHqDOzczo_HWuPuHI7uOdtofYV2K5vzBb3wD3epF5JjFl_mxDEjwYKb1hn5a69bc6ZdT-wnsvmbbG2F2944LngaAeec6a2QSbVBg4cWHw3FkzYhaFaumBa86ZljYsIOn2d0h4yPtNjGkwM1LXgC8n4DqM-gXO_Nu-bbJHkX-GG1iUCNXZgbNpTS5RoPCsN9YTOyJ9w15CRYTap3RX6c0o5nFxArcqGIdCWEoLvQlNK72ENRh17sgOxtzg2WCXi4eSovnDJ3WW-Zm35ci3IgZ4arWZqU8dGI5zDE67YPOz_hxwWo_eLR0CXTjk2hZDFhgFTf-WX8CHrgtbjetFFQdZ3dxOs6-33DDBEoPxyAAKA4iYdj5LlH6taiRoU2rbbN3xGIq5wFAdgpT7l8IIvLaogY6dTVXQCk3ijos5nvZD4Ar1TvN10agbqZKi4W629h7K3c2q7Jz1rktKd9PGjxEaWFnRBU047lr4E7A4dGAmPTTQWvMpZm5ej27cV3bxDqC_iW01u-UfAUdEZ5HAMDAflorYBy1NMOAkcZBrC-L6wZ3YxdukFwJ0Q9q4FxLxmtS4aFPgYdPhaZUdXGamUy9pk6mbVyBTr_jasuNIWxaq4SG7O3cuptlzIXVhO3Yf2AIw2fHPaj5LMbAvs=w1168-h669-no\" /></p>\n<h2>Configuration</h2>\n<h3>Basic</h3>\n<p>A simple NGINX reverse proxy can be configured by using a <code>proxy_pass</code> directive for a <code>location</code> context inside a HTTP virtual server.\nThis example will proxy HTTP requests to the <code>web-app</code> host on port <code>80</code>:</p>\n<pre><code class=\"text\">events {}\nhttp {\n    server {\n        listen 80;\n        location / {\n            proxy_pass http://web-app;\n        }\n    }\n}\n</code></pre>\n\n<h3>Multi-Tier Applications</h3>\n<p>Applications are often developed in multiple tiers; front-end, back-end and database for example.\nNGINX can be used as reverse proxy, giving access to different tiers of the application depending on what URL is used.\nHere is an example for a reverse proxy configuration that serves the <code>web-app</code> by default, but when <code>/api</code> is accessed, HTTP requests are sent to the <code>api</code> server:</p>\n<pre><code class=\"text\">events {}\nhttp {\n    server {\n        listen 80;\n        location / {\n            proxy_pass http://web-app;\n        }\n        location /api {\n            proxy_pass http://api;\n        }\n    }\n}\n</code></pre>\n\n<h2>Tasks</h2>\n<p>This guide will walk you through deploying an application behind an NGINX reverse proxy that has a front end and backend service.</p>\n<h3>Prerequisites</h3>\n<ul>\n<li>\n<p>3 Ubuntu or Debian virtual machines on the same network/subnet with the host names as follows:</p>\n<ul>\n<li><code>nginx</code></li>\n<li><code>web-app</code></li>\n<li><code>api</code></li>\n</ul>\n<p>On cloud providers like AWS, Azure and GCP this is usually done by just naming the virtual machines as shown above when you are creating them.\n- The <code>nginx</code> virtual machine will need a public IP address and have port <code>80</code> accessible for incoming traffic over the internet.</p>\n</li>\n</ul>\n<h3>Configure the <code>api</code> Virtual Machine</h3>\n<p>The API is going to return a date and time when a GET request is made to <code>/api/date</code>.\nConnect to the <code>api</code> virtual machine and use the commands shown in this section to install the API server.</p>\n<h4>Make Sure Git is Installed</h4>\n<p>We are going to use Git to download the application files that are on store in this module folder, for that we will of course need Git installed.</p>\n<pre><code class=\"bash\">sudo apt update\nsudo apt install -y git\n</code></pre>\n\n<h4>Download and Install the <code>api</code> Application</h4>\n<p>The <code>api</code> application can now be installed by cloning this repository with Git, changing to the <code>api</code> directory and running the <code>setup.bash</code> script:</p>\n<pre><code class=\"bash\">git clone https://github.com/bob-crutchley/notes\ncd notes/topics/nginx/modules/http-reverse-proxy-configuration/application/api\n./setup.bash\n</code></pre>\n\n<h3>Configure the <code>web-app</code> Virtual Machine</h3>\n<p>The web application is very simple; it uses basic JavaScript for connecting to the API server.\nConnect to the <code>web-app</code> virtual machine and install the application using the commands shown in this secion.</p>\n<h4>Make Sure Git is Installed</h4>\n<p>Git will need to be installe on this virutal machine as well, run a  command to make sure the APT repositories are up to date and install git:</p>\n<pre><code class=\"bash\">sudo apt update\nsudo apt install -y git\n</code></pre>\n\n<h4>Download and Install the <code>web-app</code> Application</h4>\n<p>We can now go ahead and install the <code>web-app</code> application by cloning this repository, changing to the <code>web-app</code> directory and running the <code>setup.bash</code> script.</p>\n<pre><code class=\"bash\">git clone https://github.com/bob-crutchley/notes\ncd notes/topics/nginx/modules/http-reverse-proxy-configuration/application/web-app\n./setup.bash\n</code></pre>\n\n<h3>Configure the <code>nginx</code> Virtual Machine</h3>\n<p>NGINX is going to be the component that ties together the Web application and API server.\nAll HTTP requests are going to go through NGINX first but then sent to the correct service depending on what URL was requested.</p>\n<p>You will see that there is a button on the Web application which makes a HTTP GET request to <code>/api/date</code> and then displays that information on the page.\nBecause the URL starts with <code>/api</code>, our NGINX configuration is going to proxy the request to the <code>api</code> server and get the response from that service.</p>\n<p>This is the configuration that is going to be installed into NGINX for you:</p>\n<pre><code class=\"text\">events {}\nhttp {\n    server {\n        listen 80;\n        location / {\n            proxy_pass http://web-app;\n        }\n        location /api {\n            proxy_pass http://api:3000;\n        }\n    }\n}\n</code></pre>\n\n<p>To get the NGINX server setup, connect to your <code>nginx</code> virtual machine and run the commands shown below.</p>\n<h4>Install Git</h4>\n<p>We are going to get the NGINX configurations onto the <code>nginx</code> virtual machine by using Git as well.\nUpdate the APT repository and install Git with these commands:</p>\n<pre><code class=\"bash\">sudo apt update\nsudo apt install -y git\n</code></pre>\n\n<h4>Configure NGINX</h4>\n<p>NGINX can now be configured by downloading he configurations with Git, changing to the <code>nginx</code> directory and running the <code>setup.bash</code> script:</p>\n<pre><code class=\"bash\">git clone https://github.com/bob-crutchley/notes\ncd notes/topics/nginx/modules/http-reverse-proxy-configuration/application/nginx\n./setup.bash\n</code></pre>\n\n<h3>View the Web Application</h3>\n<p>Now that everything is setup we can make sure that the application is working.\nNavigate to the public IP address of you <code>nginx</code> virtual machine in your web browser, you should then see something like the image below.</p>\n<p>Please note that your public IP address will almost certainly be different to the one shown in the screenshots.</p>\n<p><img alt=\"NGINX Web Application\" src=\"https://lh3.googleusercontent.com/8KgJlGCqQ2rA9lvVBJzzD5G4vcMRTD6USiKEpmpWfx-0qxIcqjbzlqGX8BcybufPtvH69ZI5CDs7D2i57wubM8cvmZvHKJ0mz3KkwMCKN-0L1qnkeEKQoz5XDQyiy_ncvb7tKgLpRV5xkSfy-d2UQ5Ab-w69pULRzjvcaFoKkvOaa9DCU1C78NN-nTulKGDbkcmxJo6R0AngL_J0tM9esVov1aJ0WMeDB-P8O_2lwp7ixMLlvF-ZdxnrMcad0WbVBN4XFUQt089yFVUk3qgXkTkGu9WruTRZd3CM3Aw4AOVmUjavPU3Ioxpp8TqIBH5K9Lg99ovV_BJ7014jS94cDQlfyWzA0y1vWZS-0482TXswdf3dSjLZip0ecAv42AgkcMnxo98QH1vulQMUz5itW_N1icHWwFz2xdI51eC4vz5aPUg_tboCMgVdJoAROFR5t3Nh1CAE9zyelQEQU4ONvfoshAJwl6eSB2Esk70A3MSQAL1rghNZcluApMI1edFUMpGl_C_EZxpfsHapNQTMLH-p-ojQi4mlrJl3zlGcOERCAYmO9So7sVqmeD1ZGhVlh6QJelDthujDOCr4t3-noMafqD73x0aso39GhdC8a-Ba_DjkrBIWaOWB4yaWs2Nmppkj-ThbylzpBZ9JfnCs2gtVc8Lu28P9GGhIPAQBbYYBbB-qgHxykc7mNcwHsmdBAKgFvl_NersOouoFgr7WFadP7GpxJJ9EJGWIYlfzbirpgXFu=w1026-h357-no\" /> </p>\n<h3>Get the Current Date</h3>\n<p>Click the button on the web page to get the current date, it should then be displayed on the webpage:</p>\n<p><img alt=\"NGINX Web Application Button Click\" src=\"https://lh3.googleusercontent.com/S5I_ONtk_ufb1rTmlL4cRBngAZ9mtJo3DWdEKzEKF0ADP9InvYEA6jUMCqlB224JUBjxLvfa7Jv5rYa_nNY_hYmnsQRGiUlqmbhgTDshtvk1IYz4Zkmmn1r5jOImmzZrMUSvcN8fbcT_IMlbbPFBYTq9bMecHJ4tlsdqWvl0Y98Y5mkdrStsO_SoDPAJsFKtsLbU6jdNcLlw_5GVglIOPE50vFR1batgymfbpatTCwCsObTtgYYSow5G_JaAWPxbau44iXAt65rA4L76zQe4yDhJIyPE6gwIrqN_sz61fJqTQQToMV9tl8Kxy9Lyz91YewvwYfee63-rqcRvISdFcXoxMZqAozuSRCdvQYxztSXxii_CjhpdlI8VikUeVsDtJI0dcwKgY2wIQTnb0BHuirLQhcsPyQz5P-R-SosRaGDxYYWsfIgjKmuMRplQ99BQ7-KsAY8Ar5i96pDARNbCbqAYYP41OszfVQYnk6V2GPl7HlhwX8O1bWkRP69jGUjefUcCTWy1znMwRuUZm0OUzhLztjxufrjIOH13ZIPKTORyJkk1yBoe629etMUwN2VJhwNlOunkqgCzooJaw-TzoT1b3AmtsvX74wIVuI_kHH_QacXMUbZEu1MEWyw0WX7XDSy6mii-37qsYExgvpuWo1jO7-RA2bDxY84N0TimjgSiBZBOTSwGdbRiZRACp96aPh6rjwus6D1tusW1A6Yitbd_xsMrs3AMbt0IOUCXN7ChTUnq=w1024-h349-no\" /> </p>\n<h3>Clean Up</h3>\n<p>You can now finish this task by deleting any virtual machines, virtual networks, subnets and firewall rules that you created while working on this task.</p>"}, {"gitUri": "topics/nginx/modules/introduction", "overview": "Nginx is a web server which can also be used as a reverse proxy, load balancer, mail proxy and HTTP cache.", "name": "Introduction", "resourceName": "nginx/introduction", "content": "<h1>Introduction</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#installation\">Installation</a><ul>\n<li><a href=\"#linux\">Linux</a><ul>\n<li><a href=\"#centosrhel\">CentOS/RHEL</a></li>\n<li><a href=\"#debianubuntu\">Debian/Ubuntu</a></li>\n</ul>\n</li>\n<li><a href=\"#windows\">Windows</a></li>\n<li><a href=\"#docker\">Docker</a></li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#install-nginx\">Install NGINX</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>Nginx is a web server which can also be used as a reverse proxy, load balancer, mail proxy and HTTP cache.\nThe goal behind NGINX was to create a fast web server for handling a large amount of concurrent connections.\nNGINX has a few common use cases:\n- Static files: NGINX can serve static files, such as HTML, CSS and JavaScript.\n- Act as a reverse proxy: handle and process all requests before sending them to another application server.\n- Be used as a load balancer: requests can be distrubed over multiple instances of your application to allow for high availability should one of you application servers fail.</p>\n<h2>Installation</h2>\n<h3>Linux</h3>\n<p>On Linux systems, NGINX can usually be installed using the relevant package manager:</p>\n<h4>CentOS/RHEL</h4>\n<pre><code class=\"bash\">sudo yum install -y nginx\n</code></pre>\n\n<h4>Debian/Ubuntu</h4>\n<pre><code class=\"bash\">sudo apt install -y nginx\n</code></pre>\n\n<h3>Windows</h3>\n<p>An installer for NGINX can be downloaded from the <a href=\"http://nginx.org/en/download.html\">NGINX downloads page</a>.\n- Download the latest, stable version of NGINX\n- Unzip the downloaded file\n- Run the <code>nginx.exe</code> executable - don't worry if it seems like nothing happens, NGINX will run in the background.</p>\n<h3>Docker</h3>\n<p>If you have Docker configured then you can get NGINX running using the <code>nginx</code> image:</p>\n<pre><code class=\"bash\">docker run -d --rm -p 80:80 --name nginx nginx\n</code></pre>\n\n<p>Once you have installed NGINX for your relevant Operating System, you can navigate to <code>http://localhost</code> in your web browser to see if NGINX is running. If you are on Linux and don't have a GUI, then you can run <code>curl http://localhost</code> to see if you can get a response from the NGINX service.</p>\n<p>Once you have put <code>http://localhost</code> in your web browser you should see a page like the following:\n<img alt=\"NGINX Default Page\" src=\"https://lh3.googleusercontent.com/G4w7DJI6YST8allYA8rBpnrySbB0N4sundqXZQbux85RgFtHC08kb6-MsvHgO2dICdlecfvU5D1UEim1LGTNwZFRJLASopmASoGeCV2lnICpJz84jI_XU-Y-TjBs4u-m8lP8wYe-ziKv0ZR3K4UZ_j0tVMcfrdckNo7lL_OGyUa9wE2ZgZecS9otx7zVNusXgYphtI2PGzA6F0d6QJEDIE5wrbsZzFHSmtNLwzDkY3ILGaJTEGfkfCT7QHT82-d3ck_6nnO_IHfCGw80yAyBznUHa7RBEv_h5i1Nq8ePQLd9rwcKV7-LZyHcQJG1P4CSy3sZYtcsOaSzlr67QMIZMj_OnfaULmcLnZICk5JXGzRYqvjuG8SPMRYjdzGR3n6fBAL_G6s6lFuROuT4EtaMoiJN0YkibJw_RjPKkKbUjJYvon8G9KzvSlonY8mvm0Cdt_UQu9B1jKy-2A0CgTxDmp56mfKo4yEDlwl4l2oejvIdQ-w26RacR1C625xc3ffEGsUf9fppfwQgKkWVps_Nd5z86xmCm4kZysluOYHohTihokpiMU6YN6L2oHhyHj8xbC0MRywEbL-sUmtBTv6rOZF770c3NeO0RGu5axeAsho0t_1ANO0gdk35oMlYfG38ikreb9_il6UHXK8v5SWsQur5foFgFskX_Ti-3uC2fS-5V56lqzBRlNDPZ08VZlrEpN3XHu-pVgTaH3OXrU6RiYWPT6vNtDy5nvf1dgUQko97-TH6=w748-h295-no\" /></p>\n<p>If you used the <code>curl</code> command on a terminal then you should see the HTML response:</p>\n<pre><code class=\"text\">bob@work-laptop:~/projects/github.com/bob-crutchley/notes$ curl http://localhost\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;Welcome to nginx!&lt;/title&gt;\n&lt;style&gt;\n    body {\n        width: 35em;\n        margin: 0 auto;\n        font-family: Tahoma, Verdana, Arial, sans-serif;\n    }\n&lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;\n&lt;p&gt;If you see this page, the nginx web server is successfully installed and\nworking. Further configuration is required.&lt;/p&gt;\n\n&lt;p&gt;For online documentation and support please refer to\n&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;\nCommercial support is available at\n&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;\n&lt;/body&gt;\n&lt;/html\n</code></pre>\n\n<h2>Tasks</h2>\n<h3>Install NGINX</h3>\n<p>Install NGINX for your current Operating System.</p>"}]}, {"gitUri": "topics/cloud", "overview": "", "name": "Common Cloud Concepts", "resourceName": "cloud", "modules": [{"gitUri": "topics/cloud/modules/cloud-enabling-technologies", "overview": "In this module you will learn what technologies allow cloud services to work.", "name": "Cloud Enabling Technologies", "resourceName": "cloud/cloud-enabling-technologies", "content": "<h1>Cloud Enabling Technologies</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a><ul>\n<li><a href=\"#fast-widearea-networks\">Fast wide-area networks</a></li>\n<li><a href=\"#disaster-recovery\">Disaster recovery</a></li>\n<li><a href=\"#powerful-inexpensive-server-computers\">Powerful, inexpensive server computers</a></li>\n<li><a href=\"#benefits-of-virtualization\">Benefits of virtualization</a></li>\n<li><a href=\"#virtualization-vs-multitenanting\">Virtualization VS Multi-Tenanting</a></li>\n<li><a href=\"#containers\">Containers</a></li>\n<li><a href=\"#task\">Task</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>In this module you will learn what technologies allow cloud services to work.</p>\n<h3>Fast wide-area networks</h3>\n<p><em>Wide Area Network</em> (WAN) is a telecommunication network that is spread over a large area. \nThe most commonly known WAN is the internet.\nHouses, villages, cities, countries and continents are all connected together.</p>\n<p>In order to get the location-independence of the cloud, you need a fast WAN. \nOtherwise the users and the servers all need to be physically close, or connected by a dedicated network.</p>\n<p>With a fast, wide-area network, we can support users in many different locations, and we can support high\n-availability disaster recovery solutions that would previously have been unworkable.</p>\n<h3>Disaster recovery</h3>\n<p>Disaster recovery is the strategy of backing up and having the ability to restore and maintain electronic records in\n a cloud environment. \n This is important if you want to be prepared for a man-made or a natural catastrophe.</p>\n<p>Cloud providers have these strategies in place for it's clients, of course that comes as an additional cost. \nYou could be charged based on bandwidth, storage space or pay-per-use.</p>\n<p>You could implement these strategies, but before implementation there are a few things to consider:\n* Is the bandwidth fast enough to move the data between primary site and the cloud\n* Can the data be encrypted in flight</p>\n<h3>Powerful, inexpensive server computers</h3>\n<p>In order to get the pool of interchangeable resources required by a cloud, we need to be able to buy lots of servers \nthat are configurable, and they need to be reasonably powerful.</p>\n<p>Building a data centre is a specialist skill, and there are standards and bodies of knowledge related to it.</p>\n<p>Data centres are becoming increasingly efficient and cheap, to the extent that it is possible to get a containerised \n<code>modular data centre</code> shipped to you.</p>\n<p>When choosing a cloud provider, they should be able to document the standards to which their data center adheres.</p>\n<p>TIA-942 and Uptime Institute are the two best-known examples.</p>\n<h3>Benefits of virtualization</h3>\n<p>Benefits can include:\n* Elasticity/scalability\n* Resource pooling on common infrastructure\n* More efficient use of physical resources\n* Granularity of monitoring and pricing\n* No leakage of data from one guest to another</p>\n<p><code>Noisy neighbours</code> \u2013 one guest using all the bandwidth/CPU/etc and the servers all need to be physically close, or\n connected by a dedicated network.</p>\n<h3>Virtualization VS Multi-Tenanting</h3>\n<p>Virtualization is a type of multi-tenanting, in that it allows multiple users to share a single physical resource.\nIt does this by separating the users at the hypervisor level.\n* Namely, every customer has their own virtual machine, from the OS up</p>\n<p>However, when we use the term multi-tenanting, we usually use it to refer to application-level separation of users\n within a single virtual machine.\n* The virtual machine is hared by many customers\n* Isolation is enforced by the application</p>\n<p>Software-as-a-service is frequently multi-tenant, for Cloud services such as Gmail\n* <code>My webmail provider almost certainly uses virtualisation, but when I log on, I don\u2019t get a virtual machine all to\n myself. Instead, the application prevents me from seeing other users email</code></p>\n<h3>Containers</h3>\n<p>Subdivide a single virtual machine, which results in less overhead than creating multiple VMs:\n* Does not require hardware support or emulation\n* Containers are isolated at the user (as opposed to kernel) level</p>\n<p>Docker is the best-known container technology <a href=\"https://docker.com\">docker.com</a>.</p>\n<p>Package an application and its dependencies as a unit.\n* Run on any Linux server: flexible and portable\n* Windows support expected soon\n* Integrated into many other cloud products</p>\n<h3>Task</h3>\n<p><strong>List all the cloud enabling technologies you have learned about in this module</strong>\n<details>\n<summary>Show Solution</summary>\n<ul>\n  <li>Fast wide area networks</li>\n  <li>Disaster recovery</li>\n  <li>Powerful, inexpensive server computers</li>\n  <li>Benefits of virtualization</li>\n  <li>Virtualization VS Multi-Tenanting</li>\n  <li>Containers</li>\n</ul>\n</details></p>\n<p><strong>Can you implement disaster recovery for on-premises hosting?</strong>\n<details>\n<summary>Show Solution</summary>\nYes, with appropriate configuration. \nAdditionally security, and infrastructure has to support it.\n</details></p>\n<p><strong>List out the benefits of virtualization</strong>\n<details>\n<summary>Show Solution</summary>\n<ul>\n  <li>Elasticity/scalability</li>\n  <li>Resource pooling on common infrastructure</li>\n  <li>More efficient use of physical resources</li>\n  <li>Granularity of monitoring and pricing</li>\n  <li>No leakage of data from one guest to another</li>\n</ul>\n</details></p>"}, {"gitUri": "topics/cloud/modules/cloud-concepts", "overview": "In this module you will learn about the concepts of cloud. These concepts are shared among all the cloud providers.", "name": "Cloud Concepts", "resourceName": "cloud/cloud-concepts", "content": "<h1>Cloud Concepts</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a><ul>\n<li><a href=\"#what-is-the-cloud\">What is the Cloud?</a></li>\n<li><a href=\"#ondemand-self-service\">On-demand self service</a><ul>\n<li><a href=\"#google-cloud-platform-gcp\">Google Cloud Platform (GCP)</a></li>\n<li><a href=\"#amazon-web-services-aws\">Amazon Web Services (AWS)</a></li>\n<li><a href=\"#microsoft-azure-az\">Microsoft Azure (AZ)</a></li>\n</ul>\n</li>\n<li><a href=\"#consumption-based-pricing\">Consumption based pricing</a></li>\n<li><a href=\"#broad-network-access\">Broad network access</a></li>\n<li><a href=\"#resource-pooling\">Resource pooling</a></li>\n<li><a href=\"#rapid-elasticity\">Rapid elasticity</a></li>\n<li><a href=\"#measured-service\">Measured service</a></li>\n<li><a href=\"#fault-tolerance\">Fault tolerance</a></li>\n<li><a href=\"#economies-of-scale\">Economies of scale</a></li>\n<li><a href=\"#capital-expenditure\">Capital expenditure</a></li>\n<li><a href=\"#task\">Task</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>In this module you will learn about the concepts of cloud. These concepts are shared among all the cloud providers.</p>\n<h3>What is the Cloud?</h3>\n<p>The terms \u2018cloud computing\u2019 and \u2018the cloud\u2019 have been used to describe all kinds of different technology. Are we\ntalking about Distributed computing? Networked Services? Virtualized Servers or Hosted services? The actual\ndefinition of cloud computing as reported by NIST (National Institute of Standards and Technology) is: <code>Cloud computing \nis a model for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing \nresources (e.g. networks, servers, storage, applications, and services) that can be rapidly provisioned and released \nwith minimal management effort or service provider interaction</code></p>\n<h3>On-demand self service</h3>\n<p>All cloud providers have a dashboard through which the customers can control the services that the provider offers. \nHence the name <code>on demand self service</code>.</p>\n<h4>Google Cloud Platform (GCP)</h4>\n<p>This is how it looks for Google Cloud:\n<img alt=\"Fork &gt;\" src=\"https://imgur.com/lwJQt2C.png\" /></p>\n<h4>Amazon Web Services (AWS)</h4>\n<p>This is how it looks for AWS:\n<img alt=\"Fork &gt;\" src=\"https://imgur.com/cnqjq2M.png\" /></p>\n<h4>Microsoft Azure (AZ)</h4>\n<p>This is how it looks for Azure:\n<img alt=\"Fork &gt;\" src=\"https://imgur.com/cK3lnGv.png\" /></p>\n<h3>Consumption based pricing</h3>\n<p>A <em>Consumption based pricing</em> is a service and payment scheme where the customer pays according to the amount of\n resources used. \n This is similar to how you would pay utilities companies for electricity/gas/water based on how much you've used it.\nThe prices may have flat rates per resource or they could be varied rates for different component. </p>\n<h3>Broad network access</h3>\n<p>Access over network via <em>standard mechanisms</em> which would generally be taken to mean standard protocols like HTTP or\n TCP. \nServices should be accessible to a variety of clients running on various hardware (phones, laptops, desktops).</p>\n<p>In other words, if it\u2019s only accessible using a proprietary protocol or data format, from custom client, it\u2019s\n probably not cloud computing. </p>\n<p>Notice that <em>network-accessible</em> is not the same thing as <em>internet-accessible</em>; there is no such thing as a private\n cloud on a public network.</p>\n<h3>Resource pooling</h3>\n<p>Cloud services are provided to multiple tenants (users, applications) by a pool of interchangeable resources.\n If each tenant needs its own, specific, customised resources, then it\u2019s not cloud computing.\n  Providing on-demand resources with utility pricing can only make economic sense if the resources come from a shared\n   pool.</p>\n<p>These resources are dynamically assigned and reassigned in order to get optimal use of out of them. \n* Storage, processing, memory, etc.</p>\n<p><strong>Location independent</strong>\n* The customer generally does not know, or need to know the exact physical location of the resources\n* For regulatory and architectural reasons, the customer is generally able to specify a general location; such as the\n country.\n    * e.g. can this data be stored outside of the EU?\n    * Can the application function well if the web-server is in the EU and the data it uses is in Australia?</p>\n<h3>Rapid elasticity</h3>\n<p>Elasticity is a fundamental property of the cloud.\n The ability to use exactly the resources you need, without either under-provisioning or excessively over\n -provisioning, is one of the key benefits of cloud services.\n  Allows the customer to scale in and out with demand. \n* <strong>Note</strong>: usually scaling in and out, as opposed to scaling up and down\nMay even be automatic or transparent to the customer.\nScaling up can be either vertical or horizontal. \nVertical scaling up means adding more resources like RAM or CPU's for the environment.\nHorizontal scaling up means adding more instances.\nScaling down means giving away the resources like RAM or CPU's, or shutting down the VMs.\n<img alt=\"Fork &gt;\" src=\"https://imgur.com/npvHFLR.jpg\" /></p>\n<h3>Measured service</h3>\n<p>If resources are being dynamically provisioned, it\u2019s essential that the customer should be able to monitor the\n performance and usage of those resources in real time.\n  Most cloud resources are offered on a pay-per-use basis, and the customer must be able to monitor their usage in\n   order to control their costs.</p>\n<h3>Fault tolerance</h3>\n<p>Fault tolerance concept exists not only in the cloud but also in the self-hosted environment.\n What this is referring to is the ability for your application to function even if one or more pieces in any layer\n  fails.</p>\n<p>In the cloud, you have auto-scaling as well as multiple geographical zones to help you aid with fault tolerance. \nIn self-hosted domain you would need to configure the infrastructure in order for it to function in case of failure\n or maintenance. This could be done with build and orchestration tools that would monitor your resources and whether\n  they are alive and responding or dead and new ones need to be created.</p>\n<h3>Economies of scale</h3>\n<p>Cost advantage experienced by companies when the level of output increases is known as <em>Economies of scale</em>. \nThis advantage comes from the relationship between per-unit cost and the quantity produced.\n Greater quantity produced lowers the per-unit cost. Increase in the output reduces the average costs, this also\n  falls under the <em>Economies of scale</em>.\n   The increase is brought by synergies of efficiency and operation.</p>\n<p>At any stage of the production process economies of scale can be implemented.\n Production that is mentioned are all the activities related to the commodity but without the final buyer involvement.\n  There are numerous ways how economies of scale can be implemented in the company like: hiring more experienced\n   marketing employees, automate human to machine labor.</p>\n<h3>Capital expenditure</h3>\n<dl>\n<dt><em>Capital expenditure</em> (CapEx) are funds that company uses to upgrade, maintain, acquire physical assets like</dt>\n<dd>buildings, technology, equipment.\n In short CapEx is the expenses that the company shows on the balance sheet marked as  investment, rather than on the\n  income statement as the expenditure.</dd>\n</dl>\n<p>Typically used for new projects. </p>\n<p>CapEx is not <em>Operating Expenses</em> (OpEx), and should not be treated as such.\n OpEx are short term expenses that keep the business running.\n  OpEx can actually be deducted from the company's taxes in the year it occurred.</p>\n<p>What the CapEx can tell you is how much a company is investing in new or existing assets, for growing or maintaining\n the company.</p>\n<h3>Task</h3>\n<p>Try to answer the following questions in order to check your knowledge.\n If you have trouble answering the question, you can check the answer below.</p>\n<p><strong>Which industries use a similar consumption-based pricing models?</strong>\n<details>\n<summary>Show Solution</summary>\nUtilities companies that provide services like: water, electricity, gas.\n</details></p>\n<p><strong>What is the difference between CapEx and OpEx?</strong>\n<details>\n<summary>Show Solution</summary>\nOpEx is short term expenses to keep the business running, CapEx is the business investment in new or existing\n resources with the goal of expanding the company.\n</details></p>\n<p><strong>How would you describe fault tolerance in one sentence?</strong>\n<details>\n<summary>Show Solution</summary>\nWhat this is referring to is the ability for your application to function even if one or more pieces in any layer fails.\n</details></p>\n<p><strong>Based on what is the price calculated for the consumption based pricing model?</strong>\n<details>\n<summary>Show Solution</summary>\nYou pay for what you use.\n</details></p>"}, {"gitUri": "topics/cloud/modules/cloud-benefits", "overview": "In this module, you will learn about the benefits that are presented through cloud technologies.", "name": "Cloud Benefits", "resourceName": "cloud/cloud-benefits", "content": "<h1>Cloud Benefits</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a><ul>\n<li><a href=\"#scaling-inout\">Scaling in/out</a></li>\n<li><a href=\"#cloud-provider-competencies\">Cloud provider competencies</a></li>\n<li><a href=\"#high-availability\">High availability</a></li>\n<li><a href=\"#agility\">Agility</a></li>\n<li><a href=\"#task\">Task</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>In this module, you will learn about the benefits that are presented through cloud technologies.</p>\n<h3>Scaling in/out</h3>\n<p>Scaling in and out is a reference to your services automatically reacting to the amount of work they need to do and\n if the resources available are not enough to automatically get more, once the workload decreases the resources are\n  released as well.</p>\n<ul>\n<li>Scale Out<ul>\n<li>Cope with spikes in demand (expected and unexpected)</li>\n<li>Scale out from zero, for batch processing</li>\n</ul>\n</li>\n<li>Scale in<ul>\n<li>In response to lower demand</li>\n<li>Automatically based on time of day (peak hours)</li>\n<li>Lower costs\nIn the picture below we can see how there is always just a bit more computational power than the demand requires.\n Also based on the amount of users coming to the service there is an increase in the resources required, once the peak\n time is over then the resources are released.\n<img alt=\"Fork &gt;\" src=\"https://imgur.com/uvwqYKg.png\" /></li>\n</ul>\n</li>\n</ul>\n<h3>Cloud provider competencies</h3>\n<p>Another major benefit is allowing customers to take advantage of the competencies of the cloud service provider. \n* Operating a Data centre is complex and many costs and issues need to be considered:\n    * Security, certifications, audits\n    * Hardware specifications, warranties, installation, disposal\n    * Operating Systems and platform licenses\n    * Network configuration and security\n    * Software has to be self managed</p>\n<p>If you were to host your own server, depending on how powerful you will be making it, there are all the previously\n mentioned costs involved to think of before doing so, as you might be spending thousands of pounds before you will\n  be able to get your server working.</p>\n<h3>High availability</h3>\n<p>Running an application in a variety of physical locations was previous so expensive that only the largest\n organisation could really consider it, and usually only for the most critical of functionality.\n  With the cloud, the idea of High Availability is essentially free:\n* Same cost to deploy to multiple data centres\n* Fewer single points of failure\n* Lower latency, high availability</p>\n<p>A good example of high availability would be a game server.\n When you play online games you usually choose the server that is as close to you as possible, as this reduces the\n  latency and makes it better for you to play. Similarly, if a company has a web application which is generating\n   revenue for it, you would like to deploy it closer to where your clients are to make the user experience better\n    with the hope of attracting more customers with your provided service.</p>\n<h3>Agility</h3>\n<p>Using the cloud tends to increase agility.\n We\u2019ll see many case studies, later on in this course, where faster time-to-market was one of the major benefits of an\n organisation\u2019s move to the cloud.\n  Faster provisioning for (e.g.) new projects.\n   Faster introduction of new services:\n* In DevOps for example; agile creation, testing and deploying of services\n* Continuous Delivery/Deployment</p>\n<h3>Task</h3>\n<p>Watch the video below about the types of scaling.</p>\n<p><a href=\"https://www.youtube.com/watch?v=RMThQbolgZs\"><img alt=\"Cloud scaling types\" src=\"https://img.youtube.com/vi/RMThQbolgZs/0.jpg\" /></a></p>"}]}, {"gitUri": "topics/git", "overview": "Git is a distributed version-control system for tracking changes in source code during software development.", "name": "Git", "resourceName": "git", "modules": [{"gitUri": "topics/git/modules/github-project-boards", "overview": "", "name": "GitHub Project Boards", "resourceName": "git/github-project-boards", "content": "<h1>GitHub Project Boards</h1>\n<!--Props\n{\n    \"prerequisites\":[\n        \"git/pull-requests\"\n    ]\n}\n-->\n\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#project-board-makeup\">Project Board Make-up</a></li>\n<li><a href=\"#cards\">Cards</a></li>\n<li><a href=\"#types-of-project-boards\">Types of Project Boards</a></li>\n<li><a href=\"#templates-for-project-boards\">Templates for Project Boards</a></li>\n<li><a href=\"#creating-a-userowned-project-board\">Creating a User-Owned Project Board</a></li>\n<li><a href=\"#tasks\">Tasks</a></li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>Project boards on <strong>GitHub</strong> help you organize and prioritise your work.</p>\n<p>You can create project boards for specific feature work, comprehensive roadmaps, or even release checklists.</p>\n<p>With project boards, you have the flexibility to create customised workflows that suit your needs.</p>\n<h2>Project Board Make-up</h2>\n<p>Project Boards are made up of <strong>issues</strong>, <strong>pull requests</strong> and <strong>notes</strong>, that are categorised as <strong><em>cards</em></strong> in columns that you have pre-defined. These can be as basic or advanced as you like.</p>\n<p>You can drag and drop, or use keyboard shortcuts, to re-order cards within a column, move cards from column to column, and change the order of columns.</p>\n<h2>Cards</h2>\n<p>Project board cards contain relevant metadata for issues and pull requests.</p>\n<p>You can view and make lightweight edits to issues and pull requests within your project board by clicking on the issue or pull request's title.</p>\n<h2>Types of Project Boards</h2>\n<p>Types of project boards:</p>\n<ul>\n<li>User-owned project boards: can contain issues and pull requests from any personal repository.</li>\n<li>Organisation-wide project boards: can contain issues and pull requests from any repository that belongs to an organisation.</li>\n<li>Repository project boards: scoped to issues and pull requests within a single repository.</li>\n</ul>\n<h2>Templates for Project Boards</h2>\n<p>You can use templates to quickly set up a new project board.</p>\n<p>When you use a template to create a project board, your new board will include columns, as well as cards with tips for using project boards (you can delete these using the <code>...</code> on each card).</p>\n<p>You can also choose a template with automation already configured.</p>\n<p>The options are:</p>\n<ul>\n<li>Basic kanban: Track your tasks with <code>To do</code>, <code>In progress</code>, and <code>Done</code> columns</li>\n<li>Automated kanban: Cards automatically move between <code>To do</code>, <code>In progress</code>, and <code>Done</code> columns</li>\n<li>Automated kanban with review: Cards automatically move between <code>To do</code>, <code>In progress</code>, and <code>Done</code> columns, with additional triggers for pull request review status</li>\n<li>Bug triage: Triage and prioritise bugs with <code>To do</code>, <code>High priority</code>, <code>Low priority</code>, and <code>Closed</code> columns</li>\n</ul>\n<h2>Creating a User-Owned Project Board</h2>\n<p>The first step is to go to GitHub, click <code>Projects</code> and then <code>New Project</code>:</p>\n<p><img alt=\"Start\" src=\"https://i.imgur.com/0Lzpd1t.png?1\" /></p>\n<p>Fill in the form, including name of the board, the template you want to use, and which reository to link to. For this example, we will use a <code>Basic kanban</code> and link it to a repository called <code>scripts</code>:</p>\n<p><img alt=\"form1\" src=\"https://i.imgur.com/b3Yfyjz.png?1\" />\n<img alt=\"form2\" src=\"https://i.imgur.com/esBvG7A.png?1\" /></p>\n<p>The Project Board will now show up under <code>Projects</code>:</p>\n<p><img alt=\"PB\" src=\"https://i.imgur.com/xWOJL1A.png?1\" /></p>\n<p>From here, you can close or edit the board using the <code>...</code>:</p>\n<p><img alt=\"edit\" src=\"https://i.imgur.com/nSOwSHV.png?1\" /></p>\n<p>When you click on the Project Board, you will see the columns defined by the template you chose (in this, we have <code>To Do</code>, <code>In Progress</code> and <code>Done</code>). On the right hand side, you can see the <strong>open issues</strong> and any <strong>Pull Requests</strong> from the linked reository.</p>\n<p>As this is a User-Owned Project Board, we could uncheck the box that says <code>Only show results from linked repositories</code>, and we would be able to see the issues and Pull Requests from all owned repositories:</p>\n<p><img alt=\"add\" src=\"https://i.imgur.com/VzWZ33p.png?1\" /></p>\n<p>From here you can drag cards to the columns, with the <code>To Do</code> column being a good starting point:</p>\n<p><img alt=\"ToDo\" src=\"https://i.imgur.com/fMHh54a.png?1\" /></p>\n<p>The process of moving the cards between columns in this example is manual, but it could all be automated if we wished to do so!</p>\n<p>Project Boards are a great colaborative tool for tracking the different projects that you, or your team, are working on.</p>\n<h2>Tasks</h2>\n<ol>\n<li>Create a new repository, or use an existing one</li>\n<li>Go into your repository, and click <code>issues</code>:</li>\n</ol>\n<p><img alt=\"issues\" src=\"https://i.imgur.com/x8uYejW.png?1\" /></p>\n<ol>\n<li>Submit 3 issues for your repository. For now, these just need a title</li>\n<li>Create a User Owned project board and link your respoitory to it</li>\n<li>Add the issues you made to the <code>To Do</code> column</li>\n<li>Create a Repository scoped project board for your repository and add the issues you submitted to the <code>To Do</code> column.</li>\n</ol>\n<p>You can do lots with GitHub Project Boards and it is a very broad topic. Make sure to experiment with different templates and also with automating your boards!</p>"}, {"prerequisites": ["git/pull-requests"], "gitUri": "topics/git/modules/github-reviews", "overview": "", "name": "GitHub Reviews", "resourceName": "git/github-reviews", "content": "<h1>GitHub Reviews</h1>\n<!--PROPS\n{\n    \"prerequisites\":[\n        \"git/pull-requests\"\n    ]\n}\n-->\n\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#requesting-a-review\">Requesting a Review</a></li>\n<li><a href=\"#reviewing-a-pr\">Reviewing a PR</a><ul>\n<li><a href=\"#making-comments\">Making Comments</a><ul>\n<li><a href=\"#making-a-suggestion-in-your-comment\">Making a Suggestion in Your Comment</a></li>\n</ul>\n</li>\n<li><a href=\"#editing-and-deleting-comments\">Editing and Deleting Comments</a></li>\n<li><a href=\"#keeping-track-of-reviewed-files\">Keeping Track of Reviewed Files</a></li>\n<li><a href=\"#finishing-the-review\">Finishing the Review</a></li>\n</ul>\n</li>\n<li><a href=\"#good-practice\">Good Practice</a></li>\n<li><a href=\"#tasks\">Tasks</a></li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>When submitting a Pull Request (PR) on GitHub (or most Git Providers), you can request a review to take place.</p>\n<p>In the review, other developers and/or members of your team can propose/request changes, ask for clarity in certain areas, discuss certain files, and eventually (hopefully!) approve the PR.</p>\n<p>Once the PR has been approved, it is then able to be merged to another branch, usually <code>develop</code> or <code>master</code>.</p>\n<h2>Requesting a Review</h2>\n<p>You request a review when submitting a PR. All you need to do is use the <code>Reviewers</code> section on the right hand side:</p>\n<p><img alt=\"PR\" src=\"https://i.imgur.com/7WOX06T.png?1\" /></p>\n<p>This will request a review from the person you choose from the dropdown.\nPlease note that the person you would like to review your PR must be a collaborator on the GitHub project.</p>\n<h2>Reviewing a PR</h2>\n<p>If someone has requested a review from you, this will show up in the <code>Pull Requests</code> section, under the repository on GitHub:</p>\n<p><img alt=\"PR1\" src=\"https://i.imgur.com/r1bU4Su.png?1\" /></p>\n<p>Once you have clicked on the correct PR, you will see that your review has been requested. You can click the <code>Add your review</code> button to start:</p>\n<p><img alt=\"Review\" src=\"https://i.imgur.com/8hIAoyo.png?1\" /></p>\n<h3>Making Comments</h3>\n<p>If you want to make a comment on a line in a file, you just use the blue <code>+</code> sign on the left hand side (it will appear as you hover over the <code>+</code> sign):</p>\n<p><img alt=\"Plus\" src=\"https://i.imgur.com/QRqqWZX.png?1\" /></p>\n<h4>Making a Suggestion in Your Comment</h4>\n<p>In the popup box, you can make a general comment if you wish or you can use the highlighted button to insert a suggestion:</p>\n<p><img alt=\"Suggestion\" src=\"https://i.imgur.com/CkGL6e7.png?1\" /></p>\n<p>This will paste the line you are commenting on into the comment box, so you can explicitly state any changes you think would be beneficial.</p>\n<p>The first time you do this, you will have the option to click on <code>Start review</code>, which will begin tracking any changes you make (including the one you just made).</p>\n<p>From then on, when you make a comment/suggestion, the <code>Start review</code> button will be replaced with a button saying <code>Add Review Comment</code>:</p>\n<p><img alt=\"ReviewStart\" src=\"https://i.imgur.com/Znn9hPA.png?1\" /></p>\n<h3>Editing and Deleting Comments</h3>\n<p>You can edit or delete any comments or suggestions you make:</p>\n<p><img alt=\"Edit\" src=\"https://i.imgur.com/XWQIBWD.png?1\" /></p>\n<h3>Keeping Track of Reviewed Files</h3>\n<p>And, following good practice, you should check <code>viewed</code> when you are done reviewing a file:</p>\n<p><img alt=\"Checked\" src=\"https://i.imgur.com/fV8LJsU.png?1\" /></p>\n<h3>Finishing the Review</h3>\n<p>When you have viewed all files, you can click on <code>Finish your review</code>:</p>\n<p><img alt=\"Finish\" src=\"https://i.imgur.com/LkomHRf.png?1\" /></p>\n<p>This will bring up a comment box where you can choose to:</p>\n<ul>\n<li>Make a comment without approval - this is usually asking for clarity around something</li>\n<li>Approve the review - the changes can then be merged into <code>develop</code> or <code>master</code></li>\n<li>Request changes - this stops a merge from happening before the changes you've requested have been made</li>\n</ul>\n<p>Once you have made your choice, you can go ahead and click <code>Submit review</code>, which will finish the review process and notify the person who requested the review that the review has been completed:</p>\n<p><img alt=\"Complete\" src=\"https://i.imgur.com/NbuxasH.png?1\" /></p>\n<h2>Good Practice</h2>\n<p>It is always good practice to not only look over any files in a review, but also to <strong>test</strong> any code in there.</p>\n<p>If there is code in the file, try to run it on your machine and make sure that:</p>\n<ul>\n<li>It runs correctly</li>\n<li>It follows best practices</li>\n<li>It is efficient</li>\n<li>Any instructions given are clear.</li>\n</ul>\n<h2>Tasks</h2>\n<p>NB. This task works much better with somebody else. If you really want to do it individually, you will need to make another GitHub account...</p>\n<ol>\n<li>Create a Pull Request, similar to how you will have done in the <code>Pull Requests</code> module, to merge a feature change from a <code>feature</code> branch into the <code>master</code> branch (ideally, you will make something that requires changing - for example, some broken code)</li>\n<li>Add a Reviewer to the PR</li>\n<li>Have the other person/other account do the same thing on their GitHub (requesting a review from you)</li>\n<li>Start the review, making sure to test the new feature(s)</li>\n<li>Make some comments for the other person/account</li>\n<li>Either approve the review, or request changes</li>\n<li>Complete the review</li>\n<li>Complete the merge once your own PR has ben reviewed and approved by the other person/account</li>\n</ol>"}, {"prerequisites": ["git/branching"], "gitUri": "topics/git/modules/reverting", "overview": "", "name": "Reverting", "resourceName": "git/reverting", "content": "<h1>Reverting</h1>\n<!--PROPS\n{\n    \"prerequisites\":[\n        \"git/branching\"\n    ]\n}\n-->\n\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#reviewing-the-history-of-a-repository\">Reviewing the history of a repository</a></li>\n<li><a href=\"#reverting-to-a-previous-commit-with-revert\">Reverting to a previous commit with revert</a></li>\n</ul>\n<!--TOC_END-->\n\n<h2>Reviewing the history of a repository</h2>\n<p>The best way to view commit history is by using the following command:</p>\n<pre><code class=\"bash\">git log\n</code></pre>\n\n<p>This command will show you the history of all commits for the current branch, with the output including: date, commit message and the SHA-1 identifying hash.</p>\n<p>There are also additional flags that make this command easier to use, such as:</p>\n<pre><code class=\"bash\">git log --oneline\n</code></pre>\n\n<p>Using <code>--oneline</code> flag simplifies the output into one line per commit.</p>\n<pre><code class=\"bash\">git log --branches=*\n</code></pre>\n\n<p>By using the <code>--branches=*</code> flag, we are making Git return the history of all commits for all the branches in that repository.</p>\n<p>To get the data for a specific branch, the log command would need to be used like this:</p>\n<pre><code class=\"bash\"># git log [BRANCH_NAME]\ngit log master\n</code></pre>\n\n<h2>Reverting to a previous commit with revert</h2>\n<p>Let's assume that your <code>git log --oneline</code> looks similar to this:</p>\n<pre><code class=\"text\"> 875f31e (HEAD -&gt; master) fourth commit\n 483856a third commit\n 2dd011d second commit\n bcabb84 first commit\n ```\n\nIf we execute:\n\n`git revert HEAD`\n\nGit will create a new commit, which will do the opposite of the previous commit (for example, if you added a piece of code you didn't need, the revert would create a commit deleting this piece of code). You can also use revert to go back to a specific SHA-1 (`483856a` for example).\n\nThe history will still contain the fourth commit, but it's changes will be undone. Using `revert` allows us to use the same branch and is considered the better solution for reverting.\n\n## Reverting with reset\n\nInstead of using `git revert` in the situation above, we could have used:\n\n`git reset --hard 483856a`\n\nThis command will return the state to the selected commit (`483856a third commit`).\n\nThe difference between this and `git revert` is that now the Git history will no longer contain the fourth commit, and work would continue as if the `fourth commit` never happened.\n\nHowever, not having the commit reflected in the commit history can cause complications when working with a shared remote repository.\n\nIf the reset happened to a commit that is already shared with others, and we tried to push some changes afterwards,\nGit would throw an error; this is because it would think that our local Git history isn't up to date. In these scenarios, it's more appropriate to use the `revert` strategy.\n\n### Using Revert to go Back to the Latest Commit\nIf you have made a lot of changes and just want to back to the latest commit that was made then you can use `reset` without specifying a SHA1:\n\n```bash\ngit reset --hard\n</code></pre>\n\n<h2>Tasks</h2>\n<ol>\n<li>Create a folder called \"tmp\"</li>\n<li>Initialise the folder as a git repository</li>\n<li>Create a new file called <code>test.txt</code></li>\n<li>Stage the file and commit, with an explicit commit message</li>\n<li>Repeat the previous two steps (using a different file name each time) until you have done 5 commits</li>\n<li>Now check the git log history for the branch you are on (try out the additional flags for viewing the git log history)</li>\n<li>Use the <code>git revert HEAD</code> command to 'undo' the last commit you did</li>\n<li>Use the <code>ls</code> command to see what happened</li>\n<li>Use the <code>reset</code> command to go back to your first commit</li>\n<li>Use the <code>ls</code> command to see what happened</li>\n<li>Check the history for the branch you're working on.</li>\n</ol>"}, {"gitUri": "topics/git/modules/pull-requests", "overview": "Pull requests let you tell others about changes you've pushed to a GitHub repository.  ", "name": "Pull Requests", "resourceName": "git/pull-requests", "content": "<h1>Pull Requests</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#collaborative-tool\">Collaborative Tool</a></li>\n<li><a href=\"#creating-a-pull-request\">Creating a Pull Request</a><ul>\n<li><a href=\"#1-pr-from-a-branch-within-a-repository\">1) PR From a Branch Within a Repository</a><ul>\n<li><a href=\"#create-a-feature-branch-and-push-it-to-vcs\">Create a feature branch and push it to VCS</a></li>\n<li><a href=\"#create-a-pull-request\">Create a Pull Request</a></li>\n</ul>\n</li>\n<li><a href=\"#2-pr-from-a-forked-repository\">2) PR from a Forked Repository</a><ul>\n<li><a href=\"#create-a-pull-request-1\">Create a Pull Request</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href=\"#closing-a-pull-request\">Closing a Pull Request</a></li>\n<li><a href=\"#after-a-pull-request\">After a Pull Request</a></li>\n<li><a href=\"#tasks\">Tasks</a></li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>Pull requests let you tell others about changes you've pushed to a GitHub repository.  </p>\n<p>Once a pull request is sent, interested parties can review the set of changes, discuss potential modifications, and even push follow-up commits if necessary.</p>\n<h2>Collaborative Tool</h2>\n<p>Pull Requests are commonly used by teams and organisations collaborating using the <strong>Shared Repository Model</strong>.</p>\n<p>This is where everyone shares a single repository, and seperate (topic) branches are used to develop features and isolate changes.</p>\n<p>Many open-source projects on Github use pull requests to manage changes from contributors, as they are useful in providing a way to notify project maintainers about any changes made.</p>\n<p>Once the project maintainer has been notified of a change via a pull requests, it opens the door for code review and general discussion about a set of changes.\nThis is really great, as it can be done before any changes are merged into the master branch.</p>\n<h2>Creating a Pull Request</h2>\n<p>There are 2 main flows when dealing with pull requests:</p>\n<h3>1) PR From a Branch Within a Repository</h3>\n<h4>Create a feature branch and push it to VCS</h4>\n<ol>\n<li>Clone a repository down using <code>git clone [URL to repository]</code> and <code>cd</code> into it</li>\n<li>Create and switch to a new (feature) branch using <code>git checkout -b [new branch name]</code></li>\n<li>Make changes on your feature branch, and then use <code>git add</code> and <code>git commit</code> to stage your changes. You will need to configure your VCS email and username at this point, using <code>git config</code> (if you haven't already) </li>\n<li>Push the feature branch up to git using <code>git push origin [new branch name]</code></li>\n<li>You new branch should now be reflected in your VCS</li>\n</ol>\n<h4>Create a Pull Request</h4>\n<p>This is done on your VCS GUI (in this example, we are using GitHub):</p>\n<ol>\n<li>Go to the repository you're working with and click on the 'Compare and pull request' button:</li>\n</ol>\n<p><img alt=\"\" src=\"https://i.imgur.com/4C9qMiD.png?1\" /></p>\n<ol>\n<li>You will need to choose which branch you want the changes to eventualy be implemented on (<code>base</code>), and which branch the proposed changes are currently on (<code>compare</code>):</li>\n</ol>\n<p><img alt=\"\" src=\"https://i.imgur.com/lWX58HA.png?1\" /></p>\n<ol>\n<li>At this point, you can give your pull request a title and add some comments, for context:</li>\n</ol>\n<p><img alt=\"\" src=\"https://i.imgur.com/geCW0mU.png?1\" /></p>\n<ol>\n<li>You can configure additional options on the right hand side, such as assigning a reviewer, adding a label, etc:</li>\n</ol>\n<p><img alt=\"\" src=\"https://i.imgur.com/i0zyMAG.png?2\" /></p>\n<ol>\n<li>Click 'Create pull request':</li>\n</ol>\n<p><img alt=\"\" src=\"https://i.imgur.com/xwRCTyk.png?3\" /></p>\n<h3>2) PR from a Forked Repository</h3>\n<h4>Create a Pull Request</h4>\n<p>This is also done on your VCS GUI:</p>\n<ol>\n<li>Ensure you have a forked repository, and have made some changes to it</li>\n<li>Navigate to the repository from which you created your fork</li>\n<li>Click on 'New pull request':</li>\n</ol>\n<p><img alt=\"\" src=\"https://help.github.com/assets/images/help/pull_requests/pull-request-start-review-button.png\" /></p>\n<ol>\n<li>Amend your <code>base</code> and <code>compare</code> to reflect to correct branches</li>\n<li>Click on 'compare accross forks':</li>\n</ol>\n<p><img alt=\"\" src=\"https://help.github.com/assets/images/help/pull_requests/compare-across-forks-link.png\" /></p>\n<ol>\n<li>Confirm that the base fork is the repository you'd like to merge changes into. Use the <code>base</code> drop-down menu to select the branch of the repository you'd like to merge changes into:</li>\n</ol>\n<p><img alt=\"\" src=\"https://help.github.com/assets/images/help/pull_requests/choose-base-fork-and-branch.png\" /></p>\n<ol>\n<li>Use the head fork drop-down menu to select your forked repository, then use the compare branch drop-down menu to select the branch you made your changes in:</li>\n</ol>\n<p><img alt=\"\" src=\"https://help.github.com/assets/images/help/pull_requests/choose-head-fork-compare-branch.png\" /></p>\n<ol>\n<li>Insert a title and description for your pull request</li>\n<li>Configure any other options you want on the right hand side</li>\n<li>Click 'Create Pull Request'</li>\n</ol>\n<h2>Closing a Pull Request</h2>\n<p>You can simply click on the \"Close\" button on the pull request page to close it:</p>\n<p><img alt=\"\" src=\"https://i.imgur.com/fsFyzqL.png?1\" /></p>\n<p>You will be given the option to delete the branch directly at this point, should you wish to do so. </p>\n<h2>After a Pull Request</h2>\n<p>Once a pull request has been opened, it can be reviewed by other collaborators and merged into the base branch you dictated earlier.</p>\n<h2>Tasks</h2>\n<ul>\n<li>Try to create a new feature branch from an existing GitHub project (or create a new project)</li>\n<li>Create a pull request to have the new feature merged into the project</li>\n<li>Fork a repository from GitHub - this can be any repository you feel like</li>\n<li>Make some changes in the forked repository</li>\n<li>Create a pull request to have your feature merged into the original project</li>\n</ul>"}, {"estTime": 10, "gitUri": "topics/git/modules/cloning", "overview": "`git clone` allows the cloning of a repository to a newly created directory. Additionally, the command creates remote", "name": "Cloning", "resourceName": "git/cloning", "content": "<!--PROPS\n{\n    \"estTime\": 10\n}\n-->\n\n<h1>Cloning</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a><ul>\n<li><a href=\"#cloning-a-repository\">Cloning a repository</a></li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#cloning-a-repository-1\">Cloning a Repository</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p><code>git clone</code> allows the cloning of a repository to a newly created directory. Additionally, the command creates remote\ntracking branches for the ones in the repository and checks out the initial branch (which becomes the current active branch).</p>\n<p>Once the clone is created, <code>git fetch</code> can be executed, without additional arguments, to get updates for the remote \nbranches. Similarly, a <code>git pull</code>, without arguments, would merge the remote branch into the current branch.</p>\n<h3>Cloning a repository</h3>\n<p>In order to clone a repository, there are a couple of things you need to do first:\n* Install Git on your machine\n* Find the URL of the repository you want to clone</p>\n<p>To get the URL of the repository you want to clone, you need to go to that repository in the VCS you are using (such as GitHub). \nOnce there, you can click on the <em>Clone or Download</em> and copy the URL. </br>\n<img alt=\"Fork &gt;\" src=\"https://imgur.com/hkzKOvt.png\" />\n<img alt=\"Fork &gt;\" src=\"https://imgur.com/hOQZaFu.png\" /></p>\n<p>Open a terminal and navigate to the directory where you want to have the project saved. You can create a directory named\n<em>projects</em> or use an existing one. In the example below, a new directory is created. </br>\n<img alt=\"Fork &gt;\" src=\"https://imgur.com/3b4KMCR.png\" /></p>\n<p>After the cloning has been completed, change to the project directory and run <code>git branch</code> to check that the active branch has been \nchecked out. </br>\n<img alt=\"Fork &gt;\" src=\"https://imgur.com/UEAW1EN.png\" /></p>\n<h2>Tasks</h2>\n<h3>Cloning a Repository</h3>\n<ul>\n<li>Create a new repository<ul>\n<li>Initialise the repository with a README.md file</li>\n</ul>\n</li>\n<li>Clone the repository to the desired location</li>\n<li>Check that an active branch has been checked out</li>\n</ul>"}, {"estTime": 10, "gitUri": "topics/git/modules/forking", "overview": "", "name": "Forking", "resourceName": "git/forking", "content": "<!--PROPS\n{\n    \"estTime\": 10\n}\n-->\n\n<h1>Forking</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#proposing-a-change\">Proposing a change</a></li>\n<li><a href=\"#your-idea\">Your idea</a></li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#forking-a-repository\">Forking a repository</a></li>\n<li><a href=\"#updating-forked-repository-from-original\">Updating forked repository from original</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h1>Overview</h1>\n<p>In layman's terms, forking is creating a copy of an existing repository under your account. </p>\n<p>Forking a repository allows you to freely experiment with the existing code base, without the fear of breaking the project.\nForking also gives you the ability to contribute to a project, by adding additional functionality. </p>\n<h2>Proposing a change</h2>\n<p>Imagine you are using someone's project and you find a bug. Usually, you would raise an issue for this; however, forking means you would be able to attempt a fix yourself. \nThe steps would be:\n1. Fork the repository\n2. Create a new branch\n3. Fix the issue\n4. Submit a pull request to the owner of the original project</p>\n<p>If the owner approves your fix, your work should then be merged into the original repository.</p>\n<h2>Your idea</h2>\n<p>If a project is under public license that allows you to freely use it, you could use the project as a starting point for\nyour own project. For example, if you found a web application that you liked, and it was under the public license,\nyou could fork the project and add any additional functionality. This would then be yours to freely use or distribute.</p>\n<h2>Tasks</h2>\n<h3>Forking a repository</h3>\n<p>You will now: fork a remote repository, configure upstream (to get updates from the original repository) and propose a change to the owner</p>\n<ol>\n<li>Make sure you're logged into your GitHub account</li>\n<li>Click on \"Fork\", in the top right of this page, for the <code>notes</code> project. This will create a copy of the repository under your account <br />\n<img alt=\"Fork &gt;\" src=\"https://imgur.com/X0bNG7K.png\" /></li>\n<li>You will be redirected to your account's version of the repository</li>\n<li>Click on the green \"Clone or download\" button, and copy the URL <br />\n<img alt=\"Fork &gt;\" src=\"https://imgur.com/hkzKOvt.png\" /></li>\n<li>Open a Bash terminal in the location you want to clone your project</li>\n<li>Run the command <code>git clone [URL]</code>, but replace [URL] with the repository URL you copied in the previous step</li>\n<li>Change directory to the project you just cloned</li>\n<li>Run the following command, to confirm that you have cloned the correct repository: <code>git remote -v</code>. You should get a \nsimilar output for <code>fetch</code> and <code>push</code>, but the URL will be pointing to your repository <br />\n<img alt=\"Fork &gt;\" src=\"https://imgur.com/FOASYQ2.png\" /></li>\n</ol>\n<h3>Updating forked repository from original</h3>\n<p>Now you will set up your local project to receive updates from the original repository. This is required, so that when\nthe owner of the original repository adds new functionality, bug fixes etc., you will be able to get these changes as well.</p>\n<ol>\n<li>Open your Bash terminal, in the root directory of your project. You should be able to see that you're on the master \nbranch. Next, you want to execute <code>git remote -v</code> to make sure that the upstream to the original repository is not set up yet.\nYou should see a similar output to this. <br />\n<img alt=\"Fork &gt;\" src=\"https://imgur.com/lqS0EUr.png\" /></li>\n<li>In your browser, go to the original git repository and copy the repository URL. You can do this by clicking on the\ngreen \"Clone or download\" button and copying the URL <br />\n<img alt=\"Fork &gt;\" src=\"https://imgur.com/hkzKOvt.png\" /></li>\n<li>Execute the following command in your Bash terminal, but replace the [URL] with the one you just copied:\n<code>git remote add upstream [URL]</code> </li>\n<li>Next, you want to check that this has worked, which you can do by executing the <code>git remote -v</code> command.\nThe output should look similar to this: <br />\n<img alt=\"Fork &gt;\" src=\"https://imgur.com/KpAfGaP.png\" /></li>\n<li>Now you will pull the changes from the original repository into yours, which you can do by executing the <code>git fetch upstream</code> command in your\nBash terminal. The output will depend on whether there are new changes or not: <br />\n<img alt=\"Fork &gt;\" src=\"https://imgur.com/L7S2JB1.png\" /></li>\n<li>You will want to update the master branch, so we will merge the <em>upstream/master</em> into the <em>local origin/master</em>. You can do this\nby executing the <code>git merge upstream/master</code> command. Keep in mind that there may be merge conflicts that you will\n need to resolve. If you have resolved the merge conflicts, or if there were none, you should <em>push</em> to update your \n <em>origin/master</em> branch. <br />\n<img alt=\"Fork &gt;\" src=\"https://imgur.com/OYejtWC.png\" /></li>\n</ol>"}, {"estTime": 30, "gitUri": "topics/git/modules/merging", "overview": "Joining the history of two or more branches through `git merge` incorporates changes into the current branch. This command is ", "name": "Merging", "resourceName": "git/merging", "content": "<!--PROPS\n{\n    \"estTime\": 30\n}\n-->\n\n<h1>Merging</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a><ul>\n<li><a href=\"#merge-conflicts\">Merge conflicts</a></li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#handling-merge-conflicts\">Handling Merge Conflicts</a><ul>\n<li><a href=\"#initialise-a-repository-for-testing-merge-conflicts\">Initialise a Repository for Testing Merge Conflicts</a></li>\n<li><a href=\"#create-a-branch-with-a-conflict\">Create a Branch with a Conflict</a></li>\n<li><a href=\"#attempt-to-merge-the-new-branch\">Attempt to Merge the New Branch</a></li>\n<li><a href=\"#resolving-the-conflict\">Resolving the Conflict</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>Joining the history of two or more branches through <code>git merge</code> incorporates changes into the current branch. This command is \nused by <code>git pull</code> to incorporate changes from a different repository, as well as to merge changes from one branch into \nanother.</p>\n<p>If we assume that we have a history like this, and the current branch is <strong>master</strong> :</p>\n<pre><code>      E---F---G issue\n     /\nA---B---C---D master\n</code></pre>\n\n<p>Executing <code>git merge issue</code> would add changes E, F and G into master and result in a new commit.\nThis new commit would end up in the following history.</p>\n<pre><code>      E---F---G issue\n     /         \\  \nA---B---C---D---H master\n</code></pre>\n\n<h3>Merge conflicts</h3>\n<p>Merge conflicts happen when more than one person has edited a file, and the line numbers that were edited are the same\n. It can also happen if someone deleted a file that another person was working on.</p>\n<p>This conflict only affects the person performing the merge, and the rest of the team wouldn't be affected by it.</p>\n<p>If a merge conflict happens, <em>Git</em> will automatically halt the merge process and mark the file, or files, that are\n conflicting. It is then up to the developer to resolve them.</p>\n<h2>Tasks</h2>\n<h3>Handling Merge Conflicts</h3>\n<p>You will now go through the steps required to cause a merge conflict.</p>\n<h4>Initialise a Repository for Testing Merge Conflicts</h4>\n<ol>\n<li>Open a terminal</li>\n<li>Create a new directory by executing <code>mkdir git-merge-conflict</code></li>\n<li>Change directory by executing <code>cd git-merge-conflict</code></li>\n<li>Initialise this directory as a git repository by executing <code>git init .</code></li>\n<li>Create a new text file <em>hello.txt</em> in the directory</li>\n<li>Add some text, such as \"hello world\", to the <em>hello.txt</em> file. Save and close the file</li>\n<li>Now you need to make git track changes for the <em>hello.txt</em> file, which can be done by executing the <code>git add\n hello.txt</code> command</li>\n<li>Now you need to create a save point, which is known as a commit. This will have the current state of the *hello.txt file in it. Execute the <code>git commit -m \"initial commit\"</code> command to achieve this </br>\n<img alt=\"Fork &gt;\" src=\"https://imgur.com/cm8Oky3.png\" /></li>\n</ol>\n<h4>Create a Branch with a Conflict</h4>\n<p>Now that you have a repository and a master branch with a file on it, the next step is to create a new branch to\n use to cause the merge conflict.</p>\n<ol>\n<li>Checkout a new branch by executing <code>git checkout -b new-branch</code></li>\n<li>Open the text file <em>hello.txt</em> and add a new line of text to it, such as \"making a change to the file\". Your text\n file should now look like this:</li>\n</ol>\n<pre><code>hello world\nmaking a change to the file\n</code></pre>\n\n<ol>\n<li>Let's ensure Git keeps track of the hello.txt file that we made a change to. This can be done by executing the <code>git add hello.txt</code> command. Now you\n need to commit again, but this time with a message that reflects the change made - <code>git commit -m \"made a change to\n  hello.txt file\"</code>. The change we made will now try to override the changes in master branch, for the text file <em>hello.txt</em>.</li>\n<li>A change to the text file <em>hello.txt</em> is now required before we can cause a merge conflict. Let's go back to\n our <em>master</em> branch, by executing the <code>git checkout master</code> command</li>\n<li>Open the text file <em>hello.txt</em> and add a new line of text to it, such as \"making a bigger change\". Your\n text file on master should now look like this:</li>\n</ol>\n<pre><code>hello world\nmaking a bigger change\n</code></pre>\n\n<p>The <em>hello.txt</em> on the <em>new-branch</em> branch should look like this:</p>\n<pre><code>hello world\nmaking a change to the file\n</code></pre>\n\n<p>Let's commit the change we made to the <em>hello.txt</em> file to the master branch, by executing <code>git add hello.txt</code> followed by\n <code>git commit -m \"modified hello.txt file\"</code>. </br>\n<img alt=\"Fork &gt;\" src=\"https://imgur.com/y6GoKCn.png\" /> </p>\n<h4>Attempt to Merge the New Branch</h4>\n<p>Now, we want to merge changes from the <em>new-branch</em> branch to the <em>master</em> branch. However, Git won't be able to figure out which version of\n the second line to use - it will create a merge conflict, which the developer will be responsible for resolving.\n1. Let's go ahead and actually cause the merge conflict, by executing the <code>git merge new-branch</code> command. You should get an output\n similar to this:</br>\n<img alt=\"Fork &gt;\" src=\"https://imgur.com/yFzxuUD.png\" />\n2. Let's take a look at the contents of the <em>hello.txt</em> file now, which should look similar to this:</p>\n<pre><code>hello world\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\nmaking a bigger change\n=======\nmaking a change to the file\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; new-branch\n</code></pre>\n\n<p>The main thing to recognise is that the first line (<code>hello world</code>) doesn't have a conflict, but there is a conflict between the\n second line of the <em>master</em> and <em>new-branch</em> branches.</p>\n<h4>Resolving the Conflict</h4>\n<p>To resolve the merge conflict, there are a couple of steps needed:\nFirstly, decide which second line to keep out of <code>making a bigger change</code> or <code>making a change to the file</code>. You could also\n choose something entirely different, such as keeping or deleting both lines.\nSecondly, delete the lines <em>Git</em> added, to show where the merge conflict is happening <code>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</code>, <code>=======</code>, <code>&gt;&gt;&gt;&gt;&gt;&gt;&gt; new-branch</code>. \nLet's say you decide to keep the second line that's currently in <em>master</em> branch. After cleaning up the file, it\n should look like this:</p>\n<pre><code>hello world\nmaking a bigger change\n</code></pre>\n\n<p>Next, you need to save the changes made. This can be done by executing the <code>git add hello.txt</code> command, followed by\n the <code>git commit -m \"resolved merge conflict\"</code> command. </br>\n<img alt=\"Fork &gt;\" src=\"https://imgur.com/IsF5LQK.png\" />\nRunning <code>git status</code> should now indicate that there are no longer any conflicts to resolve.</p>"}, {"name": "Basics", "est_time": 15, "gitUri": "topics/git/modules/basics", "overview": "Git is used for tracking changes in source code during software development.", "resourceName": "git/basics", "content": "<!--PROPS\n{\n    \"name\": \"Basics\",\n    \"est_time\": 15\n}\n-->\n\n<h1>Basics</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#basic-workflow\">Basic Workflow</a></li>\n<li><a href=\"#common-commands-and-concepts\">Common Commands and Concepts</a><ul>\n<li><a href=\"#cloning-a-repository-git-clone\">Cloning a Repository (<code>git clone</code>)</a></li>\n<li><a href=\"#staging-a-change-git-add\">Staging a Change (<code>git add</code>)</a></li>\n<li><a href=\"#username-and-email-in-git-config-git-config\">Username and Email in Git Config (<code>git config</code>)</a><ul>\n<li><a href=\"#setting-config-globally\">Setting Config Globally</a></li>\n<li><a href=\"#setting-config-locally\">Setting Config Locally</a></li>\n</ul>\n</li>\n<li><a href=\"#local-repository-status-git-status\">Local Repository Status (<code>git status</code>)</a></li>\n<li><a href=\"#commiting-a-change-git-commit\">Commiting a Change (<code>git commit</code>)</a></li>\n<li><a href=\"#pushing-changes-git-push\">Pushing Changes (<code>git push</code>)</a></li>\n<li><a href=\"#retrieving-remote-changes\">Retrieving Remote Changes</a></li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a></li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>Git is used for tracking changes in source code during software development.\nIt is designed for coordinating work amongst programmers, but it can be used to track changes in any set of files.</p>\n<h2>Basic Workflow</h2>\n<p>The basic workflow for using Git includes staging, committing and pushing changes.\nBefore a change can be committed it must be staged and to apply your changes for everyone else on the team, the changes must be pushed to the remote repository.</p>\n<h2>Common Commands and Concepts</h2>\n<p>As we know, Git is an incredibly popular tool and there are some commands that are likely to be encountered most days when using it in a basic project workflow.</p>\n<h3>Cloning a Repository (<code>git clone</code>)</h3>\n<p>To download a remote repository you can use the <code>git clone</code> command and provide the URL of the remote repository.\nThe clone command is very useful because it configures the local repository for you, the remote repository is automatically configured for when you need to push your new changes to it.</p>\n<pre><code class=\"bash\"># git clone [REPOSITORY_URL]\ngit clone https://github.com/bob-crutchley/vim\n</code></pre>\n\n<h3>Staging a Change (<code>git add</code>)</h3>\n<p>Staging is the step that you must take before commiting a change.\nStaging is a feature in Git that enables the developer to choose what changes are actually going to get committed to the repository when the commit is made. There is a few ways you stage files:</p>\n<pre><code class=\"bash\"># stage all files\ngit add --all\n\n# stage all files (only if you are at the root of your project)\ngit add .\n\n# stage selected files: git add [FILES]\ngit add file_1.txt file_2.txt\ngit add *.txt\n</code></pre>\n\n<h3>Username and Email in Git Config (<code>git config</code>)</h3>\n<p>Before you can commit changes to the repository you need to have your username and email configured.\nThis can either be set in the scope of the repository you downloaded or set globally, so that it does not need to be configured for any other repository that you clone.\nThe information that  you enter will get tied to the commit and this task doesn\u2019t need to be repeated every time you want to make a commit.</p>\n<h4>Setting Config Globally</h4>\n<pre><code class=\"bash\"># git config --global user.name &quot;[USERNAME]&quot;\ngit config --global user.name &quot;bob-crutchley&quot;\n# git config --global user.email &quot;[EMAIL]&quot;\ngit config --global user.email &quot;bob@email.com&quot;\n</code></pre>\n\n<h4>Setting Config Locally</h4>\n<pre><code class=\"bash\"># git config user.name &quot;[USERNAME]&quot;\ngit config user.name &quot;bob-crutchley&quot;\n# git config user.email &quot;[EMAIL]&quot;\ngit config user.email &quot;bob@email.com&quot;\n</code></pre>\n\n<h3>Local Repository Status (<code>git status</code>)</h3>\n<p>Knowing the current state of your local repository is very useful so that you can understand what commands to run.\nFor instance, how can you know what files have been staged and not staged?</p>\n<pre><code class=\"bash\">git status\n</code></pre>\n\n<h3>Commiting a Change (<code>git commit</code>)</h3>\n<p>When you make a commit to a Git repository, you are effectively \u201csaving\u201d the changes that you have staged to the repository.\nUnlike saving files in most other programs, Git also requires a message to be saved against the commit along with some basic information about the user from the Git config shown above.\nWhat you put in this message is important, so that you understand what it is that you changed on that particular commit.\nCommits can be reverted, so it helps when there is a concise message about what was implemented or removed.</p>\n<pre><code class=\"bash\"># git commit -m &quot;[COMMIT_MESSAGE]&quot;\ngit commit -m &quot;initial commit&quot;\n</code></pre>\n\n<h3>Pushing Changes (<code>git push</code>)</h3>\n<p>To apply the changes that you have made in a remote repository you must push them to that remote repository.\nOnly changes that have been committed will be pushed to the remote repository.\nWe can use <code>git push</code> and provide the remote repository (default is origin) and remote branch to push our changes.</p>\n<pre><code class=\"bash\"># git push -u [REMOTE] [REMOTE_BRANCH]\ngit push -u origin master\n</code></pre>\n\n<h3>Retrieving Remote Changes</h3>\n<p>Because Git is a collaborative tool, other people could have made changes to code in the remote repository, these changes will need to be pulled down to avoid conflicts in the code.</p>\n<pre><code class=\"bash\"># git pull [REMOTE] [REMOTE_BRANCH]\ngit pull origin master\n</code></pre>\n\n<h2>Tasks</h2>\n<ul>\n<li>Create a new Git repository</li>\n<li>Clone the repository to your [USER_HOME]/projects/</li>\n<li>Configure the user.name and user.email properties globally</li>\n<li>Add the following files to the repository folder, it doesn\u2019t matter what these files contain<ul>\n<li>file.java</li>\n<li>file.cs</li>\n<li>file1.txt</li>\n<li>File2.txt</li>\n</ul>\n</li>\n<li>Stage the java file and commit it</li>\n<li>Stage all text files and commit them</li>\n<li>Push the changes to your remote repository</li>\n<li>Add a new file called file.py</li>\n<li>Stage all files and commit them</li>\n<li>Push the changes to your remote repository</li>\n</ul>"}, {"prerequisites": ["git/basics"], "gitUri": "topics/git/modules/branching", "overview": "Branching in Git helps us to define workflows that make sure the code that is being delivered is in the best state possible, minimising risks for any errors or crashes.", "name": "Branching", "resourceName": "git/branching", "content": "<h1>Branching</h1>\n<!--PROPS\n{\n    \"prerequisites\":[\n        \"git/basics\"\n    ]\n}\n-->\n\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#git-branching-workflow-example\">Git Branching Workflow Example</a><ul>\n<li><a href=\"#new-application-features\">New Application Features</a></li>\n<li><a href=\"#releases\">Releases</a></li>\n<li><a href=\"#hotfixes\">Hotfixes</a></li>\n</ul>\n</li>\n<li><a href=\"#creating-and-deleting-branches\">Creating and Deleting Branches</a></li>\n<li><a href=\"#tasks\">Tasks</a></li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>Branching in Git helps us to define workflows that make sure the code that is being delivered is in the best state possible, minimising risks for any errors or crashes.</p>\n<p>With Version Control Systems, like Git, we can separate the codebase on to many different branches.</p>\n<p>This feature can be utilised for isolating the development and testing of new features from working code that is running on a production environment.</p>\n<h2>Git Branching Workflow Example</h2>\n<p>This is an example of a workflow using Git with some notes below which explain in more detail the processes.</p>\n<p>The two main branches that exist are the <code>develop</code> and <code>master</code> branches.</p>\n<h3>New Application Features</h3>\n<p>Conventionally, new features are to be created in feature branches from the develop branch, and, once the feature has been developed, the code can be reviewed by a peer in a Pull Request and deployed to a test environment for Integration or User Acceptance Testing.</p>\n<p>If all testing and reviews pass, the Pull Request can be approved and merged into the <code>develop</code> branch.</p>\n<h3>Releases</h3>\n<p>When there is a release approaching, a release candidate branch can be made.</p>\n<p>On this new branch, further testing of all the new features working together can take place, and more candidates can be made on this branch to amend any issues.</p>\n<p>Once testing has passed and the release has been signed off by the individual accountable for releases, the release candidate branch can be merged into master for the release to be deployed to a production environment.</p>\n<p>Once merged into the master branch, the code can be tagged or marked as a release on the Git service that you are using.</p>\n<p>Changes must also be merged back into the develop branch, so that any changes that were made to the release candidate will also be included in future releases.</p>\n<h3>Hotfixes</h3>\n<p>Preventing hotfixes is one of the main reasons for designing a workflow such as the one below.</p>\n<p>Hotfixes should be prevented where possible, but, as this is the wonderful world of IT we work in, they could still happen at some point.</p>\n<p>A hotfix can be conducted by creating a hotfix branch from the master branch and applying the changes on that branch; before merging back into the master branch all the changes should, of course, be tested and reviewed to avoid even more hotfixes!</p>\n<p>Once merged into the master branch, the changes must also be merged back into the develop branch; this will keep any important changes the hotfix made, and the code in the master branch should be tagged.</p>\n<p><img alt=\"Workflow\" src=\"https://i.imgur.com/TTzISff.png\" /></p>\n<h2>Creating and Deleting Branches</h2>\n<p>You can see all the current branches in your repository using:</p>\n<pre><code class=\"bash\">git branch\n</code></pre>\n\n<p>To create a new branch, the command is:</p>\n<pre><code class=\"bash\"># git branch [NEW_BRANCH_NAME]\ngit branch develop\n</code></pre>\n\n<p>This will create a new branch from whichever branch you are currently on (so this new branch will branch from <code>develop</code> if you run the command whilst on that branch).</p>\n<p>If you want to work on a new branch straight away, you can create a branch and <code>checkout</code> to it at the same time:</p>\n<pre><code class=\"bash\"># git checkout -b [NEW_BRANCH_NAME]\ngit checkout -b develop\n</code></pre>\n\n<p>When you have finished working on your branch, and your code has been merged to <code>master</code>, it is good practice to delete the branch:</p>\n<pre><code class=\"bash\"># git branch -d [BRANCH_NAME]\ngit branch -d feature-123\n</code></pre>\n\n<p>You will also need to do this on your Git Service, which you're likely using (such as GitHub). This is usually done when closing a Pull Request.</p>\n<p>If you aren't closing a Pull Request and find yourself needing to close a branch, you can use the following command to delete a branch on your remote repository (again, likely on GitHub):</p>\n<pre><code class=\"bash\"># git push --delete origin [BRANCH_NAME]\ngit push --delete origin feature-123\n</code></pre>\n\n<h2>Tasks</h2>\n<ol>\n<li>Run the command <code>git clone https://github.com/jordan-grindrod/scripts</code></li>\n<li>Run the command <code>cd ./scripts</code></li>\n<li>See which branches are currently configured for that repository</li>\n<li>Create a new branch called <code>develop</code></li>\n<li>From <code>develop</code>, checkout to a new branch called <code>issue-1</code></li>\n<li>Delete the <code>issue-1</code> and <code>develop</code> branches</li>\n</ol>"}]}, {"gitUri": "topics/traceroute", "overview": "In computing, `traceroute` and `tracert` are computer network diagnostic commands for displaying the route (path) and measuring transit delays of packets across an Internet Protocol (IP) network.", "name": "Traceroute", "resourceName": "traceroute", "modules": [{"estTime": 10, "gitUri": "topics/traceroute/modules/introduction", "overview": "In computing, `traceroute` and `tracert` are computer network diagnostic commands for displaying the route (path) and measuring transit delays of packets across an Internet Protocol (IP) network.", "name": "Introduction", "resourceName": "traceroute/introduction", "content": "<!--PROPS\n{\n    \"estTime\": 10\n}\n-->\n\n<h1>Introduction</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#traceroute-output\">Traceroute Output</a><ul>\n<li><a href=\"#example-output\">Example Output</a></li>\n<li><a href=\"#output-meaning\">Output Meaning</a><ul>\n<li><a href=\"#hop-number\">Hop Number</a></li>\n<li><a href=\"#name--ip-address\">Name &amp; IP Address</a></li>\n<li><a href=\"#rtt-columns\">RTT Columns</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#installation\">Installation</a><ul>\n<li><a href=\"#ubuntudebian\">Ubuntu/Debian</a></li>\n<li><a href=\"#centosrhel\">CentOS/RHEL</a></li>\n</ul>\n</li>\n<li><a href=\"#try-it-out\">Try it Out</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>In computing, <code>traceroute</code> and <code>tracert</code> are computer network diagnostic commands for displaying the route (path) and measuring transit delays of packets across an Internet Protocol (IP) network.</p>\n<p>Here's an example of a path for going to <code>google.co.uk</code> from a computer in London:\n<img alt=\"Traceroute Map\" src=\"https://i.imgur.com/cE9UPCB.png\" /></p>\n<p>The history of the route is recorded as the round-trip times of the packets received from each successive host (remote node) in the route (path); the sum of the mean times in each hop is a measure of the total time spent to establish the connection.\nTraceroute proceeds unless all (three) sent packets are lost more than twice. If this happens, the connection is lost and the route cannot be evaluated.</p>\n<h2>Traceroute Output</h2>\n<h3>Example Output</h3>\n<p>Below is an example output from a basic <code>traceroute</code> command to <code>google.com</code>:</p>\n<pre><code class=\"text\">traceroute to google.com (172.217.169.78), 30 hops max, 60 byte packets\n 1  192.168.0.254 (192.168.0.254)  3.141 ms  3.123 ms  3.129 ms\n 2  172.16.25.2 (172.16.25.2)  3.753 ms  3.750 ms  3.738 ms\n 3  no-reverse-dns.metronet-uk.com (164.39.75.105)  6.859 ms  6.861 ms  6.857 ms\n 4  no-reverse-dns.metronet-uk.com (164.39.85.25)  6.830 ms  6.816 ms  6.863 ms\n 5  no-reverse-dns.metronet-uk.com (85.199.237.157)  6.867 ms  6.864 ms  6.876 ms\n 6  no-reverse-dns.metronet-uk.com (51.179.187.200)  6.801 ms  5.118 ms  4.975 ms\n 7  no-reverse-dns.metronet-uk.com (85.199.224.241)  4.932 ms * *\n 8  te1-5.man-tck1gw.metronet-uk.com (85.199.239.165)  3.002 ms  3.098 ms  3.080 ms\n 9  te1-4.man-tcw1gw.metronet-uk.com (77.75.191.34)  11.700 ms  11.861 ms  11.847 ms\n10  te0-0-0-0.man-tcw2br.metronet-uk.com (164.39.85.50)  3.472 ms  3.451 ms  3.421 ms\n11  po-5-11.bb1.man2.uk.m247.com (148.252.210.96)  44.219 ms  44.156 ms  43.243 ms\n12  te-9-2-0.core-dc2.man4.uk.m247.com (77.243.185.0)  29.972 ms  30.308 ms  28.651 ms\n13  xe-2-2-2-0.core1.man4.uk.m247.com (83.97.21.71)  3.728 ms xe-2-3-0-0.core1.man4.uk.m247.com (83.97.21.150)  3.667 ms xe-1-0-3-0.core1.man4.uk.m247.com (77.243.176.46)  3.090 ms\n14  te-9-3-0.bb1.lon1.uk.m247.com (212.103.51.17)  8.133 ms te-9-6-0.bb1.lon1.uk.m247.com (212.103.51.19)  9.081 ms te-9-8-0.bb1.lon1.uk.m247.com (77.243.176.247)  8.704 ms\n15  google1.lonap.net (5.57.80.136)  8.735 ms  8.597 ms  9.454 ms\n16  74.125.242.97 (74.125.242.97)  11.616 ms 74.125.242.65 (74.125.242.65)  10.939 ms  10.902 ms\n17  172.253.66.101 (172.253.66.101)  10.034 ms 172.253.66.99 (172.253.66.99)  10.873 ms 172.253.66.101 (172.253.66.101)  10.751 ms\n18  lhr48s09-in-f14.1e100.net (172.217.169.78)  9.355 ms  9.113 ms  9.563 ms\n</code></pre>\n\n<h3>Output Meaning</h3>\n<p>Below is a table showing the meaning of the different columns of the <code>traceroute</code> commands output.\nThe data in the table is taken from the first 3 hops of the example above.</p>\n<table>\n<thead>\n<tr>\n<th>Hop Number</th>\n<th>Name &amp; IP Address</th>\n<th>RTT1</th>\n<th>RTT2</th>\n<th>RTT3</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>192.168.0.254 (192.168.0.254)</td>\n<td>3.141 ms</td>\n<td>3.123 ms</td>\n<td>3.129 ms</td>\n</tr>\n<tr>\n<td>2</td>\n<td>172.16.25.2 (172.16.25.2)</td>\n<td>3.753 ms</td>\n<td>3.750 ms</td>\n<td>3.738 ms</td>\n</tr>\n<tr>\n<td>3</td>\n<td>no-reverse-dns.metronet-uk.com (164.39.75.105)</td>\n<td>6.859 ms</td>\n<td>6.861 ms</td>\n<td>6.857 ms</td>\n</tr>\n</tbody>\n</table>\n<h4>Hop Number</h4>\n<p>This is the first column and is simply the number of the hop along the route. In this case, it is the first hop.</p>\n<h4>Name &amp; IP Address</h4>\n<p>This column has the IP address of the router. If it is available, the domain name will also be listed.</p>\n<h4>RTT Columns</h4>\n<p>The three <code>RTT</code> columns display the round trip time (RTT) for your packet to reach that point and return to your computer.\nThis is listed in milliseconds.\nThere are three columns because the traceroute sends three separate signal packets.\nThis is to display consistency, or a lack thereof, in the route.</p>\n<h2>Tasks</h2>\n<h3>Installation</h3>\n<p>Traceroute is a tool that is typically used on Linux systems.\nWindows uses a very similar tool, called <code>tracert</code>, that comes pre-installed.</p>\n<h4>Ubuntu/Debian</h4>\n<pre><code class=\"bash\">sudo apt install -y traceroute\n</code></pre>\n\n<h4>CentOS/RHEL</h4>\n<pre><code class=\"bash\">sudo yum install -y traceroute\n</code></pre>\n\n<h3>Try it Out</h3>\n<p>Lets see what hops are made just by making a request to <code>google.com</code>:</p>\n<pre><code class=\"bash\">traceroute google.com\n</code></pre>\n\n<p>You should see an output similar to this:</p>\n<pre><code class=\"text\">traceroute to google.com (172.217.169.78), 30 hops max, 60 byte packets\n 1  192.168.0.254 (192.168.0.254)  3.141 ms  3.123 ms  3.129 ms\n 2  172.16.25.2 (172.16.25.2)  3.753 ms  3.750 ms  3.738 ms\n 3  no-reverse-dns.metronet-uk.com (164.39.75.105)  6.859 ms  6.861 ms  6.857 ms\n 4  no-reverse-dns.metronet-uk.com (164.39.85.25)  6.830 ms  6.816 ms  6.863 ms\n 5  no-reverse-dns.metronet-uk.com (85.199.237.157)  6.867 ms  6.864 ms  6.876 ms\n 6  no-reverse-dns.metronet-uk.com (51.179.187.200)  6.801 ms  5.118 ms  4.975 ms\n 7  no-reverse-dns.metronet-uk.com (85.199.224.241)  4.932 ms * *\n 8  te1-5.man-tck1gw.metronet-uk.com (85.199.239.165)  3.002 ms  3.098 ms  3.080 ms\n 9  te1-4.man-tcw1gw.metronet-uk.com (77.75.191.34)  11.700 ms  11.861 ms  11.847 ms\n10  te0-0-0-0.man-tcw2br.metronet-uk.com (164.39.85.50)  3.472 ms  3.451 ms  3.421 ms\n11  po-5-11.bb1.man2.uk.m247.com (148.252.210.96)  44.219 ms  44.156 ms  43.243 ms\n12  te-9-2-0.core-dc2.man4.uk.m247.com (77.243.185.0)  29.972 ms  30.308 ms  28.651 ms\n13  xe-2-2-2-0.core1.man4.uk.m247.com (83.97.21.71)  3.728 ms xe-2-3-0-0.core1.man4.uk.m247.com (83.97.21.150)  3.667 ms xe-1-0-3-0.core1.man4.uk.m247.com (77.243.176.46)  3.090 ms\n14  te-9-3-0.bb1.lon1.uk.m247.com (212.103.51.17)  8.133 ms te-9-6-0.bb1.lon1.uk.m247.com (212.103.51.19)  9.081 ms te-9-8-0.bb1.lon1.uk.m247.com (77.243.176.247)  8.704 ms\n15  google1.lonap.net (5.57.80.136)  8.735 ms  8.597 ms  9.454 ms\n16  74.125.242.97 (74.125.242.97)  11.616 ms 74.125.242.65 (74.125.242.65)  10.939 ms  10.902 ms\n17  172.253.66.101 (172.253.66.101)  10.034 ms 172.253.66.99 (172.253.66.99)  10.873 ms 172.253.66.101 (172.253.66.101)  10.751 ms\n18  lhr48s09-in-f14.1e100.net (172.217.169.78)  9.355 ms  9.113 ms  9.563 ms\n</code></pre>"}]}, {"gitUri": "topics/networking", "overview": "A computer network is a digital telecommunications network which allows nodes to share resources.", "name": "Networking", "resourceName": "networking", "modules": [{"estTime": 10, "gitUri": "topics/networking/modules/standards-and-organisations", "overview": "The internet, as a collection of worldwide networks, requires policies, procedures, standards and protocols to make it work.", "name": "Standards and Organisations", "resourceName": "networking/standards-and-organisations", "content": "<!--PROPS\n{\n    \"estTime\": 10\n}\n-->\n\n<h1>Standards and Organisations</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#organisations-involved\">Organisations Involved</a></li>\n<li><a href=\"#tasks\">Tasks</a></li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>The internet, as a collection of worldwide networks, requires policies, procedures, standards and protocols to make it work.\nThe Internet Society (ISOC) was founded in 1992 by <a href=\"https://en.wikipedia.org/wiki/Vint_Cerf\">Vint Cerf</a> and <a href=\"https://en.wikipedia.org/wiki/Bob_Kahn\">Bob Kahn</a> to promote the open development, evolution and use of the internet for the benefit of all people throughout the world.\nThe internet has a unique model of shared global ownership that is dependent upon open standards development, and freely accessible processes for technology and policy development. </p>\n<h2>Organisations Involved</h2>\n<table>\n<thead>\n<tr>\n<th>Organisation</th>\n<th>Roles &amp; Responsibilities</th>\n<th>Website</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>American National Standards Institute (ANSI)</td>\n<td>ANSI represents a number of US standards organizations. Members submit their standards for acceptance. An example is the ANSI standard for representing ASCII characters.</td>\n<td>www.ansi.org</td>\n</tr>\n<tr>\n<td>Electronics Industries Association (EIA)</td>\n<td>EIA are made up by manufacturers in the USA. Responsible for RS232 and similar standards.</td>\n<td>www.eia.org</td>\n</tr>\n<tr>\n<td>Institute of Electrical and Electronic Engineers (IEEE)</td>\n<td>The IEEE (Pronounced Eye-triple-E) is a non- profit, technical professional association of more than 377,000 individual members in 150 countries.</td>\n<td>www.ieee.org</td>\n</tr>\n<tr>\n<td>International Organization for Standardization (ISO)</td>\n<td>A network of national standards institutes from 140 countries working in partnership with international organizations, governments, industry, business and consumer representatives. The ISO have standards covering a wide range of computer related topics.</td>\n<td>www.iso.org</td>\n</tr>\n<tr>\n<td>International Telecommunications Union (ITU) (previously known as the Comite Consultatif International Telephonique et Telegraphique (CCITT)</td>\n<td>The ITU, headquartered in Geneva, Switzerland is an international organization within the United Nations System where governments and the private sector coordinate global telecom networks and services. They are also involved with the allocation of satellite frequencies and orbits.</td>\n<td>www.itu.int</td>\n</tr>\n<tr>\n<td>Internet Assigned Numbers Authority (IANA)</td>\n<td>The global coordination of the DNS Root, IP addressing, and other Internet protocol resources is performed as the Internet Assigned Numbers Authority (IANA) functions.</td>\n<td><a href=\"https://iana.org\">iana.org</a></td>\n</tr>\n<tr>\n<td>Internet Corporation for Assigned Names and Numbers (ICANN)</td>\n<td>The Internet Corporation for Assigned Names and Numbers is a nonprofit organization responsible for coordinating the maintenance and procedures of several databases related to the namespaces and numerical spaces of the Internet, ensuring the network's stable and secure operation.</td>\n<td><a href=\"https://www.icann.org\">www.icann.org</a></td>\n</tr>\n</tbody>\n</table>\n<h2>Tasks</h2>\n<p>Take a look a this YouTube video by Elise Gerich from ICANN explaining IANA functions:</p>\n<p><a href=\"https://www.youtube.com/watch?v=D__mAX-2sXo\"><img alt=\"The IANA Functions in 180 Seconds\" src=\"https://img.youtube.com/vi/D__mAX-2sXo/0.jpg\" /></a></p>"}, {"estTime": 30, "questions": [{"value": "What does MAC stand for?", "answer": "Media Access Control.", "choices": [""]}, {"value": "What is a MAC Address?", "answer": "A unique identifier assigned to a Network Interface Controller (NIC).", "choices": [""]}], "gitUri": "topics/networking/modules/mac-address", "overview": "A Media Access Control (MAC) address of a device is a unique identifier assigned to a Network Interface Controller (NIC).", "name": "MAC Address", "resourceName": "networking/mac-address", "content": "<!--PROPS\n{\n   \"estTime\": 30,\n   \"questions\": [\n        {\n            \"value\": \"What does MAC stand for?\",\n            \"answer\": \"Media Access Control.\",\n            \"choices\": [\"\"]\n        },\n        {\n            \"value\": \"What is a MAC Address?\",\n            \"answer\": \"A unique identifier assigned to a Network Interface Controller (NIC).\",\n            \"choices\": [\"\"]\n        }\n   ]\n}\n-->\n\n<h1>MAC Address</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#relevence--day-to-day-application\">Relevence &amp; Day to Day Application</a><ul>\n<li><a href=\"#public-wifi\">Public Wifi</a></li>\n</ul>\n</li>\n<li><a href=\"#viewing-your-mac-address\">Viewing Your MAC Address</a><ul>\n<li><a href=\"#windows\">Windows</a></li>\n<li><a href=\"#linux\">Linux</a><ul>\n<li><a href=\"#using-ifconfig\">Using ifconfig</a></li>\n<li><a href=\"#using-ip\">Using ip</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href=\"#format\">Format</a><ul>\n<li><a href=\"#hexadecimals\">Hexadecimals</a></li>\n<li><a href=\"#oem--unique-id\">OEM &amp; Unique ID</a></li>\n</ul>\n</li>\n<li><a href=\"#spoofing\">Spoofing</a><ul>\n<li><a href=\"#linux-1\">Linux</a></li>\n<li><a href=\"#windows-1\">Windows</a></li>\n<li><a href=\"#why\">Why?</a></li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#find-out-about-your-current-mac-address\">Find Out About Your Current MAC Address</a></li>\n<li><a href=\"#change-your-mac-address\">Change Your MAC Address</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>A Media Access Control (MAC) address of a device is a unique identifier assigned to a Network Interface Controller (NIC).\nA NIC, is a computer hardware component that connects a computer to a computer network; this often comes in the form of an Ethernet port on the device or a wireless adapter.\nFor communications within a network segment, it is used as a network address for most IEEE 802 network technologies, including Ethernet, Wi-Fi, and Bluetooth.<br />\nMAC addresses are used as physical hardware addresses for devices on a network.\nThese are important because they are unique for every piece of networking hardware.\nThe main usage case is within a low level of networking when delivering frames (packets of data) over Local Area Networks (LAN) to make sure that the data is getting to the correct device.</p>\n<h2>Relevence &amp; Day to Day Application</h2>\n<p>Because MAC addresses are used on such a low level for LAN; any network connection made, be it browsing the internet or making a video call, will end up using MAC addresses at some point for the connection to be established.</p>\n<h3>Public Wifi</h3>\n<p>MAC addresses are there for identifying a device, so this can be utilised for something like public Wifi.\nWhen you try to log into a Wifi network in an Hotel or Coffee shop for example, you will likely be faced with a pay wall.\nAfter purchasing Wifi access, the MAC address of the current device you are using can be stored on their servers, so that any traffic coming from your device will be allowed onto the Internet.</p>\n<h2>Viewing Your MAC Address</h2>\n<h3>Windows</h3>\n<p>On a Windows machine you can use the <code>ipconfig /all</code> command inside a command prompt or PowerShell to see what your MAC address is.\nThe MAC addresse can be found under the <code>Physical Address</code> property:</p>\n<pre><code class=\"text\">Wireless LAN adapter Wi-Fi:\n\n   Connection-specific DNS Suffix  . :\n   Description . . . . . . . . . . . : Intel(R) Dual Band Wireless-AC 7265\n   Physical Address. . . . . . . . . : DC-53-60-BD-C4-64\n   DHCP Enabled. . . . . . . . . . . : Yes\n   Autoconfiguration Enabled . . . . : Yes\n   Link-local IPv6 Address . . . . . : fe80::7194:cbcc:656f:f492%4(Preferred)\n   IPv4 Address. . . . . . . . . . . : 172.17.25.18(Preferred)\n   Subnet Mask . . . . . . . . . . . : 255.255.255.0\n   Lease Obtained. . . . . . . . . . : 28 August 2019 11:03:21\n   Lease Expires . . . . . . . . . . : 29 August 2019 11:03:21\n   Default Gateway . . . . . . . . . : 172.17.25.1\n   DHCP Server . . . . . . . . . . . : 172.17.25.1\n   DHCPv6 IAID . . . . . . . . . . . : 81548128\n   DHCPv6 Client DUID. . . . . . . . : 00-01-00-01-24-33-DD-D2-B8-6B-23-7B-7B-C3\n   DNS Servers . . . . . . . . . . . : 8.8.8.8\n                                       9.9.9.9\n   NetBIOS over Tcpip. . . . . . . . : Enabled\n</code></pre>\n\n<h3>Linux</h3>\n<p>Depending on what tools are installed on your system there are several ways that you can get your MAC address:</p>\n<h4>Using ifconfig</h4>\n<p>Here's an example using <code>ifconfig</code> to find out what your MAC address is, the command used here is <code>ifconfig -a</code>.\nThe MAC address in this exmaple is <code>60:57:18:31:ab:5a</code> shown after the <code>ether</code> property.</p>\n<pre><code class=\"bash\">wlp2s0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500\n        inet 172.17.25.138  netmask 255.255.255.0  broadcast 172.17.25.255\n        inet6 fe80::7eb3:fea9:bb3:ecb9  prefixlen 64  scopeid 0x20&lt;link&gt;\n        ether 60:57:18:31:ab:5a  txqueuelen 1000  (Ethernet)\n        RX packets 499884  bytes 208446448 (208.4 MB)\n        RX errors 0  dropped 1  overruns 0  frame 0\n        TX packets 142416  bytes 28168977 (28.1 MB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n</code></pre>\n\n<h4>Using ip</h4>\n<p>Below is the output from running <code>ip link show</code>.\nThe MAC address in this case is <code>60:57:18:31:ab:5a</code>, under the <code>link/ether</code> property:</p>\n<pre><code class=\"text\">3: wlp2s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP mode DORMANT group default qlen 1000\n    link/ether 60:57:18:31:ab:5a brd ff:ff:ff:ff:ff:ff\n</code></pre>\n\n<h2>Format</h2>\n<h3>Hexadecimals</h3>\n<p>MAC addresses are 6 bytes (48 bits) of data represented as a hexadecimal:</p>\n<pre><code class=\"text\">1C-B7-2C-B9-27-09\n</code></pre>\n\n<h3>OEM &amp; Unique ID</h3>\n<p>The first 3 bytes in a MAC addres is issued to the Original Equipment Manufacturer (OEM) to assign to the device.\nThe last 3 bytes are unique to the device which are created and assigned by the OEM.\nFor example in the MAC address <code>1C-B7-2C-B9-27-09</code>; <code>1C-B7-2C</code> would be the part issued to the OEM to assign and <code>B9-27-09</code> is what was created and assigned by the OEM.</p>\n<h2>Spoofing</h2>\n<p>Although the MAC address for your device is basically hard-coded into the network interface, modern network drivers will typically allow you to change the MAC address temporarily.\nPlease note though that depending on you network adapter and drivers that you are using, this may not work.</p>\n<h3>Linux</h3>\n<p>This is easy enough to do on Linux by turning off the interface, changing the address to what you like and then starting the interface again:</p>\n<pre><code class=\"bash\"># find the interface to change the address of, enp1s0 for example\nip link show\n# bring down the interface\nip link set [INTERFACE] down\n# set the address\nip link set dev [INTERFACE] address [MAC_ADDRESS]\n# bring the interface back up\nip link set dev [INTERFACE] up\n</code></pre>\n\n<p>You can go through the same process to reset your MAC address to its original value, otherwise you can just restart the system.</p>\n<h3>Windows</h3>\n<p>PowerShell is a great tool for modifying your MAC address temporarily.\nBe sure to take note of your current MAC address before changing it, or else you will have to restart your computer to reset it.\nFirst we can find what network adapters are available and then change the MAC address accordingly:</p>\n<pre><code class=\"powershell\"># find available network adapters\nget-netadapter\n# update the network adapter, refferring to it by its Name property\nset-netadapter -Name &quot;[ADAPTER_NAME]&quot; -MacAddress &quot;[MAC_ADDRESS]&quot;\n</code></pre>\n\n<p>To reset your MAC address on Windows to its original value, you can use the same method as above, or by restarting your computer.</p>\n<h3>Why?</h3>\n<p>Changing a devices MAC address can be used for bypassing or \"tricking\" access control in place by disguising itself as another device.\nThis is typically a technique used for malicious purposes but can be used for penetration testing and ensuring your services are robust enough to not be susceptible to this.</p>\n<h2>Tasks</h2>\n<h3>Find Out About Your Current MAC Address</h3>\n<ul>\n<li>Find the MAC address of the current device that you are using, remember you can use <code>ipconfig /all</code> on Windows and <code>ip link show</code> on Linux.</li>\n<li>Use the first 3 bytes of your MAC to find out who manufactured your network interface card (NIC), usually just putting it in a Google search will show you this.</li>\n</ul>\n<h3>Change Your MAC Address</h3>\n<ul>\n<li>Make a note of your current MAC address.</li>\n<li>Change your MAC address to the following: <code>00-10-18-57-1B-0D</code></li>\n<li>Reset your MAC address back to its original value.</li>\n</ul>"}, {"gitUri": "topics/networking/modules/tcp", "overview": "Transmission Control Protocol (TCP) is connection-orientated.", "name": "TCP", "resourceName": "networking/tcp", "content": "<h1>TCP</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#tcp-header-format\">TCP Header Format</a></li>\n<li><a href=\"#tcp-operations\">TCP Operations</a><ul>\n<li><a href=\"#connection-establishment\">Connection Establishment</a></li>\n<li><a href=\"#data-transfer\">Data Transfer</a></li>\n<li><a href=\"#connection-termination-graceful-close\">Connection Termination (Graceful Close)</a></li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#viewing-tcp-packets-with-wireshark\">Viewing TCP Packets with Wireshark</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>Transmission Control Protocol (TCP) is connection-orientated.\nThis means that there is a handshake to ensure that the data has been delivered correctly.\nA logical connection must be established before any transferring of data can begin. TCP uses a 3 way handshake when establishing and terminating a connection, and there is more on this in the TCP operation section.\nThe reliable nature of TCP means that it is used in application level protocols, such as SSH, FTP and almost anything where all of the data must be transferred.</p>\n<h2>TCP Header Format</h2>\n<p>Every TCP header has 10 required fields and an optional 11th field.\nThis many fields are needed in a TCP header, because TCP has quite a few capabilities compared to a protocol such as UDP.</p>\n<ol>\n<li>Source Port \u2013 The port from which the packet was sent from</li>\n<li>Destination Port \u2013 The port of the receiving device</li>\n<li>Sequence Number \u2013 The device sending the packets will use sequence numbers to order groups of messages. For instance, an image file that is being transported over multiple messages will need to be reconstructed at the other end in the correct order.</li>\n<li>Acknowledgement Number \u2013 Both the senders and receivers of the messages will use the acknowledgement numbers field to communicate the sequence numbers of the messages that have either been recently received or expected to be sent.</li>\n<li>Data Offset \u2013 Stores the total size of the header</li>\n<li>Reserved \u2013 These are 3 bits for the reserved field. They are unused and are always set to 0.</li>\n<li>Control Flags \u2013 There are six standard and three extended control flags that are used for managing the data flow - more on this in the TCP operation section.</li>\n<li>Window Size \u2013 A way of regulating how much data can be sent, before requiring an acknowledgement to confirm that the data has been received successfully.</li>\n<li>Checksum \u2013 Generated by the sender. A mathematical technique for the receiver to assure the integrity of the data, and to make sure that it has not been corrupted or tampered with.</li>\n<li>Urgent Pointer \u2013 This value is typically set to zero and ignored; however, it can be used in conjunction with one of the control flags, to require priority in processing.</li>\n<li>Optional Data \u2013 Optional data for TCP allows more features, such as support for special types of acknowledgement and window scaling algorithms</li>\n</ol>\n<p><img alt=\"TCP Header\" src=\"https://lh3.googleusercontent.com/o9ex3p3QMp5ONvsl-rZFnJ7g6K0wdI-CdxgT5qj1Zs-H56gPK3x26p4ijnaxaPn0OcLmBl9MUZkgHzsHNCgtW0YxZ8zB8Pn9APiyNnsfB61HlQq8W3Xicx5pOiXzxRAcHBiXFD0YFa56pr9dJAsyWrgV3otXqjtgomSGOt0gmkGAC7eVnAPmX1cH1WyW3p6nn-lY-UR_WMdkMxyRXaRvr3wBRd5VDnTdSHYU48xHZuAAOmeiIc84zccP2r8axDjPuNIvJ56ge5tOIh3gASN1v5_A9c-N5UAAyjPBuBeFe0obju3hbC0U5tTNNrMBQmgt_brDZzOh2yF3RGYH-9K8Bd0nuJi2ufyv9Unb_bF9MdM-hRTNYPIbSOceSziLGOBwGSyrd1nVtnzDVrlIADcYSg9Lvv4EJePZITkUmrXR3QxKLXU_r69UAj_S3nEBpAKi3KddFxDsuDLN-UCbg0mN5LmhRvnx2nCbIeUkYOvyeQbPE36b4b07xcdY3XQaeVqw-BlTEtV3Ix0wQW3HXUyOfFhhBY-JnaHlmOaU0DLjuPf4n1qidj4zY3ZFgyXuYm1zdWRY2QkYUABa4cQow9yLEv3LU__zmbFTA2D_JUoaoeNlR5OSgcDfcDWLlGZ5Xq4msVvNL_knd5FwM1itrZCKc33eIUhBmOgDofoh4PPz-kdTDG1QFvo4__NOCBJGKLBlO4V5ikqg8d1tNVgNSe94nlmtkp_qkJknOVdTAt7n2ZmAO20n=w1084-h628-no\" /></p>\n<h2>TCP Operations</h2>\n<h3>Connection Establishment</h3>\n<p>There is a <strong>three-way handshake</strong> when establishing a new connection with TCP. The control flags are used to communicate which stage the connection establishment is at, and there are two control flags used for establishing a new connection:\n- <code>SYN</code> \u2013 The Synchronisation flag is used in the first request to the remote device. This flag is only ever used in the first packet from the sender and the receiver.\n- <code>ACK</code> \u2013 The Acknowledgement flag is used for acknowledging when a packet has been received successfully.\n<code>SYN-ACK</code> are used together on the <strong>connection accepted</strong> response from the remote machine, to inform the initial sender that the first packet has been received.\nThe three-way handshake for a TCP connection establishment is as follows:\n1. The client, or local machine, sends a data packet to the remote server with the <code>SYN</code> control flag\n2. If the packet reaches the remote server (with routing and firewalls correctly configured) then the server will respond with a confirmation receipt with the control flags <code>SYN</code>/<code>ACK</code>.\n3. When the client machine receives the confirmation receipt from the server, it will then respond with an <code>ACK</code> packet. Upon the server receiving this, a connection is created and the two machines can now communicate.</p>\n<p><img alt=\"TCP Connection Establishment\" src=\"https://lh3.googleusercontent.com/6SDc57fgBkSq3s_pbKu-bVXXwDzvGLFxsHObJqr84rlwHvtN3aBEWFeQF3cc3ew3-j2YLICS46THZ1_n8nSYvdSLhDchCt52gGYf4lPEDk5aAeEqMAKLZQrDvpEoOUMthJSfpJupMykh2gC_PES_2vUN2f372qzKOADLDULE3i5kx82Vnc34IbxtpzeBwwtVi1s-cU9KZoqjfhRHgClN78wMVufIUHbeS0KssDOVHJWTgtIM2acrlKkSpSBm3Km5C47c71zwkenaNzPALUA1b48lz1sxQ58iYtLb0bpjkFs5arT1_xz0UDgY0vAtpgs1oE_vHykyHJqKLW3SgBLpYXN6aFlfL24-bdHL7vqg8gwSnWcjDnGEs5ro1gXOQwGpeAhs2UfCzDhwUz4ao5e9yDGc4PhZCW4QQSaiYe3sMKrwAIEGA1gLWL_5zQuHLdca6PPNu0MT5NG2CXo0wBHHjG_LnBJP9DYfP_WaxG_jc2AM1r9e1Nq6ls-rxAnF6Mo2YSN9PQsIuf7mBHeCqmY9KllaIwNtHnfnDo6d0tDLdUp4qQROk2p8Efr3eaXnjl7j7TaCLy42gqKIEca2J7r_P6QvCONDHazKxnv54HGKFudlFpgwaFtvszkm44oPs-eVnQqSeDQQr9UfG1g60BNRWBaFMkQoX9726U40RAMdRQlHDMz5rnjuS_YskTwnMBwIdDos4bhWeIZ1jAlMYz3Un-4aECzMWOzqfwdavYTWn1-IX0Gn=w835-h685-no\" /></p>\n<h3>Data Transfer</h3>\n<p>Once a TCP connection has been established, data can then be transferred in sequences.\nThe three main parts to take into consideration with TCP data transfers is the <em>sequence number</em>, <em>acknowledgment number</em> and the <em>window size</em>.\nThe sequence and acknowledgement numbers are essential for both devices on the connection, to be able to transfer the data in order and reliably.\nThe window size is important for increasing the overall transfer speed of the data. The server will increase the window size as the connection continues, so that it does not have to reply with acknowledgements as often.\n1. The client and server first connect using the 3-way handshake, as shown above.\n2. The client sends a packet to the server containing the first sequence of data, and this is data block one of the PNG image. The client now awaits a response from the server.\n3. The server responds with an acknowledgement to say that the data for sequence 1 was received correctly. It also gives a window value, to let the client know that they will send another acknowledgement once one more sequence has been received.\n4. The acknowledgement is received by the client, and 1 more data sequence is then sent in a packet to the server, including a reference to the acknowledgement that asked for it.\n5. Sequence 2 is received by the server and an acknowledgement response is created, with an increased window value this time. The server will now not reply until it has received sequences 3 &amp; 4.\n6. The response from the server asking for sequences 3 &amp; 4 fails and does not reach the client. After the timeout period, the client sends the sequence 2 packet again.\n7. The server receives the packet for sequence 2 again and then, once again, asks for sequences 3 &amp; 4.\n8. This time, the acknowledgement packet from the server reaches the client and the client sends two packets, one for sequence 3 and one for sequence 4.\n9. This pattern of sending, acknowledging and increasing the window size continues until there is a connection termination.</p>\n<p><img alt=\"TCP Data Transfer\" src=\"https://lh3.googleusercontent.com/Oz074lzAMSFv68esdoexOJ4eABpFhUSiR3fqn-Scvv1atC3wrQbY_vey6KAnP4z5wImNwhJlX6jQY_PNHD6fpYvPd7RDt-GCVe28JcalbgUFXHcLs_snA6pzDU6s1dkyNtqRjY9ZEGt7hY552o4LITQVd6bTT5jjh7PJ0I_K8021XQPgMoKuX7s7yqCgZ06fnsiiL6iWtVO40bDeQwKpxuZHaX0x6_4jnclo80X-XMOhniiiUctKieP_gNmBCU4i-APcE-uRK7Zy-6POzMUNiFa1dqZ-pXrEsOCGjb4i0_SkU3G6P76_chDtmgU6GTbdR1_nxvgV0F-tB9GtZXdb8Xld7tUjGyZBlUceEo_FKLlFyxqv28DBUjUezjLDndR0_ZbGAtAjlFDWTIYtJmK-MFgwaoU_gtPQ595U_MkAsUQl_FANeuCt_3pEFEYkXBUWFNtT6tI6R9ykgQ-VsS4GfThe9fCrjkCLJtcf2NxlKrv10spQ3XT89Tvhchvy8WWIhiPinkfkyfgeWCvslRHbXkBQm9CkEXDsOQ8vIrO--4YeYtiKMl0rFSz5cvDHvSB1o7jJENQ3hpCG4pA9PKzRt_eOx2YSrkBWvLMeIbLFWaBRkBR9ACaWS20xKkK-H9sEfrHXCl-HLAwzg5yFiKeP5pF3awq-aAuCEIJmfAP5JZDGM06GE1uB7tT4e3fM5PhKZnDZ0un1hdZXnPO_wHiGu8-WVIljd-h31O-vaN9l4sbFdYLu=w911-h1060-no\" /></p>\n<h3>Connection Termination (Graceful Close)</h3>\n<p>Here is the process for terminating a TCP connection:\n1. The client, or local machine, sends a data packet to the remote server with the <code>FIN</code> control flag\n2. Once the server recieves the packet, the connection is terminated and a <code>FIN-ACK</code> packet is sent back to the client\n3. The client server now <em>acknowledges</em> the connection termination, by sending an <code>ACK</code> packet back to the sever</p>\n<p><img alt=\"TCP Connection Termination\" src=\"https://lh3.googleusercontent.com/wxM7JkZo60NgRtrhwDXIsG0d96F-yEa1xwh4GxqxgISBipDc6zPSghRhDE4GHyHzgxGi5usW-GUFLFJsgiTZ3wuK-Yh4yeeZeN4IUmgFAriuLawjkbcTbJ9y0q6BFOFINDQYS3UbyzkA549Yh-SOHBC6ctd70sPJ9IzxQNW0RmdMV-81I1Len-DKE_bDGfEKZoMimHzcRI6xNqX76Xz44AwaITc92QAmWYkWB1kszZ9x8tNTs6ehofCZGxijAdk4PmTBppf1UHkfdHp9EU-778_X79bkQ388adIbE2HMz6DEkFmTALPLtNUPg0VXRXZD60GSKkI-toN_lhn-6iEnEyvaqa376hHqPyPUCdJyYbSQnf6tBfzFDxq0ZAb4GpNbfQw4MItn8sWa5Oxzx9vCNmQKtNA_R7G27T-jvlwMjeXhcTe8mEsfw5_L0FCeLeQ-ZxfdgG79hmtkXdmTqWZ6FTPxBOqaOTnVoWRzVPNt3k-jyXlFGJlugJoSNZ0weQmXAAQJr1_UeLQrORK7vEiLhvlU3qy0JwbFAuMs765QU6widCv-bRhQhJtmJX88ccFLCnXZVXJ0ykUWbgw-WxCwDtIuF1Z9jy6Ow8xPZNqg7auJeGj9daID0UTS1qLFRyNMZt_KlxcPdujPUv4Tracblb3jnVeYI2q2W0L1NMUFErEATBhQ9TrvUBr45a4iIgZqqRbzlB3VKaxUEBITMvHYtxZk4As2auk7DrQmUyfpyBcHI91v=w884-h685-no\" /></p>\n<h2>Tasks</h2>\n<p>For the task below you will need Wireshark installed.\nIf you are unsure what Wireshark is, or how to use or install it, please have a look at the Wireshark <a href=\"/topics/wireshark/modules/introduction\">Introduction Module</a></p>\n<h3>Viewing TCP Packets with Wireshark</h3>\n<ul>\n<li>We can start by running a brief scan, until some packets come in.</li>\n<li>Once there are some packets there, you can stop the scan and click on one of the packets that has TCP as the protocol.</li>\n<li>On the middle window frame, select the <code>Transmission Control Protocol</code> drop down</li>\n</ul>\n<p>You should now be able to see information about the TCP packets. See how many of the properties shown in TCP Header diagram you can find here:</p>\n<p><img alt=\"TCP Header\" src=\"https://lh3.googleusercontent.com/no-MmNGJTMlWVjNTEIyLmBatitBWBXCki0IZaqfJT_gl0NnCJwVByUc5YIPJ6BIPt-HDNQb2cbi5OfNdijVBQkHdQ0FqWrUSRvneMl3bHfi7cq7oVyPTHaTfz_Dz5q65RhFQRESPT0LA6WYLMnpMWErNgtWfLzWzIXSssal6fmCOmwf30dNTCTrs1PKiDkuZT4fxgl2cHIp5vwUAV3WsCRpuiMZ-uB-o1v9UArp2Gpt6W9i0rviT4WDZxopN2kiJu1crn7Ha6dFkQr0E0vgfP4xSiX1naMwPkC6fFr8Ck58Dr3zwvMz6NPl6F3vRfFR04jDGatILzDOO6Z56ExTLKf5eUjNx-FvZUIAqnP3Jo5GSypMz1gqq9p_5r14wYC-ATIlZSOJNrXErkH_cAo1oZYq5E02ah-kZu6wg_XBGmt8zM49YRYrQRkOo37oNrD8fx3Egk41qWyQcx639ebPfA8Yn-r_0R8GlCAGdu_JwWajO1KCn8UwFjy0DZ39vWbJ4LbIG3jTNi1_MorC_BspWYPBejjRjBpD3StOpQkNFbNN_6lbeFELN8T8_q_nzikoBPDUJRyb-8jtcffzPo0SEG2CqhytSURS7eH3iV9ucASKscJdAi7afadAVmf0kFRxxSe6MMRTc4USDhS1kaz1lD5Oe8bHntJJeJ3LJQsTdRuP1XBbCQWm-WAiBXXZlXIxLVMsNnR1XqKdHrwQhjyQD1RwLDZDEzEcTE7MUPZ7DIdW1A4bn=w1179-h1287-no\" /></p>"}, {"gitUri": "topics/networking/modules/models", "overview": "Models are used in networking as a representational and simplified way to give us a high-level understanding of the processes that are happening within a network.", "name": "Models", "resourceName": "networking/models", "content": "<h1>Models</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#osi\">OSI</a></li>\n<li><a href=\"#tcpip\">TCP/IP</a></li>\n<li><a href=\"#tcpip-and-osi-visual-comparison\">TCP/IP and OSI Visual Comparison</a></li>\n<li><a href=\"#tasks\">Tasks</a></li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>Models are used in networking as a representational and simplified way to give us a high-level understanding of the processes that are happening within a network.\nThe two most popular models that are in use are the <strong>OSI Model</strong> and the <strong>TCP/IP Model</strong>.\nBoth of these models have a layered architecture and provide similar functionalities.</p>\n<h2>OSI</h2>\n<p>The <strong>Open System Interconnection Protocol</strong> model is a <strong>7 layer model</strong>, which is a generic, protocol independent standard.\n1. <strong>Physical Layer</strong>\nThis layer describes what hardware is being used, such as <strong>Ethernet cables, hubs and repeaters</strong>. As the lowest layer of the model, it is ultimately responsible for the transmission of data bits from the source, or sending device to the receiving or destination device.\n2. <strong>Data Link Layer</strong>\nThe Data Link Layer checks the data obtained from the physical layer, to ensure that there are no transmission errors, and packages the bits in data Frames. Physical addressing schemes are also managed on this layer, such as <strong>MAC addressing, switches and bridges</strong>. Because this layer is so complex, it is often divided into two sublayers for more clarification; these are known as the <strong>Media Access Control</strong> and the <strong>Logical Link Control</strong> sublayers.\n3. <strong>Network Layer</strong>\nThe concept of routing is introduced here in the network layer. When data arrives here, the source and destination addresses will be examined to see if the data has reached its final, intended, destination.\nIf the data has reached the correct destination, it will be moved on to the transport layer. If it hasn't, the destination address will be updated and sent to the lower layers.\nRouters are used on this layer. As an example, if there is a port forwarding rule to send all incoming TCP traffic on port 8080 to a device on the LAN, the destination addresses will be updated with that of the local device.\nRouting is supported on this layer, by maintaining the logical (IP) addresses on a network and mapping them to physical (MAC) addresses.\nThis is accomplished through using the <strong>Address Resolution Protocol (ARP)</strong>.\n4. <strong>Transport Layer</strong>\nThe two most well-known protocols that are used on this layer are <strong>TCP and UDP</strong>. Other protocols that are on this layer may be used, but only for specific devices. They offer a range of other optional capabilities, such as support for re-transmission, flow control or error recovery.\n5. <strong>Session Layer</strong>\nThe session layer is where connections are maintained and recovered in the case of lost data or connection interruptions. Session orientated communications can be compared to when you talk to a person using a mobile phone vs using a walkie-talkie. With a mobile phone you have to make a call, and the other person must accept the call. This connection is then continued until one of the people on the call hangs up, or there is a connection time out.  When there are connection interruptions on the call, such as someone going through a tunnel on a train, if the interruption isn\u2019t long enough for a time out, the connection will be re-established. However, when using walkie-talkies, there is no connection established, so you would simply talk in the device and hopefully the person with another device on the same radio frequency hears it.\n6. <strong>Presentation Layer</strong>\nThis layer is not referred to as often and is the most simple of the 7 layers. The presentation layer\u2019s role is to make sure that the data is formatted correctly for the application layer. This is includes format conversions, and the encryption or decryption of data to support the application layer.\n7. <strong>Application Layer</strong>\nThis is where network services are operating to supply services to the end-user. Most services are usually just protocols that are working with user\u2019s data. As an example, the application layer protocol in a Web browser application will package the data, using HTTP, to send and receive web page content. Data is provided to and obtained from the presentation layer.</p>\n<h2>TCP/IP</h2>\n<ol>\n<li><strong>Network Access Layer</strong>\nThe Network Access Layer is the lowest of all the TCP/IP layers and is equivalent to the Physical and Data Link layers in the OSI model. This layer is where details of how data is physically transmitted throughout a network are defined.</li>\n<li><strong>Internet Layer</strong>\nThe Internet Layer is equivalent to the Network layer in the OSI model. This is where data is put into data packets, known <strong>IP Datagrams</strong>, which contain source and destination logical addresses. The information from these packets can be used to forward the datagrams between different hosts and across vast networks. This layer is also responsible for the routing of these datagrams.</li>\n<li><strong>Transport Layer</strong>\nThe Transport layer is equivalent to the Transport layer in the OSI model. The main purpose for this layer is to allow devices to carry on a conversation. Two of the main protocols that are used on this layer are <strong>TCP</strong> and <strong>UDP</strong>.</li>\n<li><strong>Application Layer</strong>\nThe Application layer is equivalent to the Presentation and Application layers in the OSI model. The higher level protocols are included on this layer, such as <strong>HTTP</strong>, <strong>Telnet</strong>, <strong>SSH</strong>, <strong>FTP</strong> and <strong>RDP</strong>.</li>\n</ol>\n<h2>TCP/IP and OSI Visual Comparison</h2>\n<p>Here is a diagram showing how the layers between the OSI and TCP/IP models relate:</p>\n<p><img alt=\"OSI &amp; TCP Comparison\" src=\"https://lh3.googleusercontent.com/Kk1yl6jxDdDawh4UUEFlxjUyb3NkjI9A39ExIoDriff6cRr2_2noL0zgIz1p6zt1nfrkKcH3mtnIX_6e07g4wIa5StrKMvUO4419CFhjjSML0UQfe4UiW1PMfNPEbHrPNu7DpUD8CkjYNE1BP2jEXa9drRGFaU8133uUH_HhBF9GCMtQBBns-L2t88g8AEGp_KFf49KVLYb59SnPoON7R4jm6ZhQz9BZCX6C9J7omSAeTYYm4hEP-qlJ-XRtd7BwQKe0lSmVSAixeC2gE30s-Eb7EmS_rA9ONGX09lRovj4agv-nDFONhZWputVhSUwlHc-CQo1RLkUz0bq4zls2YNJKw0tkPCgzXNTdjwCozEF5GHcXqe7dF33EAnF3QMs71-RVQQTKiEIMKU_AAkKCL3nY9O9Admiv_KCgyPojUtkQPoXvEAY647nNF4rbNu9siOrnDiJERHopj82Wt9a8pD17UtiG17CJIdLt3V9TWrC8_5qXp_mZdhdO46E3GrzqcgI0epcyRWJGHDsX0rirMUr_6BWb1nTpJQhEy646I01C7Rco7_eXQ0qXNdMyFLEuC1iWi9na4MuuGrdF21_Jwf3MWSVqiE7vM5kz-WTX4OfR_TN5BHb8gKoBXuGhVAe5YzcDFkbU95BxOXgkdM_PDY8QQ90YanfncLoLB8RhdEBHVJB1mDFRmMCGLGhSP4fYjeUsfvJIdIiVlDsCNuBIEa-4AGl4Y_gpzcMTHQ8PQrmjtvtQ=w1208-h752-no\" /></p>\n<h2>Tasks</h2>\n<p>Have a look at this YouTube video for more information on this:</p>\n<p><a href=\"https://www.youtube.com/watch?v=i9RL5jD9cTI\"><img alt=\"OSI and TCP/IP Model Overview\" src=\"https://img.youtube.com/vi/i9RL5jD9cTI/0.jpg\" /></a></p>"}, {"gitUri": "topics/networking/modules/frames", "overview": "", "name": "Frames", "resourceName": "networking/frames", "content": "<h1>Frames</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overiew\">Overiew</a></li>\n<li><a href=\"#incoming-and-outgoing-frames\">Incoming and Outgoing Frames</a></li>\n<li><a href=\"#frames-traversing-the-network\">Frames Traversing the Network</a></li>\n<li><a href=\"#cyclic-redundancy-check-crc\">Cyclic Redundancy Check (CRC)</a></li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#viewing-frames-with-wireshark\">Viewing Frames with Wireshark</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overiew</h2>\n<p>Devices on a network send and receive Packetized Data in discrete chunks called frames.\nFrames can hold a maximum of 1500 bytes, or 12000 bits. Whilst it won\u2019t be necessary to remember this number exactly, it is important to understand that frames cannot hold a lot of data.\nFor instance, if an MP3 file is 4MB, that is 4,194,304 bytes. This means that lots of frames will need to be transmitted to transfer the entire file.</p>\n<h2>Incoming and Outgoing Frames</h2>\n<p>Data comes down from applications, such as a Web browser, and into the Network Interface Card (NIC).\nThe NIC then creates a frame, using this data, and sends it into the network to reach the destination device.\nIncoming frames from the network are first checked, to see if they are intended for the card.\nThe data is then processed for the application running on the system and sent to it.\nAll used and unwanted frames are discarded.</p>\n<p><img alt=\"Incoming and Outgoing Frames\" src=\"https://lh3.googleusercontent.com/NpIQqDTiCzRZSeTXQ3j8N5832ewq2DKz559cwyYNfxU0WWo7UN1groARYNZwgaj-y-G1MTZcE13HzNQPQ4cyeRFUdOqgpFukLzsdYT8YtK4Zh07hojC_pS7ncQCiUhnDr5vCc_dSbC1kFfTcON5HJZcLePtZDzXS9SBoywxPUBHpIuIjAN19X2Fk3dk01MAOoxqwo_WhM2QLntbl97PuuAnRTxeBOUU6ENgks5D8nXPDMs4yxSb1IcJs4rx1fA_yUMvKW_LyOaAVGadM6gELWpQ95rhlVw94Y2qnMY5uVAEFZsXRG6H9z8XT_boip_pFJfmfcZWAQ1IBu-uC-7dQ7OWL3fhzGc_xQFJc8mTlK7lFZTzGwXgQJoG_sXoEwIomj6n9u-rBt9dfcFC26lY3Q-sHwrytCofzuhFAwUuVkLoxXb-QvCxJs1wVHLJTKjxOIuvWFxN5p0tdWdI79hOTZ6oKJnLm67cJTzaHnOgIdLXUkTirfSV7s-IMtjCz2E9ZFsKJgSTsLOC5IohYeFcFPfGE4_C8Nm1rhs9DSrQIVT8p0YYuXCxtT7s89__PZoal880KPnNgEKmp1dBJ6JRXUrcI97gSahP_wPIEJ0PRQlsputAhH5C15O2gV25BGTYiuyQkl5QI43JBa3ogiuYmVbH3OLiIgNiPumnVG7MjXAA8xi1xv5pGD6Z4ZuPCYQbyJWLv0-olmu8EgMQO2XLzzQ7OKwTK6zzeL4Y4D-loIxiLLspD=w716-h484-no\" /></p>\n<h2>Frames Traversing the Network</h2>\n<p>With a hub, outgoing frames PCA are relayed to all devices on the network. Included in the frame is the physical address of the sender and the target.\nAll devices will check the frame, to see if the physical address matches their own.\nIf the target address matches, the frame is processed. If it doesn't match, the frame is discarded.</p>\n<h2>Cyclic Redundancy Check (CRC)</h2>\n<p>CRC is used as a way to verify the integrity of the data being sent in the frame, and to ensure that it hasn\u2019t been corrupted.\nCRCs are a part of the Frame Check Sequences (FCS). All frames that are traversing over a network are in danger of being corrupted, or damaged, by interferences on a network.\nFCS can use CRCs to validate the data that has been transmitted. CRCs work in a similar way to checksums; an algorithm generates a number or string of text from a piece of data, and this algorithm can then be used to confirm the frame's integrity when it's received.</p>\n<p><img alt=\"Cyclic Redundancy Check\" src=\"https://lh3.googleusercontent.com/UaSVzouzhqyIat8pqoGfH_3mHy1-MBV3Fu0Y6xzC1y4yM8yWMgD8FvFgd2952s3ce1D7nGN-jIEuKms1XjwCB8fVQJRLblrZ2V5vdamEFQzU_SRzS90_ObvigD3QpLlFlGJ0kOTMVyb8ZNMpgzdyF5IUKdqaScshibwT8B8Uu2sT_jNiMcS3HhKUq6M0KUZKim4Dk0vtcmASNzP7DtT4zau4X4tk1mZ9CvxTDqQ9x2qsiCFIoMQtlYsCkxNi_qWXQru0de1y4yeeVmK7obeDYm04kKCTJcznPRk3l0gdn9_xWx6FnrRH7Tkss42Vvit98cB_2kPCPY0G6a1DQaDyGcFEyggbw6K7foxdMNFerr5Rfh_YzYCTmjeAr6xmHClWt5f_U2KXgYaBLU2lrApBrGNU57Wm4_5I0bITzkA-dRCOx4bTG9d1kY5hKT6T8UL0ThMXW9YQL3LdwyDv5hAAOCXUhflEqxytwEM0fp6qOEp5xvZL_JdlNe2P8DjuICTLXBZ3RXCIIrqzUKLAAGHfgb_VaGyYy_GviC0534GQdAIdHTZS-QOy252Gpbn8PxSMDWLCxx6ADpldW7--g8_QtunlerwNV4ILXM9tqyXXPVVla5OKGBd-jLEg1Z3JFkK2gts7OegiM-I1uKKxGdR8A3mvgpZZfL0jxPz1azt6sPj1nBpjBvbfZPSFE_2hqjohLm0zL07OipEOpptUxZSyMdlou-kaAS2ERLkLmGBnfCpgGDvd=w1278-h411-no\" /></p>\n<h2>Tasks</h2>\n<p>For the task below you will need Wireshark installed.\nIf you are unsure what Wireshark is, how to use or install it, please have a look at the <a href=\"/topics/wireshark/modules/introduction\">Wireshark Introduction Module</a></p>\n<h3>Viewing Frames with Wireshark</h3>\n<p>We can start by running a scan until some packets come in.\nOnce there are some packets there, you can stop the scan and click on one of the packets.</p>\n<p><img alt=\"Wireshark Frames\" src=\"https://lh3.googleusercontent.com/dibVkV243q_w-BgH7Iwv4-55mJ--drOww0I1EQct98MR7l8sOH47hYx-LFpMm2Lm79d6Vsb8sBdvawUzSNf4bZPt1A-fk2lLwwhmVBUzPnnZzlv1rWxqUz0EXwrbaGa5-krA_PPBR9v3EIEzMe4TyRQEB4Zq16-C3ma7znaNSpz1sPlwfTrcY05JQ0U9cLFzBiBkCg0NXuBEvLm3kuDyGcO1A996ZfyNHLDK2Ngck6nLvBw5OGqCNuCINQlQUtwaPgwl13DV_zOUG8aSfHJIoUkHmZee8_7hoiH61d_10Lhgh6DjRhDX0SBbmJ2rqe6IMyJUxnzeewI2zWFzWAS2YGV0OW7xttHgBAlQIzrYdZ7vlHHsYje4Qy3Eli3uiwOCL7LMzPJyKhka8bKRTpKhude50RUYfP2Ymx8haT6jsCxZ_21iiNWafe1vqDA1QOBFT8jxXyUP0DgJCftPqBnJMgWJ5MXZ5ff3RaBn6bfz4X0FdRDUBgcwmtc-nvfBy_XtACdwVC_70tg8D6KB_AuxxBATmgBO-pAI_a4bZzLftfNtj9ZnDaXYFQ_SngdQwiwdDasrXCv115cTAxR2stiZBXWG6Yi6t1dRB4BImBuFWOK35xDNaRRJTQbwjc11ZF7ii0stdKlzywmyPLEn9OFmdmCRBwR_S23sbQcmvWqivM8xwf4WVj3AFeJOCzsY_NjcvwzjEYwjj6ycgax7S34Z_EVTywHFtAfEBgGkE571F_RR8bba=w1102-h430-no\" /></p>\n<ul>\n<li>In the bottom window pane, you will see the frame contents</li>\n<li>In the middle frame is properties about the frame and protocols being used in that frame.</li>\n<li>The example above shows properties for a TCP packet over IPV4</li>\n<li>You can expand the <code>Frame</code> drop down to see frame properties<ul>\n<li>The CRC is removed by the network interface before being sent to Wireshark, so this won't be visible</li>\n</ul>\n</li>\n<li>Under the <code>Ethernet</code> section is information about the source and destination addresses.</li>\n</ul>"}, {"gitUri": "topics/networking/modules/udp", "overview": "User Datagram Protocol (UDP) is connectionless and not as reliable a service as TCP. There is no acknowledgement of packet delivery, sequencing or even error recovery.", "name": "UDP", "resourceName": "networking/udp", "content": "<h1>UDP</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#udp-header-format\">UDP Header Format</a></li>\n<li><a href=\"#udp-operation\">UDP Operation</a></li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#viewing-udp-packets-with-wireshark\">Viewing UDP Packets with Wireshark</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>User Datagram Protocol (UDP) is connectionless and not as reliable a service as TCP. There is no acknowledgement of packet delivery, sequencing or even error recovery.\nHowever, UDP does have a very important advantage over TCP - <strong>speed</strong>.\nHigher connection speeds are always preferred, but sacrificing reliability can be a big issue (depending on the use case).\nUDP is great for tasks that require data on demand or in real-time, such as audio and video streaming on conference calls or when playing online multiplayer games.</p>\n<h2>UDP Header Format</h2>\n<p>Other than the data, there are four components to a UDP packet\u2019s header. This is significantly smaller than the TCP headers, because UDP is more limited in capability.</p>\n<ol>\n<li><code>Source Port</code> - The port from which the packet was sent from</li>\n<li><code>Destination Port</code> - The port of the receiving device</li>\n<li><code>Length</code> - The total size of each data packet is stored here, including both the header and the\ndata.</li>\n<li><code>Checksum</code> \u2013 Similar to how TCP works, UDP checksum allows the receivers to validate\nthe incoming data for any corrupted parts of the message. </li>\n</ol>\n<p><img alt=\"UDP Header\" src=\"https://lh3.googleusercontent.com/g8GbrocvKB53cwpqiWtSqxgnmkdiUJMQOLsfd4gxkTf2Qq82nASrHXe2oTtMa_MVmzuuH33K0F8T7cNDunhBHnGKQQhmir5LyacyCWpPEQA63kZrPMSpYYKc4Ch_g_oMbpAqzXxv6iivDz7L0S64gP7cHyGCVndcpHtHie4hjGYhePBTtVr9SJ14w7eRB8tirtFFbOBRMuocYiUB-42wnNP3rOq6nUnqGwolgM5Sf9-P0YQfX7HipbyOcDcXTX42TKnvHrdnpHVndv6YIByhNKpRM-opAKrTbrbtfl6sEzlg5Ip-rZB-8QCf755dn-L2g1tYmvKoJHic_fs6ZOSj2K0Il3ybk5k-b5DhsfrQ1EOD3XJv8kCL-E4i1IriAIchgB_ZMM5EFBizbcE1FyZ4RLRnHJtVzLf7vuBzr9RMGi9W22vsm6ad_6K1-P1Z3WokXc4-a2nPyHvf_Fis9vldJ9WsdJeiKc-OBS2D7yk-rdQuwp_XRm_2uRae1_HET7RRcHjq9N45EOtA87OPJGVvXbPQkuLwtJCE4Alm3Fyec4zNzfDoVS4XVGwi1b9UkS33exSPOmTWnXhBB0kzwLJDSj83g6wRWuoE4LtmCXxbhBx-srU3XFCGdVRfTaJ7BU4aar20lkjIgqNgCfS-7c2nKS7pUBEixcdIfbIb8e8lUE08XS3vmDtT89tmfp5-dPNsEwqpYh73yFRNieu33IiXQifD50QDXX5uRVoWyrtZMMK1XYAE=w1084-h341-no\" /></p>\n<h2>UDP Operation</h2>\n<p>Regarding the illustration below:</p>\n<ul>\n<li>Segment 1, 2, 4 and 6 are successfully received by the server and processed</li>\n<li>Segment 3 was lost in a connection interruption. There is no way of the remote server, or local machine, knowing that it should have received that lost packet. If this were TCP, the packet would have been resent to the server after a time-out period.</li>\n<li>The packet from segment 5 has been corrupted and the checksum validation fails when it reaches the server. The local machine does not know about this and will not resend the packet; it will simply discard it.</li>\n</ul>\n<p><img alt=\"UDP Operation\" src=\"https://lh3.googleusercontent.com/kskI1eWHh67F2Nbh1raZeNNllsbIPdl9bh6bqC9_XKkRx3VHkE34ToBYZNsEjtlrfRog7vXYhrrJ5JEkDdfgEbgvp4V95F7f1PbbO3rxAiF8SC-d0zfv27lu5WJ-KGk-wQrDdXPiv9paqM5pnvONDSfOlwfmWSOzEdLJRx4vsG9oyQ6kxu3tEbhEy4ktU4DtGfhvohTSMx5hpVab4tP618_eacN8ji-8PpD3A6BIXIfZruxAus8prZyak0aTeChW2KeLoVL35PzH3_NRiH0d23ZrOaT-eZF7yD5Rf8pqyP4C4UAJRLP_HTu-a8z13NRSOaMezE7bB42GMImQA2GOnrjOvXaNhJEzAMuouVTg98NxFLJc4-0o-RkHjf1yqpDjVFahC6-lx7jxYhu_OTXsE5MnQQs7t8NVwOmCzEgRkvKAViRH4xNUgCe_IKO_L5Ys8CGEmiqZ7d9sUE81zRcE_tnHaK5sNneVxaIiXZLIp6KFeRkcCOQ4qZ1CkXGgXj70L-ZF6O79m22mjQmwvaewNu62LTNJRiNoDjQUou3Kf-wMK95vtQZd9Sm19x66RdZA32QonJPU_49rFaZccn4OaK3qcE5Q8vCek4-OlBglnokzcwL3keTP9qi1NYZpT1X9Z8nwmrsrG6k4uOQ9GKDZ1yx3oUwbvGyp18GbqddhXgFkHnUuJBD0Fd7gEnI4XgteKOuLIMvT-TyeEjHzNX3zP-ppwED-tkTR1Xxw8s46dXw3Fkt4=w725-h685-no\" /></p>\n<h2>Tasks</h2>\n<p>For the task below you will need Wireshark installed.\nIf you are unsure what Wireshark is, or how to use or install it, please have a look at the Wireshark <a href=\"/topics/wireshark/modules/introduction\">Introduction Module</a></p>\n<h3>Viewing UDP Packets with Wireshark</h3>\n<ul>\n<li>We can start by running a brief scan, until some packets come in.</li>\n<li>Add a display filter for UDP, by putting <code>udp</code> in the display filter box:\n    <img alt=\"UDP Display Filter\" src=\"https://lh3.googleusercontent.com/uz5gxaGCQE_guHbfHo9MVM7onIM1qEmtdxzkHTFGRd8hWZHV_PS7KZtnJPcrrNnfJV8oTw2VWiIJ-EHAUfm7UmOPs4xMLseSpqFMCvJ1ELKmw2A4E2xhGnI7D7L0GxxVwFMSYveEqfI3V2NVO268dK6eLRMrGYXbiULBuPhSlCdamh4nefkOITf30Ih2272G-IiT0X5uYXVT9GgOpbHadJwsIDs8FWujTH8iAf5UvgjvH84Rg9OVXPrJB2N8Oc_Ljuy3br5GuGUMKHn8m9jaT9bIKTHihYp3WO4mSpwn-kymrA6rplz9DlKEbu7awkZk6xIH6yTqTStMO4H82Q8yPX5W1NA9nf0IBdeLG-qqCspeVKeM_oW_hfuI8Rf6Y6_WKigAOQ5McmIsQP5pZNeOK-YkkNePLSnTeb8ZbJXiHeJPIlcYhts88X3DkRLNQtVPoHGmAXfHUHVBjwVetBX-tgziDoib6IxCN7tSzHq-uK1bE1ubhxuzXbkLGn1JMtOk2hsYP5ncTAnIOTjg51XVCOE3i27MEtakh5UCFU-6-5wUol6rjnoL_UIVS1tg5S_m8WuTFbPMMzyrvn5xzMmVtgOz8A1gqK_lr5KDHlu9vVh09DFaS93PKER8DWZcUYhYM8nHT0NPW1Zr-Bd0MeqxshAK3pCCdn1aY91I0IsSrH-xhlvswZaiV9mHVv8BcvSXExYH0k_2Kv_6q-zkPQ5JoRvZX56jCWleZB4wpw4qqMVwflK2=w1116-h51-no\" /></li>\n<li>Once there are some packets there, you can stop the scan and click on one of the packets that use the UDP protocol</li>\n<li>On the middle window frame, select the <code>User Datagram Protocol</code> drop down</li>\n</ul>\n<p>You should now be able to see information about the UDP packet. See how many of the properties shown in UDP Header diagram you can find here:</p>\n<p><img alt=\"UDP Data\" src=\"https://lh3.googleusercontent.com/W0ZWp-urebN0f7nyIC17HpXW4IL3XT8WunCu3KH3-K3FL2pEYpmXT74yFVM7eSfdt6iWjH2JppSxqwy0CjmTfV-8Zn28P7tafGXi5aiMm41c30UITk3pQapeRSZ3ohGSkdDDtWeJFl27PLNGZw8cPVEEmhoDiPGyvLUsgthVLPjjXxP2CYdYtP2BKAyeW5yPcmDnOi1hkTcxG_wtfAfBFET1kkImZa9nnyRSoYrup8-BpRE-etXYVJ1Mm-8Fi6owjiEtQZV_yNySMekYmK4j4MHoIFxzanw85Q-k0lIikQ7eAwSbQVxUZoied57IHb0rSijkXznM5338NScibPDurik5CcdiQ9HuzOxIJHb1JmORRyHtMgMgswSLBmbe119qnQRbs4-iIymI3o4u4gC_yPkL1YXJVN4K7O3-k1LvqKlfbBj3KHGUMbJ9f5_Hv7k_2lv06rgretJBULdUSjw4zWZb0MLR6k1QRm4xKSpRRW8xYGifA1MGuQ_QnVJB-dNeYLHVJ0vrRXFKyDhViaWWu--WkiZbZvSAi9awKf_Vv1OvoskH1-rSgNMRPhMISD7YITCYtnZvVr1qJ5UD2qmHYl8wXYs3ECEH_ZmFb6edrnnCfW0xm9aR_O9Eml8JaVTTpzEai76RtwYXt7JQia-zAyfFaS5CzG-w96j8rsy30iA_UVa4Jiz2yMt4jevDJMzKZLsARVqhFNVIy5DySekNeA1LPvRFXDTlCvBwopkQ8dV68_p4=w1181-h1287-no\" /></p>"}]}, {"gitUri": "topics/netcat", "overview": "netcat (often abbreviated to nc) is a computer networking utility for reading from and writing to network connections using TCP or UDP.", "name": "netcat", "resourceName": "netcat", "modules": [{"estTime": 10, "questions": [{"value": "What can port scanning be used for?", "answer": "Finding out what ports are available on a host.", "choices": ["Load testing.", "Monitoring TCP traffic going through the given ports."]}], "gitUri": "topics/netcat/modules/port-scanning", "overview": "Port scanning is a technique used for finding out which ports have an application running on them, making them accessible.", "name": "Port Scanning with netcat", "resourceName": "netcat/port-scanning", "content": "<!--PROPS\n{\n    \"estTime\": 10,\n    \"questions\": [\n        {\n            \"value\": \"What can port scanning be used for?\",\n            \"answer\": \"Finding out what ports are available on a host.\",\n            \"choices\": [\n                \"Load testing.\",\n                \"Monitoring TCP traffic going through the given ports.\"\n            ]\n        }\n    ]\n}\n-->\n\n<h1>Port Scanning with netcat</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#usage\">Usage</a></li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#run-a-basic-scan\">Run a Basic Scan</a></li>\n<li><a href=\"#run-a-scan-again-after-installing-an-application\">Run a Scan Again After Installing an Application</a><ul>\n<li><a href=\"#installing-on-ubuntudebian\">Installing on Ubuntu/Debian</a></li>\n<li><a href=\"#installing-on-centosrhel\">Installing on CentOS/RHEL</a></li>\n<li><a href=\"#run-the-scan-again\">Run the Scan Again</a></li>\n</ul>\n</li>\n<li><a href=\"#cleanup\">Cleanup</a><ul>\n<li><a href=\"#removing-on-ubuntudebian\">Removing on Ubuntu/Debian</a></li>\n<li><a href=\"#removing-on-centosrhel\">Removing on CentOS/RHEL</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>Port scanning is a technique used for finding out which ports have an application running on them, making them accessible.\nThis can be used to verify security polices that are in place, which define what ports are accessible on a host machine.\nA preferred tool for port scanning is <code>nmap</code>; however, if this is not available to you, you can still use <code>netcat</code>.</p>\n<h2>Usage</h2>\n<p>You can use the following command to run a simple port scan:</p>\n<pre><code class=\"bash\"># nc -zv [HOST] [PORT_RANGE]\nnc -zv 127.0.0.1 1-1000\n</code></pre>\n\n<p>This example scans the <code>127.0.0.1</code> host (the local machine) over ports 1 to 1000.\nThe <code>z</code> option is used here for running netcat in a scanning mode; this means that while it's testing all the ports, it won't attempt to download anything.\nThe <code>v</code> option is used for verbose mode, which indicates, more clearly, whether netcat was able to find an accessible port.</p>\n<h2>Tasks</h2>\n<h3>Run a Basic Scan</h3>\n<p>On a Linux machine with netcat, run a scan to find the accesible ports:</p>\n<pre><code class=\"bash\">nc -zv 127.0.0.1 1-1000\n</code></pre>\n\n<p>You should see that most of the ports are not accessable, because there are no applications listening on them:</p>\n<pre><code class=\"text\">bob@port-scanning-with-netcat:~$ nc -zv 127.0.0.1 1-1000\nlocalhost [127.0.0.1] 22 (ssh) open\n</code></pre>\n\n<h3>Run a Scan Again After Installing an Application</h3>\n<p>Now try installing an application, such as NGINX, so that port <code>80</code> shows up in the scan:</p>\n<h4>Installing on Ubuntu/Debian</h4>\n<pre><code class=\"bash\">sudo apt install -y nginx\n</code></pre>\n\n<h4>Installing on CentOS/RHEL</h4>\n<pre><code class=\"bash\">sudo yum install -y nginx\n</code></pre>\n\n<h4>Run the Scan Again</h4>\n<p>Try running the scan again:</p>\n<pre><code class=\"bash\">nc -zv 127.0.0.1 1-1000\n</code></pre>\n\n<p>You should now see port <code>80</code> pop up in the scan:</p>\n<pre><code class=\"text\">bob@port-scanning-with-netcat:~$ nc -zv 127.0.0.1 1-1000\nlocalhost [127.0.0.1] 22 (ssh) open\nlocalhost [127.0.0.1] 80 (http) open\n</code></pre>\n\n<h3>Cleanup</h3>\n<p>Remove NGINX to cleanup:</p>\n<h4>Removing on Ubuntu/Debian</h4>\n<pre><code class=\"bash\">sudo systemctl stop nginx\nsudo apt purge -y nginx\n</code></pre>\n\n<h4>Removing on CentOS/RHEL</h4>\n<pre><code class=\"bash\">sudo systemctl stop nginx\nsudo yum remove -y nginx\n</code></pre>"}]}, {"gitUri": "topics/tracert", "overview": "In computing, traceroute and tracert are computer network diagnostic commands for displaying the route and measuring transit delays of packets across an Internet Protocol network.", "name": "Tracert", "resourceName": "tracert", "modules": [{"estTime": 10, "gitUri": "topics/tracert/modules/introduction", "overview": "In computing, `traceroute` and `tracert` are computer network diagnostic commands for displaying the route (path) and measuring transit delays of packets across an Internet Protocol (IP) network.", "name": "Introduction", "resourceName": "tracert/introduction", "content": "<!--PROPS\n{\n    \"estTime\": 10\n}\n-->\n\n<h1>Introduction</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#tracert-output\">Tracert Output</a><ul>\n<li><a href=\"#example-output\">Example Output</a></li>\n<li><a href=\"#output-meaning\">Output Meaning</a><ul>\n<li><a href=\"#hop-number\">Hop Number</a></li>\n<li><a href=\"#name--ip-address\">Name &amp; IP Address</a></li>\n<li><a href=\"#rtt-columns\">RTT Columns</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#try-it-out\">Try it Out</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>In computing, <code>traceroute</code> and <code>tracert</code> are computer network diagnostic commands for displaying the route (path) and measuring transit delays of packets across an Internet Protocol (IP) network.</p>\n<p>Here's an example of a path for going to <code>google.co.uk</code> from a computer in London:\n<img alt=\"Traceroute Map\" src=\"https://i.imgur.com/cE9UPCB.png\" /></p>\n<p>The history of the route is recorded as the round-trip times of the packets received from each successive host (remote node) in the route (path); the sum of the mean times in each hop is a measure of the total time spent to establish the connection.\nTraceroute proceeds unless all (three) sent packets are lost more than twice. If this happens, the connection is lost and the route cannot be evaluated.</p>\n<h2>Tracert Output</h2>\n<h3>Example Output</h3>\n<p>Below is an example output from a basic <code>tracecrt</code> command to <code>google.com</code>:</p>\n<pre><code class=\"text\">Tracing route to google.com [172.217.20.142]\nover a maximum of 30 hops:\n\n  1    &lt;1 ms    &lt;1 ms    &lt;1 ms  hyperhub.mynet [192.168.1.1]\n  2    32 ms    58 ms     4 ms  100.97.100.1\n  3     1 ms     1 ms     1 ms  172.16.25.18 [172.16.25.18]\n  4     9 ms     1 ms     1 ms  172.17.10.102 [172.17.10.102]\n  5     1 ms     1 ms     1 ms  172.17.14.0 [172.17.14.0]\n  6     1 ms    &lt;1 ms    &lt;1 ms  172.16.17.81 [172.16.17.81]\n  7    &lt;1 ms    &lt;1 ms    &lt;1 ms  ae2-775.cr1-man1.ip4.gtt.net [77.67.123.169]\n  8     7 ms     7 ms     7 ms  et-0-0-43.cr10-lon1.ip4.gtt.net [89.149.139.1]\n  9     8 ms     7 ms     8 ms  72.14.221.145\n 10     *        *        *     Request timed out.\n 11     9 ms     8 ms     9 ms  216.239.57.120\n 12     7 ms     7 ms     7 ms  108.170.246.176\n 13     8 ms     8 ms     9 ms  64.233.175.113\n 14     8 ms     8 ms     8 ms  72.14.237.52\n 15     8 ms     8 ms     8 ms  74.125.242.65\n 16     8 ms     8 ms     8 ms  172.253.68.23\n 17     8 ms     8 ms     7 ms  muc11s10-in-f14.1e100.net [172.217.20.142]\n</code></pre>\n\n<h3>Output Meaning</h3>\n<p>Below is a table showing the meaning of the different columns of the <code>tracert</code> commands output.\nThe data in the table is taken from the first 3 hops of the example above.</p>\n<table>\n<thead>\n<tr>\n<th>Hop Number</th>\n<th>RTT1</th>\n<th>RTT2</th>\n<th>RTT3</th>\n<th>Name &amp; IP Address</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>1 ms</td>\n<td>1 ms</td>\n<td>1 ms</td>\n<td>hyperhub.mynet [192.168.1.1]</td>\n</tr>\n<tr>\n<td>2</td>\n<td>32 ms</td>\n<td>58 ms</td>\n<td>4 ms</td>\n<td>100.97.100.1</td>\n</tr>\n<tr>\n<td>3</td>\n<td>1 ms</td>\n<td>1 ms</td>\n<td>1 ms</td>\n<td>172.16.25.18 [172.16.25.18]</td>\n</tr>\n</tbody>\n</table>\n<h4>Hop Number</h4>\n<p>This is the first column and is simply the number of the hop along the route. In this case, it is the first hop.</p>\n<h4>Name &amp; IP Address</h4>\n<p>This column has the IP address of the router. If it is available, the domain name will also be listed.</p>\n<h4>RTT Columns</h4>\n<p>The three <code>RTT</code> columns display the round trip time (RTT) for your packet to reach that point and return to your computer.\nThis is listed in milliseconds.\nThere are three columns because the tracert sends three separate signal packets.\nThis is to display consistency, or a lack thereof, in the route.</p>\n<h2>Tasks</h2>\n<h3>Try it Out</h3>\n<p>Lets see what hops are made just by making a request to <code>google.com</code>:</p>\n<pre><code class=\"bash\">tracert google.com\n</code></pre>\n\n<p>You should see an output similar to this:</p>\n<pre><code class=\"text\">Tracing route to google.com [172.217.20.142]\nover a maximum of 30 hops:\n\n  1    &lt;1 ms    &lt;1 ms    &lt;1 ms  hyperhub.mynet [192.168.1.1]\n  2    32 ms    58 ms     4 ms  100.97.100.1\n  3     1 ms     1 ms     1 ms  172.16.25.18 [172.16.25.18]\n  4     9 ms     1 ms     1 ms  172.17.10.102 [172.17.10.102]\n  5     1 ms     1 ms     1 ms  172.17.14.0 [172.17.14.0]\n  6     1 ms    &lt;1 ms    &lt;1 ms  172.16.17.81 [172.16.17.81]\n  7    &lt;1 ms    &lt;1 ms    &lt;1 ms  ae2-775.cr1-man1.ip4.gtt.net [77.67.123.169]\n  8     7 ms     7 ms     7 ms  et-0-0-43.cr10-lon1.ip4.gtt.net [89.149.139.1]\n  9     8 ms     7 ms     8 ms  72.14.221.145\n 10     *        *        *     Request timed out.\n 11     9 ms     8 ms     9 ms  216.239.57.120\n 12     7 ms     7 ms     7 ms  108.170.246.176\n 13     8 ms     8 ms     9 ms  64.233.175.113\n 14     8 ms     8 ms     8 ms  72.14.237.52\n 15     8 ms     8 ms     8 ms  74.125.242.65\n 16     8 ms     8 ms     8 ms  172.253.68.23\n 17     8 ms     8 ms     7 ms  muc11s10-in-f14.1e100.net [172.217.20.142]\n</code></pre>"}]}, {"gitUri": "topics/linux", "overview": "The Linux open-source operating system, or Linux OS, is a freely distributable, cross-platform operating system, based on Unix. It can be installed on PCs, laptops, netbooks, mobile and tablet devices, video game consoles, servers, supercomputers and more.", "name": "Linux", "resourceName": "linux", "modules": [{"gitUri": "topics/linux/modules/managing-systemd-services", "overview": "A service, or daemon, is a background application that waits to be used, or carries out essential tasks, rather than being in direct control of an interactive user.", "name": "Managing systemd Services", "resourceName": "linux/managing-systemd-services", "content": "<h1>Managing systemd Services</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#systemctl\">systemctl</a><ul>\n<li><a href=\"#listing-services\">Listing Services</a></li>\n<li><a href=\"#starting-a-service\">Starting a Service</a></li>\n<li><a href=\"#stopping-a-service\">Stopping a Service</a></li>\n<li><a href=\"#restarting-a-service\">Restarting a Service</a></li>\n<li><a href=\"#reloading-a-service-configuration\">Reloading a Service Configuration</a></li>\n<li><a href=\"#enabling-a-service\">Enabling a Service</a><ul>\n<li><a href=\"#enable-and-start\">Enable and Start</a></li>\n</ul>\n</li>\n<li><a href=\"#disable-a-service\">Disable a Service</a></li>\n<li><a href=\"#check-the-service-status\">Check the Service Status</a></li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#install-nginx\">Install NGINX</a></li>\n<li><a href=\"#check-the-service-status-1\">Check the Service Status</a></li>\n<li><a href=\"#stop-the-service\">Stop the Service</a></li>\n<li><a href=\"#check-the-service-status-2\">Check the Service Status</a></li>\n<li><a href=\"#enable-and-start-the-service\">Enable and Start the Service</a></li>\n<li><a href=\"#make-a-configuration-change\">Make a Configuration Change</a></li>\n<li><a href=\"#cleanup\">Cleanup</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>A service, or daemon, is a background application that waits to be used, or carries out essential tasks, rather than being in direct control of an interactive user.\nAn example of this is all of the processes running in the background on a machine, such as: the networking services, graphical interface, etc.\nWe can use the systemd software suite as a unified and consistent way of controlling all of these daemons, and even use it to manage our own applications, such as web and API servers.</p>\n<h2>systemctl</h2>\n<p>Within the systemd suite there is a tool called systemctl (System Control), which can be used to interact with services.</p>\n<h3>Listing Services</h3>\n<p>The <code>list-units</code> command can be used to see everything being managed by systemctl.\nTo see the services specifically, which is what we are interested in here, we can use the <code>--type</code> option:</p>\n<pre><code class=\"bash\">sudo systemctl list-units --type service\n</code></pre>\n\n<h3>Starting a Service</h3>\n<p>Use the <code>start</code> command to start a service.\nThe service that has been configured will be started in the background:</p>\n<pre><code class=\"bash\"># sudo systemctl start [SERVICE_NAME]\nsudo systemctl start my-service\n</code></pre>\n\n<h3>Stopping a Service</h3>\n<p>Use the <code>stop</code> command to stop a service.\nThe process managed by systemd will be terminated for you:</p>\n<pre><code class=\"bash\"># sudo systemctl stop [SERVICE_NAME]\nsudo systemctl stop my-service\n</code></pre>\n\n<h3>Restarting a Service</h3>\n<p>Stop and then start a service.\nThis can be used if a new version of the service has been installed, or if configurations for the application have been updated:</p>\n<pre><code class=\"bash\"># sudo systemctl restart [SERVICE_NAME]\nsudo systemctl restart my-service\n</code></pre>\n\n<h3>Reloading a Service Configuration</h3>\n<p>Some services have the capability of reloading their configuration without needing to restart.\nThis is the preferred option (if it's available) because if the configurations are invalid, the service will continue to use the configuration that was already in place and continue running.\nLets say a new configuration was entered for a service, and the service was then restarted, the service could crash if the configuration is invalid; however, this could be avoided by using the reload command:</p>\n<pre><code class=\"bash\"># sudo systemctl reload [SERVICE_NAME]\nsudo systemctl reload my-service\n</code></pre>\n\n<h3>Enabling a Service</h3>\n<p>It's common to need a service to be running once the system turns on.\nWe can use the enable command to make a service run on start up:</p>\n<pre><code class=\"bash\"># sudo systemctl enable [SERVICE_NAME]\nsudo systemctl enable my-service\n</code></pre>\n\n<h4>Enable and Start</h4>\n<p>The <code>--now</code> option can also be used to start the service.\nYou can think of this as running the <code>start</code> and <code>enable</code> commands at the same time:</p>\n<pre><code class=\"bash\"># sudo systemctl enable --now [SERVICE_NAME]\nsudo systemctl enable --now my-service\n</code></pre>\n\n<h3>Disable a Service</h3>\n<p>This command may sound a little misleading, as it wont actuallly \"disable\" the service. It will actually just stop it running on startup (so the opposite of enabling a service):</p>\n<pre><code class=\"bash\"># sudo systemctl disable [SERVICE_NAME]\nsudo systemctl disable my-service\n</code></pre>\n\n<h3>Check the Service Status</h3>\n<p>To make sure everything is running well, you can check the status of your service using the <code>status</code> command:</p>\n<pre><code class=\"bash\"># sudo systemctl status [SERVICE_NAME]\nsudo systemctl status my-service\n</code></pre>\n\n<h2>Tasks</h2>\n<p>Here are some tasks that will give you a chance to use the commands shown above.\nNGINX will be used as an example for these commands; you don't need to fully understand what NGINX is, just that it's a web-server and, in this case, is managed as a systemd service.\nFor these tasks, its best to have a fresh install of Debian or Ubuntu</p>\n<h3>Install NGINX</h3>\n<p>We can use <code>apt</code> to get our NGINX server downloaded and configured as a systemd service. We'll also install curl, for getting a response from the NGINX server:</p>\n<pre><code class=\"bash\">sudo apt install -y nginx curl\n</code></pre>\n\n<h3>Check the Service Status</h3>\n<p>Make sure that NGINX is running by checking its status:</p>\n<pre><code class=\"bash\">sudo systemctl status nginx\n</code></pre>\n\n<h3>Stop the Service</h3>\n<p>First, lets get a response from the server:</p>\n<pre><code class=\"bash\">curl localhost\n</code></pre>\n\n<p>You should see a basic HTML (web page) response.\nNow, stop the service:</p>\n<pre><code class=\"bash\">sudo systemctl stop nginx\n</code></pre>\n\n<p>If we use curl to try and get a response from the server, it should fail:</p>\n<pre><code class=\"bash\">curl localhost\n</code></pre>\n\n<h3>Check the Service Status</h3>\n<p>We can now see that the service has been stopped, by checking its status:</p>\n<pre><code class=\"bash\">sudo systemctl status nginx\n</code></pre>\n\n<h3>Enable and Start the Service</h3>\n<p>Make sure that the NGINX service will run on startup by enabling it.\nThe service can be started back up at the same time too:</p>\n<pre><code class=\"bash\">sudo systemctl enable --now nginx\n</code></pre>\n\n<p>Check the status to see that the service is back up and running:</p>\n<pre><code class=\"bash\">sudo systemctl status nginx\n</code></pre>\n\n<h3>Make a Configuration Change</h3>\n<p>Edit the <code>/etc/nginx/nginx.conf</code> using <code>sudo</code>, or as the <code>root</code> user, and enter the following:</p>\n<pre><code class=\"nginx.conf\">events {}\nhttp {\n    server {\n        location / {\n            return 200 &quot;Reload Worked!\\n&quot;;\n        }\n    }\n}\n</code></pre>\n\n<p>Then, reload the NGINX service:</p>\n<pre><code class=\"bash\">sudo systemctl reload nginx\n</code></pre>\n\n<p>We can then check that the configration has taken effect on the server, by making a request to it (again using curl):</p>\n<pre><code class=\"bash\">curl localhost\n</code></pre>\n\n<p>The server should reply with <code>Reload Worked!</code></p>\n<h3>Cleanup</h3>\n<p>Undo the changes we made by running the following:</p>\n<pre><code class=\"bash\">sudo systemctl disable nginx \nsudo systemctl stop nginx\nsudo apt purge -y nginx\n</code></pre>"}, {"prereqs": ["linux/nano", "linux/vi"], "gitUri": "topics/linux/modules/sudoers", "overview": "The sudo tool allows a user to act as a superuser for a command.", "name": "Sudoers", "resourceName": "linux/sudoers", "content": "<!--PROPS\n{\n    \"prereqs\": [\n        \"linux/nano\",\n        \"linux/vi\"\n    ]\n}\n-->\n\n<h1>Sudoers</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#configuring-a-sudo-user\">Configuring a sudo User</a><ul>\n<li><a href=\"#run-sudo-commands-without-a-password\">Run sudo Commands Without a Password</a></li>\n<li><a href=\"#only-allow-specific-commands\">Only Allow Specific Commands</a></li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#create-a-jenkins-user\">Create a Jenkins User</a></li>\n<li><a href=\"#install-nginx\">Install NGINX</a></li>\n<li><a href=\"#configure-jenkins-as-sudo-user\">Configure Jenkins as sudo User</a></li>\n<li><a href=\"#check-the-basic-sudoers-configuration-works\">Check the Basic sudoers Configuration Works</a></li>\n<li><a href=\"#configure-sudoers-to-only-manage-nginx\">Configure sudoers to Only Manage NGINX</a></li>\n<li><a href=\"#check-the-more-advanced-configuration-works\">Check the More Advanced Configuration Works</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>The sudo tool allows a user to act as a superuser for a command.\nWhen you run a command as sudo, it's like running an application as administrator on a Windows machine.\nOf course, only certain users can run a sudo command on a Linux machine (otherwise everyone would have administritive access!).\nUsers who can use sudo are configured in the <code>/etc/sudoers</code> file.\nThis file is extremely important and <strong>should not be edited directly</strong>.\nIf the sudoers file is broken, no one on the system can use sudo commands!\nThere is a tool called <code>visudo</code>, which can be used to edit the file safely.\nWhen you save the file using <code>visudo</code>, the syntax will be checked first to make sure the file isn't currupt.</p>\n<h2>Configuring a sudo User</h2>\n<p>To edit the <code>/etc/sudoers</code> file, we can run <code>sudo visudo</code> (or just <code>visudo</code> if  you are the <code>root</code> user).\nAn entry can be made into the sudoers file using the following format:\n<img alt=\"Sudoers Entry\" src=\"https://i.imgur.com/qMdXw1h.png\" /></p>\n<h3>Run sudo Commands Without a Password</h3>\n<p>By default, a sudo user needs to enter their password when running a command as sudo.\nHowever, this can be an issue if the commands are being run in a script.\nTo get around this, a sudo user can be configured to use sudo without a password:</p>\n<pre><code class=\"text\"># allow the user bob to run any command as sudo without a password\nbob ALL=(ALL:ALL) NOPASSWD:ALL\n</code></pre>\n\n<h3>Only Allow Specific Commands</h3>\n<p>Allowing all commands for a user basically just makes them a proxy root user, which often isn't what a system administrator would want.\nWe can allow the user to only run specific commands; for example, a Jenkins user might only need to be able to manage a systemd service, like so:</p>\n<pre><code class=\"text\">jenkins ALL=(ALL:ALL) NOPASSWD:\\\n    /bin/systemctl start nginx,\\\n    /bin/systemctl stop nginx,\\\n    /bin/systemctl status nginx\n</code></pre>\n\n<p>Make sure that you include the full path to the binaries that you are using.\nFor instance, the <code>systemctl</code> command's full path is <code>/bin/systemctl</code>.\nTo find the location of an application, you can use the <code>type</code> command:</p>\n<pre><code class=\"bash\">type systemctl \n# /bin/systemctl\n</code></pre>\n\n<h2>Tasks</h2>\n<p>These tasks will take you through configuring a <code>jenkins</code> user to manage a systemd service without using a password.\nTo manage a systemd service, you must be able to use the <code>systemctl</code> command; this requires elevated permissions (sudo).</p>\n<h3>Create a Jenkins User</h3>\n<p>For this example, we need a Jenkins user:</p>\n<pre><code class=\"bash\">sudo useradd -m -s /bin/bash jenkins\n</code></pre>\n\n<h3>Install NGINX</h3>\n<p>NGINX is going to be a systemd service that we will use as an example here.\nInstall NGINX using your relevant package manager:</p>\n<pre><code class=\"bash\"># for ubuntu/debian use this:\nsudo apt install -y nginx\n# for centos/rhel use this:\nsudo yum install -y nginx\n</code></pre>\n\n<h3>Configure Jenkins as sudo User</h3>\n<p>To keep things simple, let's allow Jenkins to run all commands with sudo.\nStart editing the <code>/etc/sudoers</code> file, by running <code>sudo visudo</code>, then enter the following into the file:</p>\n<pre><code class=\"text\">jenkins ALL=(ALL:ALL) NOPASSWD:ALL\n</code></pre>\n\n<h3>Check the Basic sudoers Configuration Works</h3>\n<p>Let's see if it worked, by switching to the Jenkins user and running a command with sudo:</p>\n<pre><code class=\"bash\">sudo su - jenkins\nsudo echo &quot;Hello I'm jenkins using sudo!&quot;\nexit\n</code></pre>\n\n<h3>Configure sudoers to Only Manage NGINX</h3>\n<p>We can now be more specific with our sudoers configuration, by only allowing the <code>jenkins</code> user to stop, start and check the status of the NGINX systemd service.\nTo understand what to put in the sudoers file, let's see what commands <code>jenkins</code> will need to be able to run:</p>\n<pre><code class=\"bash\">sudo systemctl start nginx\nsudo systemctl stop nginx\nsudo systemctl status nginx\n</code></pre>\n\n<p>So, jenkins will need to be able to execute the <code>systemctl</code> command.\nIn the sudoers file, we will need to include the full path of this binary; to do that, we can use the <code>type</code> command to find out where it is on the filesystem:</p>\n<pre><code class=\"bash\">type systemctl\n</code></pre>\n\n<p>Now we know the entries in the sudoers file are going to have to look more like the following:</p>\n<pre><code class=\"bash\">/bin/systemctl start nginx\n/bin/systemctl stop nginx\n/bin/systemctl status nginx\n</code></pre>\n\n<p>Now we can run <code>sudo  visudo</code> and change the entry for jenkins to be like this:</p>\n<pre><code class=\"text\">jenkins ALL=(ALL:ALL) NOPASSWD:\\\n    /bin/systemctl start nginx,\\\n    /bin/systemctl stop nginx,\\\n    /bin/systemctl status nginx\n</code></pre>\n\n<h3>Check the More Advanced Configuration Works</h3>\n<p>We can check the new sudoers entry works by switching to jenkins user and running the commands we entered:</p>\n<pre><code class=\"bash\">sudo su - jenkins\nsudo systemctl stop nginx\nsudo systemctl start nginx\nsudo systemctl status nginx\nexit\n</code></pre>"}]}, {"gitUri": "topics/aws", "overview": "Amazon Web Services (AWS) is the world\u2019s most comprehensive and broadly adopted cloud platform, offering over 165 fully featured services from data centers globally. Millions of customers \u2014including the fastest-growing startups, largest enterprises, and leading government agencies\u2014trust AWS to power their infrastructure, become more agile, and lower costs.", "name": "Amazon Web Services (AWS)", "resourceName": "aws", "modules": [{"gitUri": "topics/aws/modules/vpc-internet-gateways", "overview": "An internet gateway is a horizontally scaled, redundant, and highly available VPC component that allows communication between instances in your VPC and the internet.", "name": "EC2 VPC Internet Gateways", "resourceName": "aws/vpc-internet-gateways", "content": "<h1>EC2 VPC Internet Gateways</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#allowing-your-ec2-instances-internet-access\">Allowing Your EC2 Instances Internet Access</a></li>\n<li><a href=\"#creating-an-internet-gateway\">Creating an Internet Gateway</a><ul>\n<li><a href=\"#basic-usage\">Basic Usage</a></li>\n</ul>\n</li>\n<li><a href=\"#attaching-an-internet-gateway-to-a-vpc\">Attaching an Internet Gateway to a VPC</a><ul>\n<li><a href=\"#basic-usage-1\">Basic Usage</a></li>\n</ul>\n</li>\n<li><a href=\"#view-existing-internet-gateways\">View Existing Internet Gateways</a></li>\n<li><a href=\"#detaching-internet-gateways\">Detaching Internet Gateways</a></li>\n<li><a href=\"#deleting-internet-gateways\">Deleting Internet Gateways</a></li>\n<li><a href=\"#tasks\">Tasks</a></li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>An internet gateway is a horizontally scaled, redundant, and highly available VPC component that allows communication between instances in your VPC and the internet.\nIt therefore imposes no availability risks or bandwidth constraints on your network traffic.</p>\n<p>An internet gateway serves two purposes: to provide a target in your VPC route tables for internet-routable traffic, and to perform network address translation (NAT) for instances that have been assigned public IPv4 addresses.</p>\n<p>An internet gateway supports IPv4 and IPv6 traffic.</p>\n<h2>Allowing Your EC2 Instances Internet Access</h2>\n<p>To enable access to or from the internet for instances in a VPC subnet, you must do the following:\n- Attach an internet gateway to your VPC.\n- Ensure that your subnet's route table points to the internet gateway.\n- Ensure that instances in your subnet have a globally unique IP address (public IPv4 address, Elastic IP address, or IPv6 address).\n- Ensure that your network access control and security group rules allow the relevant traffic to flow to and from your instance.</p>\n<p>To use an internet gateway, your subnet's route table must contain a route that directs internet-bound traffic to the internet gateway.\nYou can scope the route to all destinations not explicitly known to the route table (0.0.0.0/0 for IPv4 or ::/0 for IPv6), or you can scope the route to a narrower range of IP addresses; for example, the public IPv4 addresses of your company\u2019s public endpoints outside of AWS, or the Elastic IP addresses of other Amazon EC2 instances outside your VPC.\nIf your subnet is associated with a route table that has a route to an internet gateway, it's known as a public subnet.</p>\n<p>To enable communication over the internet for IPv4, your instance must have a public IPv4 address or an Elastic IP address that's associated with a private IPv4 address on your instance.\nYour instance is only aware of the private (internal) IP address space defined within the VPC and subnet.\nThe internet gateway logically provides the one-to-one NAT on behalf of your instance, so that when traffic leaves your VPC subnet and goes to the internet, the reply address field is set to the public IPv4 address or Elastic IP address of your instance, and not its private IP address.\nConversely, traffic that's destined for the public IPv4 address or Elastic IP address of your instance has its destination address translated into the instance's private IPv4 address before the traffic is delivered to the VPC.</p>\n<h2>Creating an Internet Gateway</h2>\n<h3>Basic Usage</h3>\n<p>Creating an Internet Gateway is very simple, as no parameters are required:</p>\n<pre><code class=\"bash\">aws ec2 create-internet-gateway \n</code></pre>\n\n<h2>Attaching an Internet Gateway to a VPC</h2>\n<h3>Basic Usage</h3>\n<p>You must have an existing VPC to attach the internet gateway to.\nTo attach an Internet Gateway to a VPC, you must provide the IDs for both the VPC and the Internet Gateway:</p>\n<pre><code class=\"bash\"># aws ec2 attach-internet-gateway --internet-gateway-id [INTERNET_GATEWAY_ID] --vpc-id [VPC_ID]\naws ec2 attach-internet-gateway --internet-gateway-id igw-0a831f55f06387254 --vpc-id vpc-05207b1e60ee695c5\n</code></pre>\n\n<h2>View Existing Internet Gateways</h2>\n<p>We can use the <code>describe-internet-gateways</code> command to see the existing Internet Gateways.\nThis will also give us useful information, such as their IDs and the VPCs that they are attached to:</p>\n<pre><code class=\"bash\">aws ec2 describe-internet-gateways\n</code></pre>\n\n<h2>Detaching Internet Gateways</h2>\n<p>Before you can delete an Internet Gateway, it must be detached. If you don't do this, you will get an error stating that the IG has dependencies that can't be deleted.\nDetaching an Internet Gateway can be done by providing the Internet Gateway ID and the ID of the VPC that it is attached to:</p>\n<pre><code class=\"bash\"># aws ec2 detach-internet-gateway --internet-gateway-id [INTERNET_GATEWAY_ID] --vpc-id [VPC_ID]\naws ec2 detach-internet-gateway --internet-gateway-id igw-0a831f55f06387254 --vpc-id vpc-05207b1e60ee695c5\n</code></pre>\n\n<h2>Deleting Internet Gateways</h2>\n<p>An Internet Gateway can be deleted by providing the ID of the Internet Gateway:</p>\n<pre><code class=\"bash\"># aws ec2 delete-internet-gateway --internet-gateway-id [INTERNET_GATEWAY_ID]\naws ec2 delete-internet-gateway --internet-gateway-id igw-0a831f55f06387254\n</code></pre>\n\n<h2>Tasks</h2>\n<p>Try to complete the following tasks:\n- Create a VPC\n- Create an Internet Gateway\n- Attach the new Internet Gateway to the VPC that you created\n- View information about the Internet Gateway, does it say that it is attached to a VPC?\n- Detach the Internet Gateway\n- Delete the VPC and Internet Gateway that you created</p>\n<p><a href=\"../README.md#tasks\">Return to VPC Tasks</a></p>"}, {"gitUri": "topics/aws/modules/ec2-key-pairs", "overview": "", "name": "Overview", "resourceName": "aws/ec2-key-pairs", "content": "<h1>Overview</h1>\n<p>Key Pairs in EC2 can be used for securely connecting to EC2 instances in AWS.\nConnections are usually over SSH, which uses public and private keys.\nThis handout discusses how to manage these Key Pairs, and how to locally store the private keys that are generated.</p>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#creating-key-pairs\">Creating Key Pairs</a><ul>\n<li><a href=\"#basic-usage\">Basic Usage</a></li>\n<li><a href=\"#the-private-key\">The Private Key</a></li>\n<li><a href=\"#locally-storing-the-private-key\">Locally Storing the Private Key</a></li>\n<li><a href=\"#private-key-permissions\">Private Key Permissions</a></li>\n</ul>\n</li>\n<li><a href=\"#deleting-key-pairs\">Deleting Key Pairs</a>\n        - <a href=\"#basic-usage-1\">Basic Usage</a></li>\n<li><a href=\"#tasks\">Tasks</a></li>\n</ul>\n<!--TOC_END-->\n\n<h2>Creating Key Pairs</h2>\n<h3>Basic Usage</h3>\n<p>The create-key-pair command can be used to create our key pair. We specify the name of the Key Pair so that it can be easily referenced later on, such as when we want to add a key pair to an EC2 instance:</p>\n<pre><code class=\"bash\"># aws ec2 create-key-pair --key-name [KEY_PAIR_NAME]\naws ec2 create-key-pair --key-name MyKeyPair\n</code></pre>\n\n<h3>The Private Key</h3>\n<p>Once a new Key Pair has been created, the AWS CLI will print out the private key, along with some other information about the Key Pair.\nThe private key is what we can use on the client side, to authenticate with an EC2 instance.</p>\n<p>Here is an example output when creating a new key pair:</p>\n<pre><code>{\n    &quot;KeyFingerprint&quot;: &quot;69:bc:f4:ae:0e:ab:98:cb:6d:b7:ec:32:58:3a:00:82:c0:46:c7:c0&quot;,\n    &quot;KeyMaterial&quot;: &quot;-----BEGIN RSA PRIVATE KEY-----\\nMIIEpAIBAAKCAQEAmJuYixAl4YlYRIVQxZUZ+Fb0vZpRFG342ju8AuY90npucDFyzMfTBhprMrKK\\nM3zXhUCkXCdciza2qIQF4UZEJItmPt7hDhnaFy7R12Ta9Av2xBZZCXnNijeaFzGxgI8Yk42VxLLZ\\n9Tlm1hKq7x+aVVfjQQkrJVUM4NN5z7skyHM7B+9mW8uVSnamtGTyVo1lUQcrcc+YN2iKElAFiQ6u\\nIKndmtjg9ufIYBkx631sSBAuNHaPpAITpaYfr/E+ecz0BekHyGHgKUmmFh6Rklia+kxttJYfSJfR\\nxLvOwIwyj+knRAJ2VyWsX1TfxZ6aYBdW2n2NQ8ym5p2WMPsxAwO3kQIDAQABAoIBAEXJkd62Sbxz\\n5IuhM6jHYJLyoQU71qwzBkQ2YOoqhEcGeg6QbmE7WENIPZF3mD+nbZ+gSglibq2zHaC+jznPukXE\\nAcPqhJzAMb28SXXox0AnYHeXiKwOqXH1r1+/995EkgaYDs9ewtGjqGVpMAYeO6Ofh2ssWDDATh1a\\nWDAo8s8/ODQb4c1ewkFNxAwEV5m5bAcF2pG5/TUDt8ctV3RZCHEHryoNKWN44L3Yi7OqJjBGStQT\\nKLSiwItmDi0+CNyl43sPqW6BjDc5VY79LNOFgbwIqv+Bxt7uDIrhUfXPIAsdgdeU0ktHw+lbK0fZ\\nUtlWmJog9o28+qwCZNSLl46SkAECgYEA/sGKtt73VEwpWHl9BDBjVblSurWzikRm7nsh1wqIoVDE\\nnpL/3xq0OikS9SwlQTGvJckslGOsHiycz3LZWUjoIGuFtCaSRceFdaArJfQpESFBhr8Xgxi/7W8W\\nQjkMpD/S33WVq0J3dTZOkDl3HqnHQAdmlxyBg+GnAYtwG6BiDxECgYEAmVpdDMES65dWiU68pLA5\\n987nSPwIPxcy55sIIXZEnM98Ajb6naQ3NanmzptQ6LJDn1EVJt4tW5khshDydsF7+4UKZsxxkWOm\\nQHuH7lY54WfteaN4B5Ydqp4iWwuL3+K834AxXCe2GRVRXw0DBUPOIjI3OhbuZxb12yBNs2Q4IIEC\\ngYEAmhfFaNG69qFOzPZHOTZvj1WWhdsMK1EulYejM2hqtnCdTXGLFY8YfqmDjwrRyfpcf9WMgoE7\\nhdDkVNKaR1hDGAERkaNXDKAfyMNF9iIWiQb9lJyXgzOAPATaiNnrHJqCWanNCxccHKjponEv7Tsy\\nizcuxa53ZKckFloaSIudZJECgYEAiuT7bjfZSSSTLl3wIkGy3y248bPETFBYvMj//j6+OkD6ko71\\nQp6fmq097VdjWr9K3Bt2SvPkpRf3Gu6ajNEF2HNRTnZRTluxEqpQHaBfYDbfMdLLPiPKzuPXPhsh\\nHzCf3Nag3lTha6qRPsPsPnKBWxucRbLLTvfOyh9iAN7+rwECgYB4hFe+i5ioxP+SC6cr0kMlZ92n\\nu3nscQO5Q3DFZY4w5s6C9qI/rqd2FOtvLwxokF6u/tpQRCc0crLGhaJUvXYqKABkS6tTKmSGY/ro\\nuQRyT9Xu9DMGKzzHXp/fTEBHZxATPLLzJRpnupgvFKryhEHKVv9zN7LJXe/ojUplB+RY0A==\\n-----END RSA PRIVATE KEY-----&quot;,\n    &quot;KeyName&quot;: &quot;MyKeyPair&quot;\n}\n</code></pre>\n\n<h3>Locally Storing the Private Key</h3>\n<p>It is important that we save the private key somewhere, because we will not be able to gain access to it again.\nTo do this, we can add a query to our command that gets the <code>KeyMaterial</code> property when the key information is returned. We can then specify that we would like a text output, and then redirect the output to a file for the key to be stored in.</p>\n<p><strong>Make sure that you do not put your key somewhere publicly accessible, such as a GitHub repository</strong></p>\n<pre><code class=\"bash\"># aws ec2 create-key-pair --key-name [KEY_PAIR_NAME] --query [QUERY] --output [OUTPUT_TYPE]\naws ec2 create-key-pair --key-name MyKeyPair --query \u2018KeyMaterial\u2019 --output text &gt; ~/.ssh/MyKeyPair.pem\n</code></pre>\n\n<h3>Private Key Permissions</h3>\n<p>When storing a private key, it is important that only you, as the owner, can read it. Make sure you change the file permissions to allow this:</p>\n<pre><code class=\"bash\">chmod 400 ~/.ssh/MyKeyPair.pem\n</code></pre>\n\n<h2>Deleting Key Pairs</h2>\n<h4>Basic Usage</h4>\n<p>Deleting key pairs is very easy - just be 100% sure that you want to delete them!</p>\n<p>Provide the name of the Key Pair to delete it:</p>\n<pre><code class=\"bash\"># aws ec2 delete-key-pair --key-name [KEY_PAIR_NAME]\naws ec2 delete-key-pair --key-name MyKeyPair\n</code></pre>\n\n<h2>Tasks</h2>\n<p>Try to complete the following tasks:\n- Create a new key pair called <code>MyKeyPair</code>, and make sure the value of the key gets saved to a file: <code>~/ssh/MyKeyPair.pem</code>\n- Verify the key has been saved properly by viewing the contents of the file\n- Delete the key pair that you created and also the file that you saved</p>\n<p><a href=\"../README.md#tasks\">Go Back</a></p>"}, {"gitUri": "topics/aws/modules/ec2-instances", "overview": "An EC2 instance is a virtual server in Amazon\u2019s Elastic Compute Cloud (EC2) for running applications on the Amazon Web Services (AWS) infrastructure.", "name": "AWS EC2 Instances", "resourceName": "aws/ec2-instances", "content": "<h1>AWS EC2 Instances</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#amazon-machine-images-amis\">Amazon Machine Images (AMIs)</a><ul>\n<li><a href=\"#overview-1\">Overview</a></li>\n<li><a href=\"#viewing-available-amis\">Viewing Available AMIs</a></li>\n</ul>\n</li>\n<li><a href=\"#running-an-instance\">Running an Instance</a><ul>\n<li><a href=\"#basic-usage\">Basic Usage</a></li>\n</ul>\n</li>\n<li><a href=\"#view-running-instances\">View Running Instances</a><ul>\n<li><a href=\"#basic-usage-1\">Basic Usage</a></li>\n</ul>\n</li>\n<li><a href=\"#terminate-a-running-instance\">Terminate a Running Instance</a><ul>\n<li><a href=\"#basic-usage-2\">Basic Usage</a></li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a></li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>An EC2 instance is a virtual server in Amazon\u2019s Elastic Compute Cloud (EC2) for running applications on the Amazon Web Services (AWS) infrastructure.</p>\n<p>AWS is a comprehensive, evolving cloud computing platform; EC2 is a service that allows business subscribers to run application programs in the computing environment. The EC2 can serve as a practically unlimited set of virtual machines. </p>\n<p>Amazon provides a variety of types of instances with different configurations of CPU, memory, storage, and networking resources to suit user needs. Each type is also available in two different sizes to address workload requirements.</p>\n<p>Instance types are grouped into families based on target application profiles. These groups include: general purpose, compute-optimized, GPU instances, memory optimized, storage optimized and micro instances.</p>\n<h2>Amazon Machine Images (AMIs)</h2>\n<h3>Overview</h3>\n<p>Instances are created from Amazon Machine Images (AMI).\nThe machine images are like templates that are configured with an operating system and other software, which determine the user\u2019s operating environment.\nUsers can select an AMI provided by AWS, the user community, or through the AWS Marketplace.\nUsers can also create their own AMIs and share them.</p>\n<h3>Viewing Available AMIs</h3>\n<p>We need to provide an AMI when running an instance; Amazon has a page with commands for finding the latest image for popular operating systems: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/finding-an-ami.html. Please note that you will need <code>jq</code> installed to run the commands provided.\nHere is an example that gets the latest <code>ubuntu 18.04</code> image id (AMI):</p>\n<pre><code class=\"bash\">aws ec2 describe-images --owners 099720109477 --filters 'Name=name,Values=ubuntu/images/hvm-ssd/ubuntu-bionic-18.04-amd64-server-????????' 'Name=state,Values=available' --output json | jq -r '.Images | sort_by(.CreationDate) | last(.[]).ImageId'\n</code></pre>\n\n<h2>Running an Instance</h2>\n<h3>Basic Usage</h3>\n<p>Running an instance requires quite a few options:\n- <strong>Image ID:</strong>\n    This is the base image that the machine will use, and it usually comes with an operating system install, such as Ubuntu.\n- <strong>Count:</strong>\n    The amount of instances to run from this command\n- <strong>Instance Type:</strong>\n    The size of the machine, how many CPUs and how much RAM\n- <strong>Key Name:</strong>\n    The Key Pair to install onto the machine. We need this to be able to securely connect to the instance with SSH.\n- <strong>Subnet ID:</strong>\n    Which subnet to run the instance in. The instance will be given a private IP address, from the subnet that you put it in, and security group rules from the VPC will be applied to the instance.</p>\n<pre><code class=\"bash\"># aws ec2 run-instances --image-id [IMAGE_ID] --count [AMOUNT_OF_INSTANCES] --instance-type [MACHINE_SIZE] --key-name [KEY_PAIR_NAME] --subnet-id [SUBNET_ID]\naws ec2 run-instances --image-id ami-0ee246e709782b1be --count 1 --instance-type t2.micro --key-name MyKeyPair --subnet-id subnet-0b601356c0674d00d\n</code></pre>\n\n<h2>View Running Instances</h2>\n<h3>Basic Usage</h3>\n<p>To check what existing instances there are, we can use the <code>describe-instances</code> command:</p>\n<pre><code class=\"bash\">aws ec2 describe-instances\n</code></pre>\n\n<h2>Terminate a Running Instance</h2>\n<h3>Basic Usage</h3>\n<p>We can terminate instances by providing their IDs to the <code>terminate-instances</code> command:</p>\n<pre><code class=\"bash\"># aws ec2 terminate-instances --instance-ids [INSTANCE_IDS]\naws ec2 terminate-instances --instance-ids i-1234567890abcdef0\n</code></pre>\n\n<h2>Tasks</h2>\n<ul>\n<li>Create and configure a VPC with the following:<ul>\n<li>CIDR Block of 10.0.0.0/16</li>\n<li>Associated Internet Gateway</li>\n<li>Route Table configured for Internet Access</li>\n<li>Subnet with a CIDR block of 10.0.1.0/24</li>\n<li>Security Group that allows SSH access from anywhere</li>\n</ul>\n</li>\n<li>Create a Key Pair called MyKeyPair, and store the private key into <code>~/.ssh/MyKeyPair.pem</code></li>\n<li>Run an EC2 instance with the following:<ul>\n<li>AMI of your choice</li>\n<li>The Key Pair you created</li>\n<li>and put it in the Subnet that you created</li>\n</ul>\n</li>\n<li>Connect to your EC2 instance using SSH and the private key that you stored</li>\n</ul>\n<p><a href=\"../README.md#tasks\">Go Back</a></p>"}, {"gitUri": "topics/aws/modules/vpc-introduction", "overview": "Amazon Virtual Private Cloud (Amazon VPC) lets you provision a logically isolated section of the AWS Cloud where you can launch AWS resources in a virtual network that you define.", "name": "Virtual Private Cloud (VPC)", "resourceName": "aws/vpc-introduction", "content": "<h1>Virtual Private Cloud (VPC)</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#creating-a-vpc\">Creating a VPC</a><ul>\n<li><a href=\"#basic-usage\">Basic Usage</a></li>\n<li><a href=\"#cidr-blocks--limitations\">CIDR Blocks &amp; Limitations</a></li>\n</ul>\n</li>\n<li><a href=\"#view-existing-vpcs\">View Existing VPCs</a><ul>\n<li><a href=\"#basic-usage-1\">Basic Usage</a></li>\n<li><a href=\"#getting-the-id-property-using-queries\">Getting the ID Property Using Queries</a></li>\n</ul>\n</li>\n<li><a href=\"#delete-vpcs\">Delete VPCs</a><ul>\n<li><a href=\"#basic-usage-2\">Basic Usage</a></li>\n<li><a href=\"#creating-a-default-vpc\">Creating a Default VPC</a></li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a><ul>\n<li><a href=\"#managing-a-simple-vpc\">Managing a Simple VPC</a><ul>\n<li><a href=\"#create-a-new-vpc-with-a-cidr-block-of-1000016\">Create a new VPC with a CIDR block of <code>10.0.0.0/16</code></a></li>\n<li><a href=\"#delete-a-vpc-using-id\">Delete a VPC using ID</a></li>\n<li><a href=\"#storing-a-vpcs-id-in-a-bash-variable\">Storing a VPC's ID in a Bash Variable</a></li>\n<li><a href=\"#using-a-bash-variable-to-delete-a-vpc\">Using a Bash Variable to Delete a VPC</a></li>\n<li><a href=\"#make-sure-that-there-are-none-of-the-vpcs-we-created-here-are-left-and-move-on-to-the-next-section\">Make sure that there are none of the VPCs we created here are left and move on to the next section:</a></li>\n</ul>\n</li>\n<li><a href=\"#learn-how-to-fully-configure-a-vpc\">Learn how to Fully Configure a VPC</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>Amazon Virtual Private Cloud (Amazon VPC) lets you provision a logically isolated section of the AWS Cloud where you can launch AWS resources in a virtual network that you define.\nYou have complete control over your virtual networking environment, including selection of your own IP address range, creation of subnets, and configuration of route tables and network gateways.\nYou can use both IPv4 and IPv6 in your VPC for secure and easy access to resources and applications.</p>\n<p>You can easily customize the network configuration for your Amazon VPC.\nFor example, you can create a public-facing subnet for your web servers that has access to the Internet, and place your backend systems such as databases or application servers in a private-facing subnet with no Internet access.\nYou can leverage multiple layers of security, including security groups and network access control lists, to help control access to Amazon EC2 instances in each subnet.</p>\n<h2>Creating a VPC</h2>\n<h3>Basic Usage</h3>\n<p>VPCs can be created very easily - you should only have to provide the CIDR block, which defines the address range for your subnet:</p>\n<pre><code class=\"bash\"># aws ec2 create-vpc --cidr-block [CIDR_DEFINITION]\naws ec2 create-vpc --cidr-block 10.0.0.0/16\n</code></pre>\n\n<h3>CIDR Blocks &amp; Limitations</h3>\n<p>The CIDR block is what defines the size of your network.\nThe smallest CIDR block you can have is /28, with 16 hosts, or /16, which can have up to 65,536 hosts.</p>\n<h2>View Existing VPCs</h2>\n<h3>Basic Usage</h3>\n<p>You may want to view the existing VPCs to view the properties of them:</p>\n<pre><code class=\"bash\">aws ec2 describe-vpcs\n</code></pre>\n\n<h3>Getting the ID Property Using Queries</h3>\n<p>To manage a VPC, such as when you want to delete it, you will need to be able to reference that VPC by its ID.\nIf you have several VPCs then the output can be a little overwhelming, considering that you just want to see the IDs.\nWe can use a query, like the one below, and change the output to be text only; this will return a list of VPC IDs:</p>\n<pre><code class=\"bash\"># aws ec2 describe-vpcs --output [OUTPUT_TYPE] --query [JSON_QUERY]\naws ec2 describe-vpcs --output text --query &quot;Vpcs[].VpcId&quot;\n</code></pre>\n\n<h2>Delete VPCs</h2>\n<h3>Basic Usage</h3>\n<p>The VPC ID must be provided when deleting a VPC:</p>\n<pre><code class=\"bash\"># aws ec2 delete-vpc --vpc-id [VPC_ID]\naws ec2 delete-vpc --vpc-id vpc-061635ad5414cf433\n</code></pre>\n\n<h3>Creating a Default VPC</h3>\n<p>A default VPC is suitable for getting started quickly, and for launching public instances such as a blog or simple website. You can modify the components of your default VPC as needed.\nOther resources that are needed to get EC2 instances functional are already in place such as an Internet Gateway, DHCP Options Set, Subnets and Security Groups.</p>\n<p>If, for whatever reason, you have deleted your default VPC, it's easy to create another one:</p>\n<pre><code class=\"bash\">aws ec2 create-default-vpc\n</code></pre>\n\n<h2>Tasks</h2>\n<h3>Managing a Simple VPC</h3>\n<p>Try to complete the following tasks, using the commands you learned above:</p>\n<h4>Create a new VPC with a CIDR block of <code>10.0.0.0/16</code></h4>\n<p>This example creates a VPC network that can have up to 65,536 hosts:</p>\n<pre><code class=\"bash\">aws ec2 create-vpc --cidr-block 10.0.0.0/16\n</code></pre>\n\n<h4>Delete a VPC using ID</h4>\n<p>We can then delete the VPC using its ID; just replace <code>[VPC_ID]</code> in the command below with the ID of your VPC you just created:</p>\n<pre><code class=\"bash\">aws ec2 delete-vpc --vpc-id [VPC_ID]\n</code></pre>\n\n<h4>Storing a VPC's ID in a Bash Variable</h4>\n<pre><code class=\"bash\">vpc_id=$(aws ec2 create-vpc --cidr-block 10.0.0.0/16 --query Vpc.VpcId --output text)\necho ${vpc_id}\n</code></pre>\n\n<p>You wil now be able to access the <code>vpc_id</code> variable in other parts of the script you are writing.</p>\n<h4>Using a Bash Variable to Delete a VPC</h4>\n<pre><code class=\"bash\">aws ec2 delete-vpc --vpc-id ${vpc_id}\n</code></pre>\n\n<h4>Make sure that there are none of the VPCs we created here are left and move on to the next section:</h4>\n<pre><code class=\"bash\">aws ec2 describe-vpcs\n</code></pre>\n\n<h3>Learn how to Fully Configure a VPC</h3>\n<p>Unless you create a default VPC, there are several other components to understand and configure:\n- Learn about <a href=\"./subnets\">Subnets</a>\n- Learn about <a href=\"./internet-gateways\">Internet Gateways</a>\n- Learn about <a href=\"./route-tables\">Route Tables</a>\n- Learn about <a href=\"./security-groups\">Security Groups</a></p>\n<p><a href=\"../README.md#tasks\">Go Back</a></p>"}, {"gitUri": "topics/aws/modules/vpc-subnets", "overview": "", "name": "EC2 VPC Subnets", "resourceName": "aws/vpc-subnets", "content": "<h1>EC2 VPC Subnets</h1>\n<p>A VPC spans all the Availability Zones in the region.\nAfter creating a VPC, you can add one or more subnets in each Availability Zone.\nWhen you create a subnet, you specify the CIDR block for the subnet, which is a subset of the VPC CIDR block.\nEach subnet must reside entirely within one Availability Zone and cannot span zones.\nAvailability Zones are distinct locations that are engineered to be isolated from failures in other Availability Zones.\nBy launching instances in separate Availability Zones, you can protect your applications from the failure of a single location.\nWe assign a unique ID to each subnet.</p>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#creating-subnets\">Creating Subnets</a><ul>\n<li><a href=\"#basic-usage\">Basic Usage</a></li>\n</ul>\n</li>\n<li><a href=\"#view-existing-subnets\">View Existing Subnets</a><ul>\n<li><a href=\"#basic-usage-1\">Basic Usage</a></li>\n<li><a href=\"#getting-the-id-property-using-queries\">Getting the ID Property Using Queries</a></li>\n</ul>\n</li>\n<li><a href=\"#delete-subnets\">Delete Subnets</a><ul>\n<li><a href=\"#basic-usage-2\">Basic Usage</a></li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a></li>\n</ul>\n<!--TOC_END-->\n\n<h2>Creating Subnets</h2>\n<h3>Basic Usage</h3>\n<p>After you create a subnet, you can't change its CIDR block.\nThe size of the subnet's IPv4 CIDR block can be the same as a VPC's IPv4 CIDR block, or a subset of a VPC's IPv4 CIDR block.\nIf you create more than one subnet in a VPC, the subnets' CIDR blocks must not overlap.\nThe smallest IPv4 subnet (and VPC) you can create uses a /28 netmask (16 IPv4 addresses), and the largest uses a /16 netmask (65,536 IPv4 addresses).</p>\n<p>When you create each subnet, you provide the VPC ID and IPv4 CIDR block for the subnet:</p>\n<pre><code class=\"bash\"># aws ec2 create-subnet --vpc-id [VPC_ID] --cidr-block [CIDR_BLOCK]\naws ec2 create-subnet --vpc-id vpc-081ec835f3EXAMPLE --cidr-block 10.0.1.0/24\n</code></pre>\n\n<h2>View Existing Subnets</h2>\n<h3>Basic Usage</h3>\n<p>You may want to view the existing Subnets to view the properties of them:</p>\n<pre><code class=\"bash\">aws ec2 describe-subnets\n</code></pre>\n\n<h3>Getting the ID Property Using Queries</h3>\n<p>To manage a Subnet, such as when you want to delete it, you will need to be able to reference that Subnet by its ID.\nIf you have several Subnets, the output can be a little overwhelming, considering that you just want to see the IDs.\nWe can use a query, like the one below, and change the output to be text only; this will return a list of Subnet IDs:</p>\n<pre><code class=\"bash\"># aws ec2 describe-subnets --output text --query Subnets[].SubnetId\naws ec2 describe-subnets --output text --query Subnets[].SubnetId\n</code></pre>\n\n<h2>Delete Subnets</h2>\n<h3>Basic Usage</h3>\n<p>The Subnet ID must be provided when deleting a Subnet:</p>\n<pre><code class=\"bash\"># aws ec2 delete-subnet --subnet-id [SUBNET_ID]\naws ec2 delete-subnet --subnet-id subnet-04c9613a521b24db0\n</code></pre>\n\n<h2>Tasks</h2>\n<p>Try to complete the following tasks using the commands you learned above:\n- Create a new VPC with a CIDR block of 10.0.0.0/16\n- Create a new Subnet inside the VPC you made, with a CIDR block of 10.0.1.0/24\n- Create another Subnet inside the same VPC, with a CIDR block of 10.0.2.0/24\n- List the Subnets you have, showing only the IDs of them\n- Delete the VPC and Subnets that you created.</p>\n<p><a href=\"../README.md#tasks\">Go Back to VPC Tasks</a></p>"}, {"gitUri": "topics/aws/modules/vpc-security-groups", "overview": "A security group acts as a virtual firewall for your instance to control inbound and outbound traffic.", "name": "EC2 VPC Security Groups", "resourceName": "aws/vpc-security-groups", "content": "<h1>EC2 VPC Security Groups</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#security-group-basics\">Security Group basics</a></li>\n<li><a href=\"#creating-security-groups\">Creating Security Groups</a></li>\n<li><a href=\"#listing-security-groups\">Listing Security Groups</a><ul>\n<li><a href=\"#basic-usage\">Basic Usage</a></li>\n<li><a href=\"#filtering-out-security-groups-by-name\">Filtering Out Security Groups by Name</a></li>\n</ul>\n</li>\n<li><a href=\"#security-group-rules\">Security Group Rules</a><ul>\n<li><a href=\"#overview-1\">Overview</a></li>\n<li><a href=\"#basic-usage-1\">Basic Usage</a></li>\n<li><a href=\"#example-for-allowing-ssh-from-anywhere\">Example for Allowing SSH from Anywhere</a></li>\n<li><a href=\"#allow-ssh-only-from-your-ip-address\">Allow SSH Only from Your IP Address</a></li>\n</ul>\n</li>\n<li><a href=\"#deleting-a-security-group\">Deleting a Security Group</a><ul>\n<li><a href=\"#basic-usage-2\">Basic Usage</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>A security group acts as a virtual firewall for your instance to control inbound and outbound traffic.\nWhen you launch an instance in a VPC, you can assign up to five security groups to the instance.\nSecurity groups act at the instance level, not the subnet level.\nTherefore, each instance in a subnet in your VPC could be assigned to a different set of security groups.\nIf you don't specify a particular group at launch time, the instance is automatically assigned to the default security group for the VPC.</p>\n<p>For each security group, you add rules that control the inbound traffic to instances, and a separate set of rules that control the outbound traffic.\nThis section describes the basic things you need to know about security groups for your VPC and their rules.</p>\n<h2>Security Group basics</h2>\n<p>The following are the basic characteristics of security groups for your VPC:\n- You have limits on the number of security groups that you can create per VPC, the number of rules that you can add to each security group, and the number of security groups you can associate with a network interface. For more information, see Amazon VPC Limits.\n- You can specify allow rules, but not deny rules.\n- You can specify separate rules for inbound and outbound traffic.\n- When you create a security group, it has no inbound rules. Therefore, no inbound traffic originating from another host to your instance is allowed until you add inbound rules to the security group.\n- By default, a security group includes an outbound rule that allows all outbound traffic. You can remove the rule and add outbound rules that allow specific outbound traffic only. If your security group has no outbound rules, no outbound traffic originating from your instance is allowed.\n- Security groups are stateful \u2014 if you send a request from your instance, the response traffic for that request is allowed to flow in regardless of inbound security group rules. Responses to allowed inbound traffic are allowed to flow out, regardless of outbound rules.\n- Instances associated with a security group can't talk to each other unless you add rules allowing it (exception: the default security group has these rules by default).\n- Security groups are associated with network interfaces. After you launch an instance, you can change the security groups associated with the instance, which changes the security groups associated with the primary network interface (eth0). You can also change the security groups associated with any other network interface. For more information about network interfaces, see Elastic Network Interfaces.\n- When you create a security group, you must provide it with a name and a description. The following rules apply:\n- Names and descriptions can be up to 255 characters in length.\n- Names and descriptions are limited to the following characters: a-z, A-Z, 0-9, spaces, and ._-:/()#,@[]+=&amp;;{}!$*.\n- A security group name cannot start with sg-.\n- A security group name must be unique within the VPC.</p>\n<h2>Creating Security Groups</h2>\n<p>Security groups can be created and applied to a VPC; instances within this VPC will then be affected, unless a Security Group has been applied to them directly.</p>\n<pre><code class=\"bash\"># aws ec2 create-security-group --group-name [SECURITY_GROUP_NAME] --description [DESCRIPTION] --vpc-id [VPC_ID]\naws ec2 create-security-group --group-name my-sg --description &quot;My security group&quot; --vpc-id vpc-1a2b3c4d\n</code></pre>\n\n<h2>Listing Security Groups</h2>\n<h3>Basic Usage</h3>\n<p>The Security Groups that you have can be listed:</p>\n<pre><code class=\"bash\"># aws ec2 describe-security-groups\naws ec2 describe-security-groups\n</code></pre>\n\n<h3>Filtering Out Security Groups by Name</h3>\n<p>Viewing Security Groups by name can be useful when you have a lot of them:</p>\n<pre><code class=\"bash\"># aws ec2 describe-security-groups --group-names [GROUP_NAMES]\naws ec2 describe-security-groups --group-names my-sg\n</code></pre>\n\n<h2>Security Group Rules</h2>\n<h3>Overview</h3>\n<p>You can add or remove rules for a security group (also referred to as authorizing or revoking inbound or outbound access). A rule applies either to inbound traffic (ingress) or outbound traffic (egress). You can grant access to a specific CIDR range, or to another security group in your VPC or in a peer VPC (requires a VPC peering connection).</p>\n<p>The following are the basic parts of a security group rule in a VPC:\n- (Inbound rules only) The source of the traffic and the destination port or port range. The source can be another security group, an IPv4 or IPv6 CIDR block, or a single IPv4 or IPv6 address.\n- (Outbound rules only) The destination for the traffic and the destination port or port range. The destination can be another security group, an IPv4 or IPv6 CIDR block, a single IPv4 or IPv6 address, or a prefix list ID ( A service is identified by a prefix list\u2014the name and ID of a service for a Region).\n- Any protocol that has a standard protocol number (for a list, see Protocol Numbers). If you specify ICMP as the protocol, you can specify any or all of the ICMP types and codes.\n- An optional description for the security group rule to help you identify it later. A description can be up to 255 characters in length. Allowed characters are a-z, A-Z, 0-9, spaces, and ._-:/()#,@[]+=;{}!$*.</p>\n<p>When you specify a CIDR block as the source for a rule, traffic is allowed from the specified addresses for the specified protocol and port. When you specify a security group as the source for a rule, traffic is allowed from the elastic network interfaces (ENI) for the instances associated with the source security group for the specified protocol and port. Adding a security group as a source does not add rules from the source security group.</p>\n<p>If you specify a single IPv4 address, specify the address using the /32 prefix length. If you specify a single IPv6 address, specify it using the /128 prefix length. For example to specify the address <code>216.58.213.14</code>, you can use the following: <code>216.58.213.14/32</code></p>\n<p>Some systems for setting up firewalls let you filter on source ports. Security groups only let you filter on destination ports.</p>\n<p>When you add or remove rules, they are automatically applied to all instances associated with the security group.</p>\n<h3>Basic Usage</h3>\n<p>To make a rule allowing incoming traffic, we must provide the Security Group ID, the Protocol being used, the address range where the requests will be coming from and the port that will be used:</p>\n<pre><code class=\"bash\"># aws ec2 authorize-security-group-ingress --group-id [SECURITY_GROUP_ID] --protocol [PROTOCOL] --port [PORT] --cidr [ADDRESS_RANGE]\naws ec2 authorize-security-group-ingress --group-id sg-903004f8 --protocol tcp --port 443 --cidr 0.0.0.0/0\n</code></pre>\n\n<h3>Example for Allowing SSH from Anywhere</h3>\n<p>Here is an example that will allow anyone in the world to attempt an SSH connection to your machine:</p>\n<pre><code class=\"bash\"># aws ec2 authorize-security-group-ingress --group-id [SECURITY_GROUP_ID] --protocol [PROTOCOL] --port [PORT] --cidr [ADDRESS_RANGE]\naws ec2 authorize-security-group-ingress --group-id sg-903004f8 --protocol tcp --port 22 --cidr 0.0.0.0/0\n</code></pre>\n\n<h3>Allow SSH Only from Your IP Address</h3>\n<p>Allowing access from anywhere may be a security concern, so it's good to know how to control access.\nWe can use https://checkip.amazonaws.com to check our public IP address:</p>\n<pre><code class=\"bash\">$ curl https://checkip.amazonaws.com\n203.0.113.57\n</code></pre>\n\n<p>Once you know your public IP address, this can be used when configuring the SSH rule in our Security Group:</p>\n<pre><code class=\"bash\"># aws ec2 authorize-security-group-ingress --group-id [SECURITY_GROUP_ID] --protocol [PROTOCOL] --port [PORT] --cidr [ADDRESS_RANGE]\naws ec2 authorize-security-group-ingress --group-id sg-903004f8 --protocol tcp --port 22 --cidr 203.0.113.57/32\n</code></pre>\n\n<p>You can also use command substitution in bash to get this working in a single command:</p>\n<pre><code class=\"bash\"># aws ec2 authorize-security-group-ingress --group-id [SECURITY_GROUP_ID] --protocol [PROTOCOL] --port [PORT] --cidr [ADDRESS_RANGE]\naws ec2 authorize-security-group-ingress --group-id sg-903004f8 --protocol tcp --port 22 --cidr $(curl https://checkip.amazonaws.com)/32\n</code></pre>\n\n<h2>Deleting a Security Group</h2>\n<h3>Basic Usage</h3>\n<p>You must provide the ID of the Security Group when you are deleting it:</p>\n<pre><code class=\"bash\"># aws ec2 delete-security-group --group-id [SECURITY_GROUP_ID]\naws ec2 delete-security-group --group-id sg-903004f8\n</code></pre>\n\n<p><a href=\"../README.md#tasks\">Go Back to VPC Tasks</a></p>"}, {"gitUri": "topics/aws/modules/vpc-route-tables", "overview": "A route table contains a set of rules, called routes, that are used to determine where network traffic is directed.", "name": "AWS Route Tables", "resourceName": "aws/vpc-route-tables", "content": "<h1>AWS Route Tables</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#creating-route-tables\">Creating Route Tables</a></li>\n<li><a href=\"#deleting-route-tables\">Deleting Route Tables</a><ul>\n<li><a href=\"#basic-usage\">Basic Usage</a></li>\n</ul>\n</li>\n<li><a href=\"#creating-routes\">Creating Routes</a><ul>\n<li><a href=\"#route-for-internet-access\">Route for Internet Access</a></li>\n</ul>\n</li>\n<li><a href=\"#deleting-routes\">Deleting Routes</a><ul>\n<li><a href=\"#basic-usage-1\">Basic Usage</a></li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a></li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>A route table contains a set of rules, called routes, that are used to determine where network traffic is directed.</p>\n<p>Each subnet in your VPC must be associated with a route table; the table controls the routing for the subnet. A subnet can only be associated with one route table at a time, but you can associate multiple subnets with the same route table.\nThe following are the basic things that you need to know about route tables:\n- Your VPC has an implicit router.\n- Your VPC automatically comes with a main route table that you can modify.\n- You can create additional custom route tables for your VPC.\n- Each subnet must be associated with a route table, which controls the routing for the subnet. If you don't explicitly associate a subnet with a particular route table, the subnet is implicitly associated with the main route table.\n- You cannot delete the main route table, but you can replace the main route table with a custom table that you've created (so that this table is the default table each new subnet is associated with).\n- Each route in a table specifies a destination CIDR and a target (for example, traffic destined for the external corporate network 172.16.0.0/12 is targeted for the virtual private gateway). We use the most specific route that matches the traffic to determine how to route the traffic.\n- CIDR blocks for IPv4 and IPv6 are treated separately. For example, a route with a destination CIDR of 0.0.0.0/0 (all IPv4 addresses) does not automatically include all IPv6 addresses. You must create a route with a destination CIDR of ::/0 for all IPv6 addresses.\n- Every route table contains a local route for communication within the VPC over IPv4. If your VPC has more than one IPv4 CIDR block, your route tables contain a local route for each IPv4 CIDR block. If you've associated an IPv6 CIDR block with your VPC, your route tables contain a local route for the IPv6 CIDR block. You cannot modify or delete these routes.\n- When you add an Internet gateway, an egress-only Internet gateway, a virtual private gateway, a NAT device, a peering connection, or a VPC endpoint in your VPC, you must update the route table for any subnet that uses these gateways or connections.</p>\n<h2>Creating Route Tables</h2>\n<p>When creating a route table, you will need a VPC to attach it to. This is then referenced by its ID when creating the Route Table:</p>\n<pre><code class=\"bash\"># aws ec2 create-route-table --vpc-id [VPC_ID]\naws ec2 create-route-table --vpc-id vpc-a01106c2\n</code></pre>\n\n<h2>Deleting Route Tables</h2>\n<h3>Basic Usage</h3>\n<p>Like most resources, a Route Table can be deleted by referencing its ID.\nMake sure that the Route Table isn't being used by any VPCs or Subnets:</p>\n<pre><code class=\"bash\"># aws ec2 delete-route-table --route-table-id [ROUTE_TABLE_ID]\naws ec2 delete-route-table --route-table-id rtb-22574640\n</code></pre>\n\n<h2>Creating Routes</h2>\n<h3>Route for Internet Access</h3>\n<p>A very common reason for needing to create routes is for Internet access; we can create a route for all requests from instances in a VPC going to the <code>0.0.0.0/0</code> address range to get routed to an Internet Gateway, allowing internet access for that instance:</p>\n<pre><code class=\"bash\"># aws ec2 create-route --route-table-id [ROUTE_TABLE_ID] --destination-cidr-block [ADDRESS_RANGE] --gateway-id [INTERNET_GATEWAY_ID]\naws ec2 create-route --route-table-id rtb-22574640 --destination-cidr-block 0.0.0.0/0 --gateway-id igw-c0a643a9\n</code></pre>\n\n<h2>Deleting Routes</h2>\n<h3>Basic Usage</h3>\n<p>When deleting a Route from a Route Table, you must reference the Route Table ID and the destination CIDR block (the address range) that the Route has configured - for example: <code>0.0.0.0/0</code>:</p>\n<pre><code class=\"bash\"># aws ec2 delete-route --route-table-id [ROUTE_TABLE_ID] --destination-cidr-block [CIDR_BLOCK]\naws ec2 delete-route --route-table-id rtb-22574640 --destination-cidr-block 0.0.0.0/0\n</code></pre>\n\n<h2>Tasks</h2>\n<ul>\n<li>Create VPC and an Internet Gateway that is attached to it.</li>\n<li>Create a Route Table for the new VPC.</li>\n<li>Add a Route that allows Internet Access for the VPC.</li>\n<li>Delete the Route Table, detach the Internet Gateway from the VPC and delete the it, Delete the VPC</li>\n</ul>\n<p><a href=\"../README.md#tasks\">Go Back</a></p>"}, {"gitUri": "topics/aws/modules/ec2-introduction", "overview": "Amazon Elastic Compute Cloud (Amazon EC2) is a web service that provides secure, resizable compute capacity in the cloud. It is designed to make web-scale cloud computing easier for developers.", "name": "Elastic Cloud Compute (EC2)", "resourceName": "aws/ec2-introduction", "content": "<h1>Elastic Cloud Compute (EC2)</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#tasks\">Tasks</a></li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>Amazon Elastic Compute Cloud (Amazon EC2) is a web service that provides secure, resizable compute capacity in the cloud. It is designed to make web-scale cloud computing easier for developers.</p>\n<p>Amazon EC2\u2019s simple web service interface allows you to obtain and configure capacity with minimal friction.\nIt provides you with complete control of your computing resources and lets you run on Amazon\u2019s proven computing environment.\nAmazon EC2 reduces the time required to obtain and boot new server instances to minutes, allowing you to quickly scale capacity, both up and down, as your computing requirements change.\nAmazon EC2 changes the economics of computing by allowing you to pay only for capacity that you actually use.\nAmazon EC2 provides developers the tools to build failure resilient applications and isolate them from common failure scenarios.</p>\n<h2>Tasks</h2>\n<ul>\n<li>To be able to connect securely to our EC2 instances, we need to configure keys. This can be done with  <a href=\"./key-pairs\">Key Pairs</a></li>\n<li>Learn about running <a href=\"./instances\">EC2 Instances</a></li>\n</ul>\n<p><a href=\"../README.md#tasks\">Go Back</a></p>"}]}, {"gitUri": "topics/markdown", "overview": "Markdown is a way to write content for the web. It's written in what people call 'plaintext'; this is just the regular alphabet, with a few symbols (such as `*` and `#`).", "name": "Markdown", "resourceName": "markdown", "modules": [{"gitUri": "topics/markdown/modules/basics", "overview": "", "name": "Basics", "resourceName": "markdown/basics", "content": "<h1>Basics</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#italics--bold\">Italics &amp; Bold</a></li>\n<li><a href=\"#headers\">Headers</a></li>\n<li><a href=\"#blockquotes\">Blockquotes</a></li>\n<li><a href=\"#lists\">Lists</a></li>\n<li><a href=\"#paragraphs\">Paragraphs</a><ul>\n<li><a href=\"#hard-breaks\">Hard Breaks</a></li>\n<li><a href=\"#soft-breaks\">Soft Breaks</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>This module covers some of the fundamentals of Markdown. After this, you should be well on your way to creating your own Markdown files. </p>\n<h2>Italics &amp; Bold</h2>\n<p>Making text <em>italic</em> and/or <strong>bold</strong> is really useful. Thankfully, it's simple to do. To make text italic, surround it with <code>_</code>, and to make it bold, surround it with <code>**</code>, like so:</p>\n<pre><code class=\"markdown\">_this would make text italic_\n**this would make text bold**\n</code></pre>\n\n<p>You can make words <strong><em>both bold and italic</em></strong>:</p>\n<pre><code class=\"markdown\">**_This would make the sentence bold and italic_**\n</code></pre>\n\n<h2>Headers</h2>\n<p>To make headers in Markdown, you preface the phrase with a <code>#</code> symbol. Headers come in different size, which can be dictated by the number of <code>#</code> symbols you use:</p>\n<pre><code class=\"markdown\"># Header 1 = Largest\n## Header 2\n### Header 3\n#### Header 4\n##### Header 5\n###### Header 6 - Smallest\n</code></pre>\n\n<h2>Blockquotes</h2>\n<p>If you need to call special attention to a quote from another source, or design a pull quote for a magazine article, then Markdown's blockquote syntax will be useful. A blockquote is a sentence or paragraph that's been specially formatted to draw attention to the reader:</p>\n<blockquote>\n<p>\"Hard work beats talent, when talent doesn't work hard\"</p>\n</blockquote>\n<p>To do this, all you have to do is preface the line with a <code>&gt;</code> symbol:</p>\n<pre><code class=\"markdown\">&gt; This would make this sentence a block quote\n</code></pre>\n\n<p>If your quote spans multiple lines, you will need to put a <code>&gt;</code> before each line (even the empty lines):</p>\n<pre><code class=\"markdown\">&gt; Quote spanning\n&gt;\n&gt;\n&gt; multiple lines\n</code></pre>\n\n<h2>Lists</h2>\n<p>You can create a list with bullet points, by prefacing each list item with a <code>*</code>, or a list with numbers, by prefacing each list item with a number and full stop (<code>1.</code>):</p>\n<pre><code class=\"markdown\">* Bullet\n* Point\n* List\n\n1. Numbered\n2. List\n</code></pre>\n\n<ul>\n<li>Bullet</li>\n<li>Point</li>\n<li>\n<p>List</p>\n</li>\n<li>\n<p>Numbered</p>\n</li>\n<li>List</li>\n</ul>\n<p>You can make nested lists by indenting each item <strong>one space</strong> more than the preceding item:</p>\n<pre><code class=\"markdown\">* Indented\n * list\n * would look like\n  * this\n</code></pre>\n\n<ul>\n<li>Indented</li>\n<li>list</li>\n<li>would look like<ul>\n<li>this</li>\n</ul>\n</li>\n</ul>\n<h2>Paragraphs</h2>\n<p>If you want text to format your text to span a few lines (think poetry or a small paragraph under a list item), you won't be able to manually insert each new line:</p>\n<pre><code class=\"markdown\">This poetry is very smart,\nEach new line is a new start,\nOr is it?\n</code></pre>\n\n<p>Eventhough this looks like a verse of (amazing) poetry, Markdown would render this as one long line - this isn't what we want!</p>\n<h3>Hard Breaks</h3>\n<p>A hard break is where you would take the above verse and forcefully insert new lines:</p>\n<pre><code class=\"markdown\">This poetry is very smart,\n\nEach new line is a new start,\n\nOr is it?\n</code></pre>\n\n<p>Doing this would affect the togetherness of the text, which also isn't what we want to do.</p>\n<h3>Soft Breaks</h3>\n<p>We want to use a soft break for this. To do this, you would insert 2 spaces at the end of each line (below, each <code>.</code> denotes a space):</p>\n<pre><code class=\"markdown\">This poetry is very smart,..\nEach new lines is a new start,..\nIt is!\n</code></pre>\n\n<p>It's not as simple as making the text 'readable'...we have to make sure Markdown interprets the text how we want it to.</p>"}, {"gitUri": "topics/markdown/modules/advanced", "overview": "This topic will go over some of the more advanced Markdown syntax and formatting. There's lots you can do with Markdown, so experiment beyond this brief introduction to it!", "name": "Advanced", "resourceName": "markdown/advanced", "content": "<h1>Advanced</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#image-align\">Image Align</a><ul>\n<li><a href=\"#left-alignment\">Left Alignment</a></li>\n<li><a href=\"#right-alignment\">Right Alignment</a></li>\n<li><a href=\"#centre-alignment\">Centre Alignment</a></li>\n</ul>\n</li>\n<li><a href=\"#collapse-sections\">Collapse Sections</a></li>\n<li><a href=\"#tables\">Tables</a><ul>\n<li><a href=\"#table-alignment\">Table Alignment</a></li>\n</ul>\n</li>\n<li><a href=\"#closing\">Closing</a></li>\n<li><a href=\"#task\">Task</a></li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>This topic will go over some of the more advanced Markdown syntax and formatting. There's lots you can do with Markdown, so experiment beyond this brief introduction to it!</p>\n<h2>Image Align</h2>\n<p>As you saw in the last topic, we didn't dictate where we wanted our images to be displayed on the page. You'll be glad to hear that we are able to do this: </p>\n<h3>Left Alignment</h3>\n<p><img align=\"left\" width=\"100\" height=\"100\" src=\"https://s3.amazonaws.com/spectrumnews-web-assets/wp-content/uploads/2018/11/13154625/20181112-SHANK3monkey-844.jpg\"></p>\n<p>To left align your images, you need to do the following:</p>\n<pre><code class=\"html\">&lt;img align=&quot;left&quot; width=&quot;100&quot; height=&quot;100&quot; src=&quot;https://s3.amazonaws.com/spectrumnews-web-assets/wp-content/uploads/2018/11/13154625/20181112-SHANK3monkey-844.jpg&quot;&gt;\n</code></pre>\n\n<hr />\n<h3>Right Alignment</h3>\n<p><img align=\"right\" width=\"100\" height=\"100\" src=\"https://s3.amazonaws.com/spectrumnews-web-assets/wp-content/uploads/2018/11/13154625/20181112-SHANK3monkey-844.jpg\"></p>\n<p>To right align your images, use:</p>\n<pre><code class=\"html\">&lt;img align=&quot;right&quot; width=&quot;100&quot; height=&quot;100&quot; src=&quot;https://s3.amazonaws.com/spectrumnews-web-assets/wp-content/uploads/2018/11/13154625/20181112-SHANK3monkey-844.jpg&quot;&gt;\n</code></pre>\n\n<hr />\n<h3>Centre Alignment</h3>\n<p>To align your images in the centre of a page, simply use:</p>\n<pre><code class=\"html\">&lt;p align=&quot;center&quot;&gt;\n  &lt;img width=&quot;460&quot; height=&quot;300&quot; src=&quot;https://s3.amazonaws.com/spectrumnews-web-assets/wp-content/uploads/2018/11/13154625/20181112-SHANK3monkey-844.jpg&quot;&gt;\n&lt;/p&gt;\n</code></pre>\n\n<p align=\"center\">\n  <img width=\"460\" height=\"300\" src=\"https://s3.amazonaws.com/spectrumnews-web-assets/wp-content/uploads/2018/11/13154625/20181112-SHANK3monkey-844.jpg\">\n</p>\n\n<p>As you can see, you can also dictate the width and height of an image at the same time!</p>\n<hr />\n<h2>Collapse Sections</h2>\n<p><details>\n<summary>Click to learn!</summary></p>\n<p>Collapsing large blocks of text can make your Markdown easier to read. It is also really useful for solutions or hints to exercises.</p>\n<p>To add a collapsing section, you need to do:</p>\n<pre><code class=\"html\">&lt;details&gt;\n&lt;summary&gt;&quot;Click to expand&quot;&lt;/summary&gt;\nthis is hidden\n&lt;/details&gt;\n</code></pre>\n\n</details>\n\n<hr />\n<h2>Tables</h2>\n<p>To add a table, use three or more hyphens (---) to create each column\u2019s header, and use pipes (|) to separate each column. You can optionally add pipes on either end of the table:</p>\n<pre><code class=\"markdown\">| Column1     | Column2     |\n| ----------- | ----------- |\n| Header      | Title       |\n| Paragraph   | Text        |\n</code></pre>\n\n<table>\n<thead>\n<tr>\n<th>Column1</th>\n<th>Column2</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Row1</td>\n<td>Row1</td>\n</tr>\n<tr>\n<td>Row2</td>\n<td>Row2</td>\n</tr>\n</tbody>\n</table>\n<h3>Table Alignment</h3>\n<p>You can align text in the columns to the left, right, or center by adding a colon (:) to the left, right, or on both side of the hyphens within the header row:</p>\n<pre><code class=\"markdown\">| Left Align  | Centre Align | Right Align   |\n| :---        |    :----:    |          ---: |\n| Row1        | Row1         | Row1          |\n| Row2        | Row2         | Row2          |\n</code></pre>\n\n<table>\n<thead>\n<tr>\n<th align=\"left\">Left Align</th>\n<th align=\"center\">Centre Align</th>\n<th align=\"right\">Right Align</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\">Row1</td>\n<td align=\"center\">Row1</td>\n<td align=\"right\">Row1</td>\n</tr>\n<tr>\n<td align=\"left\">Row2</td>\n<td align=\"center\">Row2</td>\n<td align=\"right\">Row2</td>\n</tr>\n</tbody>\n</table>\n<h2>Closing</h2>\n<p>By no means is this an extensive Markdown module, but it should give you the tools to create Markdown README.md files to a relatively good standard. Make sure to give the task below a go!</p>\n<h2>Task</h2>\n<ul>\n<li>Go to the <a href=\"./project\">projects folder</a></li>\n<li>Create a README.md to explain how to get the simple python application up and running</li>\n<li>The formatting is for you to be creative with, but you must highlight to the user that they need to:</li>\n<li>Install python3 (including a link to the website)</li>\n<li>Install <code>pip3</code> - <code>sudo apt install python-pip</code></li>\n<li>Pip install virtualenv with <code>pip3 install virtualenv</code></li>\n<li>Create their virtual environment - <code>virtualenv venv</code><ul>\n<li>And make sure they are working inside of it - <code>source venv/bin/activate</code></li>\n</ul>\n</li>\n<li>Install the pip dependencies file, using <code>pip3 install -r pip_dependencies.txt</code></li>\n<li>Run the python program - <code>python3 pass_gen.py</code></li>\n</ul>"}, {"gitUri": "topics/markdown/modules/links_images", "overview": "This module explains how to integrate links and images into your Markdown files. Links and images make your Markdown more interactive and interesting, so it's really useful to learn how to use them.", "name": "Links and Images", "resourceName": "markdown/links_images", "content": "<h1>Links and Images</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#links\">Links</a><ul>\n<li><a href=\"#inline-link\">Inline Link</a></li>\n<li><a href=\"#reference-link\">Reference Link</a></li>\n</ul>\n</li>\n<li><a href=\"#images\">Images</a><ul>\n<li><a href=\"#inline-image-link\">Inline Image Link</a></li>\n<li><a href=\"#reference-image-link\">Reference Image Link</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>This module explains how to integrate links and images into your Markdown files. Links and images make your Markdown more interactive and interesting, so it's really useful to learn how to use them.</p>\n<h2>Links</h2>\n<p>There are two different link types in Markdown, but both of them render the exact same way.</p>\n<h3>Inline Link</h3>\n<p>An inline link occurs within the text body, and is a really quick way of creating a link in your Markdown file. To do an inline link, you wrap the text you want to use as the link in square brackets <code>[]</code>, and then put the link in normal brackets <code>()</code>:</p>\n<pre><code class=\"markdown\">[Search for it](http://www.google.com)\n</code></pre>\n\n<p><a href=\"http://www.google.com\">Search for it</a></p>\n<h3>Reference Link</h3>\n<p>These links, as the name implies, reference another place on your document, where the link is defined. The syntax for these is similar to, but not the same as, inline links:</p>\n<pre><code class=\"markdown\">Here's a link to [Google][google-link]\nAnd one to [GitHub][github-link]\n\n[google-link]: http://www.google.com\n[github-link]: http://www.github.com\n</code></pre>\n\n<p>Here's a link to <a href=\"http://www.google.com\">Google</a><br />\nAnd one to <a href=\"http://www.github.com\">GitHub</a></p>\n<p>The advantage of a reference link is that if you had multiple links to the same place in your document, and the link changed, you'd only need to update the link in one place (think variable in programming!)</p>\n<p>You can add other Markdown elements to links, such as <strong>bold</strong> and <em>italics</em>, by simply using the syntax you saw in the last module.</p>\n<h2>Images</h2>\n<p>Once you know how to create links in Markdown, you can work with images! The main difference is that images are prefaced with an exclamation mark <code>!</code>.</p>\n<p>Just like links, images have two styles that render in exactly the same way:</p>\n<h3>Inline Image Link</h3>\n<p>To create an inline image link, enter an exclamation mark <code>!</code>, wrap the alt text in square brackets <code>[]</code>, and then wrap the link in normal brackets <code>()</code>:</p>\n<pre><code class=\"markdown\">My favourite food:  \n![egg](https://static-s.aa-cdn.net/img/ios/454956113/395fdfd6a701d37e111c1ff20b993aed)\n</code></pre>\n\n<p>My favourite food:</p>\n<p><img alt=\"egg\" src=\"https://static-s.aa-cdn.net/img/ios/454956113/395fdfd6a701d37e111c1ff20b993aed\" /></p>\n<p>You don't necessarily need to add the alt text (in this case <code>egg</code>), but it makes the content asccesible to a wider audience (such as visually impaired), which is always a good thing.</p>\n<h3>Reference Image Link</h3>\n<p>For this, you follow the same pattern as the reference link in the previous section, but use the <code>!</code> as well:</p>\n<pre><code class=\"markdown\">![Manchester City][blue]\n![Manchester United][red]\n\n[blue]: https://cdn.images.express.co.uk/img/dynamic/footballteams/x256/20.png\n[red]: https://icons.iconseeker.com/png/fullsize/soccer-teams/manchester-united-fc-logo.png\n</code></pre>\n\n<p><img alt=\"Manchester City\" src=\"https://cdn.images.express.co.uk/img/dynamic/footballteams/x256/20.png\" /></p>\n<p><img alt=\"Manchester United\" src=\"https://icons.iconseeker.com/png/fullsize/soccer-teams/manchester-united-fc-logo.png\" /></p>\n<p>And that's it, for now, for links and images!</p>"}]}, {"gitUri": "topics/ansible", "overview": "Ansible is an open-source software provisioning, configuration management, and application-deployment tool.", "name": "Ansible", "resourceName": "ansible", "modules": [{"estTime": 20, "prerequisites": ["bash/introduction", "networking/ip-networking", "networking/ssh-key-configuration"], "gitUri": "topics/ansible/modules/inventory", "overview": "The Ansible inventory is used for defining hosts in your infrastructure to connect to and configure.", "name": "Inventory", "resourceName": "ansible/inventory", "content": "<!--PROPS\n{\n    \"estTime\": 20,\n    \"prerequisites\": [\n        \"bash/introduction\", \"networking/ip-networking\", \"networking/ssh-key-configuration\"\n    ]\n}\n-->\n\n<h1>Inventory</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#configuration-overview\">Configuration Overview</a><ul>\n<li><a href=\"#inventory-files-for-different-environments\">Inventory Files for Different Environments</a></li>\n</ul>\n</li>\n<li><a href=\"#inventory-parameters\">Inventory Parameters</a><ul>\n<li><a href=\"#applying-to-a-host\">Applying to a Host</a></li>\n<li><a href=\"#applying-to-a-group-of-hosts\">Applying to a Group of Hosts</a></li>\n<li><a href=\"#ansible-user\">Ansible User</a></li>\n<li><a href=\"#ssh-private-key-file\">SSH Private Key File</a></li>\n<li><a href=\"#ssh-arguments\">SSH Arguments</a></li>\n</ul>\n</li>\n<li><a href=\"#tasks\">Tasks</a>\n        - <a href=\"#prerequisites\">Prerequisites</a><ul>\n<li><a href=\"#configure-the-inventory-file\">Configure the Inventory File</a></li>\n<li><a href=\"#playbook\">Playbook</a></li>\n<li><a href=\"#run-the-playbook-on-the-test-hosts\">Run the Playbook on the <code>test</code> Hosts</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>The Ansible inventory is used for defining hosts in your infrastructure to connect to and configure.\nA host can be a domain name or IP address.\nThe default location for the inventory configurations are in the <code>/etc/ansible/hosts</code> file however, a different inventory file or hosts can be specified at any time when using the <code>-i</code> option on the command line:</p>\n<pre><code class=\"bash\"># specify an inventory file\nansible-playbook -i my_inventory playbook.yaml\n# specify a list of hosts\nansible-playbook -i '192.168.1.123,192.168.1.124' playbook.yaml\n</code></pre>\n\n<h2>Configuration Overview</h2>\n<p>The inventory file can be configured with an \"INI-LIKE\" syntax:</p>\n<pre><code class=\"ini\"># single host\nmail.example.com\n\n# group of hosts\n[webservers]\nfoo.example.com\nbar.example.com\n\n[dbservers]\none.example.com\ntwo.example.com\n216.58.205.46\n</code></pre>\n\n<p>When we are configuring ansible playbooks to run tasks we get the option to say which hosts to run the tasks on.\nEither a single host or group of hosts can be specified.\nWhen a group is specified, the tasks will be executed on all of the hosts in that particular group.\nThis feature makes Ansible great for configuring many hosts simultaneously.</p>\n<p>You may want to specify the inventory file for most of the tasks that you are running, to edit <code>/etc/ansible/hosts</code> you will likely need root access on the machine.</p>\n<h3>Inventory Files for Different Environments</h3>\n<p>Another reason for using the inventory file in a custom location is for running tasks on different environments.\nYou may have several environments for different development and testing purposes.</p>\n<p>These files can then be accessed by passing them as an argument to the inventory option <code>-i</code>:</p>\n<pre><code class=\"bash\">ansible-playbook -i staging playbook.yaml\nansible-playbook -i development playbook.yaml\n</code></pre>\n\n<h2>Inventory Parameters</h2>\n<p>Inventory parameters are additional properties which can be configured in the inventory file which can change things like:\n- The user to connect to the machine as\n- Which private SSH key to use\n- The port to connect on, if you aren't using SSH on port 22\n- The connection type - maybe you aren't using SSH at all and want to run the tasks locally or in a Docker container</p>\n<h3>Applying to a Host</h3>\n<p>Inventory parameters can be applied on per-host basis, in the example shown here <code>inventory_parameter</code> would be replaced with whatever parameter you would like to use:</p>\n<pre><code class=\"ini\">foo.example.com inventory_parameter=value\nbar.example.com inventory_parameter=value\n</code></pre>\n\n<h3>Applying to a Group of Hosts</h3>\n<p>Quite often we are going to want to use the same parameter and value for more than one host.\nThis can be done by applying the parameters to a group as opposed to a single host.\nIn the example shown, you would replace <code>inventory_parameter</code> with the the specific parameter that you want to use:</p>\n<pre><code class=\"ini\">[my-group]\nfoo.example.com\nbar.example.com\n\n[my-group:vars]\ninventory_parameter=value\n</code></pre>\n\n<h3>Ansible User</h3>\n<p>The <code>ansible_user</code> parameter can be used to change which user to connect as, here Ansible would try to connect to the <code>bar.example.com</code> host as the user <code>bob</code>:</p>\n<pre><code class=\"ini\">bar.example.com ansible_user=bob\n</code></pre>\n\n<h3>SSH Private Key File</h3>\n<p>One of Ansible's main use cases is for connecting to multiple hosts and multiple envinronments to configure many machines so naturally there are going to be different private SSH key files to access these many different hosts.</p>\n<p>A path to a private key file can be specified with <code>ansible_ssh_private_key_file</code>.\nIn the example shown below Ansible will try to connect to the <code>foo.example.com</code>, authenticating with the <code>~/.ssh/development_id_rsa</code> private key file:</p>\n<pre><code class=\"ini\">foo.example.com ansible_ssh_private_key_file=~/.ssh/development_id_rsa\n</code></pre>\n\n<h3>SSH Arguments</h3>\n<p>We are able to pass any arguments to the SSH connection using the <code>ansible_ssh_common_args</code> option.\nA common use case for this would be to disable strict host key checking if you knew for certain that the address you are connecting to is correct.</p>\n<p>Here is an example of the common args option being used to disable strict host key checking for SSH:</p>\n<pre><code class=\"ini\">foo.example.com ansible_ssh_common_args='-o StrictHostKeyChecking=no'\n</code></pre>\n\n<h2>Tasks</h2>\n<p>In this set of tasks we are going to be configuring Ansible to be able to \"ping\" a group of servers.</p>\n<h4>Prerequisites</h4>\n<ul>\n<li>Two Linux machines<ul>\n<li>Public IP Address</li>\n<li>Port 22 open to internet access</li>\n</ul>\n</li>\n<li>SSH key pair<ul>\n<li>Public key installed on both machines</li>\n<li>Private key installed on local machine as <code>~/.ssh/ansible_id_rsa</code></li>\n</ul>\n</li>\n</ul>\n<h3>Configure the Inventory File</h3>\n<p>There is a file in this module folder called <code>inventory</code>, use this as a template for creating your own inventory file, replacing the following:\n- <code>IP_ADDRESS_1</code> and <code>IP_ADDRESS_2</code> with the public IP addresses of you machines.\n- <code>USER</code> with the user you configured SSH access for on the machines</p>\n<p>It should then look something like this, but with different IP addresses and a different user, well unless you're called Bob I guess:</p>\n<pre><code class=\"ini\">[test]\nIP_ADDRESS_1\nIP_ADDRESS_2\n\n[test:vars]\nansible_user=USER\nansible_ssh_common_args='-o StrictHostKeyChecking=no'\nansible_ssh_private_key_file=~/.ssh/ansible_id_rsa\n</code></pre>\n\n<h3>Playbook</h3>\n<p>The playbook has been configured for you already in a file called <code>playbook.yaml</code>.\nAll this playbook does is tell Ansible to connect the <code>test</code> group of hosts in the inventory file and run the <code>ping</code> module.</p>\n<p>This playbook will confirm that we can successfully connect to all of the hosts in the <code>test</code> group and execute tasks on them:</p>\n<pre><code class=\"yaml\">- hosts: test\n  tasks:\n  - name: &quot;Ping {{ inventory_hostname }}&quot;\n    ping:\n</code></pre>\n\n<h3>Run the Playbook on the <code>test</code> Hosts</h3>\n<p>Now we can have a go at running the playbook, you will need to run the command shown while in this module directory.\nThe <code>-v</code> option is just going to show a little more information about the tasks being run, inlcuding the \"pong\" response from the servers:</p>\n<pre><code class=\"bash\">ansible-playbook -v -i inventory playbook.yaml\n</code></pre>\n\n<p>You should then see and output similar to the following, indicating that Ansible was able to connect successfully to the hosts configured in the inventory file:</p>\n<pre><code class=\"text\">bob@work-laptop:~/projects/github.com/bob-crutchley/notes/topics/ansible/modules/inventory$ ansible-playbook -i inventory -v playbook.yaml \n\nPLAY [test] ********************************************************************************************************************************************************************************\n\nTASK [Gathering Facts] *********************************************************************************************************************************************************************\nok: [ec2-3-9-191-132.eu-west-2.compute.amazonaws.com]\nok: [ec2-35-178-160-92.eu-west-2.compute.amazonaws.com]\n\nTASK [Ping] ********************************************************************************************************************************************************************************\nok: [ec2-3-9-191-132.eu-west-2.compute.amazonaws.com] =&gt; {&quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;}\nok: [ec2-35-178-160-92.eu-west-2.compute.amazonaws.com] =&gt; {&quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;}\n\nPLAY RECAP *********************************************************************************************************************************************************************************\nec2-3-9-191-132.eu-west-2.compute.amazonaws.com : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   \nec2-35-178-160-92.eu-west-2.compute.amazonaws.com : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   \n</code></pre>\n\n<p>Note that the hosts (<code>ec2-3-9-191-132.eu-west-2.compute.amazonaws.com</code> &amp; <code>ec2-35-178-160-92.eu-west-2.compute.amazonaws.com</code>) shown in the output will show as the IP addresses that you configured in your inventory file.</p>"}, {"gitUri": "topics/ansible/modules/introduction", "overview": "Ansible is an open-source software provisioning, configuration management, and application-deployment tool.", "name": "Introduction", "resourceName": "ansible/introduction", "content": "<!--PROPS>\n{\n    \"prerequisites\": [\n        \"package-managers/pip-introduction\",\n        \"linux/path-environment-variable\"\n    ],\n    \"supportedPlatforms\": [\n        \"ubuntu-18\"\n    ]\n}\n<!-->\n\n<h1>Introduction</h1>\n<!--TOC_START-->\n\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#installation\">Installation</a><ul>\n<li><a href=\"#using-pip\">Using Pip</a></li>\n</ul>\n</li>\n<li><a href=\"#task\">Task</a><ul>\n<li><a href=\"#install-ansible\">Install Ansible</a></li>\n<li><a href=\"#configure-a-playbook-to-install-a-web-server\">Configure a Playbook to Install a Web Server</a></li>\n<li><a href=\"#run-the-playbook\">Run the Playbook</a></li>\n<li><a href=\"#check-nginx-has-been-installed-correctly\">Check NGINX has been Installed Correctly</a></li>\n</ul>\n</li>\n</ul>\n<!--TOC_END-->\n\n<h2>Overview</h2>\n<p>Ansible is an open-source software provisioning, configuration management, and application-deployment tool.\nIt runs on many Unix-like systems, and can configure both Unix-like systems as well as Microsoft Windows. </p>\n<h2>Installation</h2>\n<h3>Using Pip</h3>\n<p>A good way to install Ansible is by using the Pip package manager.\nThis is because to run Ansible on any machine you are going to need Python installed, with Python installed the Pip package manager is a consistent way to install Ansible on any machine.</p>\n<p>We can also use Pip to install Ansible into the current user's home directory aswell - avoiding any need for elevated permissions on the machine.</p>\n<pre><code class=\"bash\"># make sure ~/.local/bin exists and is on your PATH\nmkdir -p ~/.local/bin\necho 'PATH=$PATH:~/.local/bin' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n## install ansible with pip\npip install --user ansible\n# check that ansible has been installed\nansible --version\n</code></pre>\n\n<h2>Task</h2>\n<h3>Install Ansible</h3>\n<p>Start by making sure that Python installed on you machine, then go ahead and install Ansible using Pip.</p>\n<h3>Configure a Playbook to Install a Web Server</h3>\n<p>We can use something called playbooks in Ansible to configure hosts, more on the configuration of this in another module.</p>\n<p>Of course you would commonly use Ansible to install applications and configurations on other remote hosts but for this example to keep things simple we will just install a web server on the same host.</p>\n<p>Here we have a playbook which installs a basic NGINX web server so that we can give Ansible a go, so go ahead and create a file called <code>playbook.yml</code> which contains the following:</p>\n<pre><code class=\"yaml\">---\n- hosts: 127.0.0.1\n  connection: local\n  become: true\n  tasks:\n  - name: Install NGINX\n    apt:\n      name: nginx\n      state: latest\n      update_cache: true\n  - name: Start NGINX Service\n    service:\n      name: nginx\n      state: started\n</code></pre>\n\n<h3>Run the Playbook</h3>\n<p>The <code>ansible-playbook</code> command can be used to run our playbook and install NGINX on the server:</p>\n<pre><code class=\"bash\">ansible-playbook playbok.yml\n</code></pre>\n\n<h3>Check NGINX has been Installed Correctly</h3>\n<p>The <code>curl</code> command can be used to check that our web server is running correctly:</p>\n<pre><code class=\"bash\">curl http://localhost\n</code></pre>\n\n<p>You should get a response back similar to this:</p>\n<pre><code class=\"html\">&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;Welcome to nginx!&lt;/title&gt;\n&lt;style&gt;\n    body {\n        width: 35em;\n        margin: 0 auto;\n        font-family: Tahoma, Verdana, Arial, sans-serif;\n    }\n&lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;\n&lt;p&gt;If you see this page, the nginx web server is successfully installed and\nworking. Further configuration is required.&lt;/p&gt;\n\n&lt;p&gt;For online documentation and support please refer to\n&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;\nCommercial support is available at\n&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"}]}]}
